{"cells":[{"cell_type":"markdown","metadata":{"id":"pR13fWqju2kK"},"source":["# 0. Initial Set-up"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2127,"status":"ok","timestamp":1718873474848,"user":{"displayName":"Ha Dong","userId":"09398423743232978796"},"user_tz":420},"id":"CTfLKeHgvFBb","outputId":"b3f485f4-3220-4a97-9ba5-e1192301bb51"},"outputs":[{"name":"stderr","output_type":"stream","text":["[10:44:42] Initializing Normalizer\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import requests\n","import os\n","import json\n","import tqdm\n","\n","from rdkit import Chem\n","from tqdm import tqdm\n","from thermo import functional_groups\n","from Bio import Entrez\n","from chembl_structure_pipeline import checker\n","from rdkit.Chem import rdMolDescriptors, Descriptors, Lipinski, Crippen, inchi\n","from rdkit.Chem.FilterCatalog import FilterCatalog, FilterCatalogParams\n","from concurrent.futures import ThreadPoolExecutor, as_completed\n","\n","import utils\n","import filters\n","from data_gathering import download_and_save"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":201,"status":"ok","timestamp":1718873482660,"user":{"displayName":"Ha Dong","userId":"09398423743232978796"},"user_tz":420},"id":"wa4sdsmpvI6L"},"outputs":[],"source":["# Save the path to your curation folder to \"curation_path\"\n","dataset_name = 'AID2258'\n","curation_path = 'S:/coding/WelQrate/'\n","data_folder = f'{curation_path}/data/{dataset_name}'\n","\n","# Columns to be extracted from the assays:\n","# Modify if your datasets have different format\n","smi_col = 'PUBCHEM_EXT_DATASOURCE_SMILES' # Column containing SMILES\n","cid_col = 'PUBCHEM_CID' # Column containing identifiers (e.g, CIDs)\n","activity_col = 'PUBCHEM_ACTIVITY_OUTCOME' # Column containing activity outcomes\n","col_list = [cid_col, smi_col, activity_col]"]},{"cell_type":"markdown","metadata":{"id":"oScTOVFvwzqE"},"source":["# 1. Data Gathering"]},{"cell_type":"markdown","metadata":{},"source":["Before importing data, need to identify which AIDs will be included. \n","\n","Data will be imported from https://pubchem.ncbi.nlm.nih.gov/assay/. For more information on PubChem's programmatic access, refer to: https://pubchem.ncbi.nlm.nih.gov/docs/bioassays. Some other programmatic access options available such as PUG-REST. However, these might not be optimal for bulk retrieval or handling of large dataset due to the limitation of request volume.\n","\n","Data for individual assays include 7 required columns (CIDs, isomeric SMILES, etc.) and optional test results. Refer to https://ftp.ncbi.nlm.nih.gov/pubchem/Bioassay/CSV/README for further details. For datasets intended for regression model, additional columns could be extracted accordingly."]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["# Desired AIDs:\n","AIDs = [2239, 2287, 2282, 2283, 2558]"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":257,"status":"ok","timestamp":1718873488081,"user":{"displayName":"Ha Dong","userId":"09398423743232978796"},"user_tz":420},"id":"hsCoPFP-w0Y9","outputId":"97cb2817-d699-49ba-93dc-fb6e27626047"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of datasets retrieving:  5\n"]}],"source":["#Keep unique values in list AIDs (since there could be overlapping AIDs from different targets or project)\n","AIDs = list(set(AIDs))\n","AIDs = [str(AID) for AID in AIDs]\n","print('Number of datasets retrieving: ', len(AIDs))"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3489,"status":"ok","timestamp":1718873492783,"user":{"displayName":"Ha Dong","userId":"09398423743232978796"},"user_tz":420},"id":"IbWS3EI3xFsl","outputId":"665d9a6e-abd6-41f5-bb07-b0cc204845dd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Completed 1 out of 5 datasets.\n","Completed 2 out of 5 datasets.\n","Completed 3 out of 5 datasets.\n","Completed 4 out of 5 datasets.\n","Completed 5 out of 5 datasets.\n"]}],"source":["download_and_save(AIDs, data_folder, col_list, smi_col, cid_col, activity_col)"]},{"cell_type":"markdown","metadata":{"id":"nVX8_HtF2N_x"},"source":["# 2. Isomeric SMILES"]},{"cell_type":"markdown","metadata":{"id":"etcd9f2W2QTI"},"source":["For the purpose of our project, we would like to include isomeric form of SMILES representation in our final dataset. Although PubChem claimed that their datatable should include isomeric SMILES (https://pubchem.ncbi.nlm.nih.gov/docs/bioassays), some dataset might include non-isomeric SMILES. This step is to import isomeric SMILES based on CIDs.\n","\n","Several packages such as RDkit have modules to return isomeric SMILES from a given input SMILES. However, for consistency, we decided to use the PubChem Identifier Exchange Service, which take an input identifier (CIDs, SMILES, InChI, etc.)  and return the corresponding identifier (CIDs, isomeric SMILES, InChIs, etc.). Here, we export the list of CIDs for compounds in our dataset and use this server to retrieve their isomeric SMILES. For more information, refer to: https://pubchem.ncbi.nlm.nih.gov/docs/identifier-exchange-service"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1241,"status":"ok","timestamp":1718873576031,"user":{"displayName":"Ha Dong","userId":"09398423743232978796"},"user_tz":420},"id":"uDfydbxE2Q9s"},"outputs":[],"source":["#Create a new step folder:\n","if not os.path.exists(f'{data_folder}/before_finished/step_2'):\n","    os.makedirs(f'{data_folder}/before_finished/step_2')\n","\n","#Export list of CIDs to csv with one column (without the column name):\n","for AID in AIDs:\n","    assay = pd.read_csv(f'{data_folder}/before_finished/step_1/AID{AID}.csv')\n","    cids = assay['PUBCHEM_CID'].astype(int)  # Ensure the CIDs are integers\n","    cids.to_csv(f'{data_folder}/before_finished/step_2/CID{AID}.csv', index=False, header=False)\n","\n","#After this step, we submit the list at https://pubchem.ncbi.nlm.nih.gov/idexchange/idexchange.cgi with operator type \"same CID\" and Output IDs \"SMILES\" (isomeric SMILES by default)\n","#https://pubchem.ncbi.nlm.nih.gov/docs/identifier-exchange-service for more details\n","#Here I named the output file as \"SMILES{AID}.txt\""]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def check_isomeric_smiles(AIDs):\n","    \"\"\"\n","    Check if the SMILES in the assay are the same as the isomeric forms returned by pubchem idexchange.\n","    Input: AIDs (list of strings)\n","    Output: non_isomeric_smi_cids (dictionary with AID as key and list of CIDs as values for the datasets in AIDs\n","    \"\"\"\n","    non_isomeric_smi_cids = {}\n","    for AID in AIDs:    \n","        non_isomeric_smi_cids[AID] = []\n","        #import SMILES.txt file as a table:\n","        correct_isomeric_smiles = pd.read_csv(f'{data_folder}/before_finished/step_2/isomeric_smi_{AID}.txt', sep='\\t', header=None)\n","        assay = pd.read_csv(f'{data_folder}/before_finished/step_1/AID{AID}.csv')\n","\n","        #compare smiles in assay with smiles in correct_smiles:\n","        for cid in assay['PUBCHEM_CID']:\n","            if assay.loc[assay['PUBCHEM_CID'] == cid, 'PUBCHEM_EXT_DATASOURCE_SMILES'].values[0] != correct_isomeric_smiles.loc[correct_isomeric_smiles[0] == cid, 1].values[0]:\n","                non_isomeric_smi_cids[AID].append(cid)\n","\n","        if len(non_isomeric_smi_cids[AID]) == 0:\n","            print(f'All SMILES in AID {AID} are isomeric')\n","        else:\n","            print(f'There are some potential non-isomeric SMILES in AID {AID}:')\n","            print(non_isomeric_smi_cids[AID])\n","\n","    return non_isomeric_smi_cids\n","\n","def update_isomeric(AIDs, non_isomeric_smi_cids):\n","    \"\"\"\n","    Update the SMILES in the assay to isomeric SMILES.\n","    Input: AIDs (list of strings), non_isomeric_smi_cids (dictionary with AID as key and list of non-isomeric CIDs as values)\n","    \"\"\"\n","    with open(f'{data_folder}/before_finished/step_2/non_isomeric_smi_cids.txt', 'w') as f:\n","        # record the non-isomeric SMILES \n","        for AID in AIDs:\n","            assay = pd.read_csv(f'{data_folder}/before_finished/step_1/AID{AID}.csv')\n","            correct_isomeric_smiles = pd.read_csv(f'{data_folder}/before_finished/step_2/isomeric_smi_{AID}.txt', sep='\\t', header=None)\n","            f.write(f'AID {AID}: {non_isomeric_smi_cids[AID]}\\n')\n","\n","            for cid in non_isomeric_smi_cids[AID]:\n","                f.write(f'CID {cid}: {assay.loc[assay[\"PUBCHEM_CID\"] == cid, \"PUBCHEM_EXT_DATASOURCE_SMILES\"].values[0]} -> {correct_isomeric_smiles.loc[correct_isomeric_smiles[0] == cid, 1].values[0]}\\n')\n","                assay.loc[assay['PUBCHEM_CID'] == cid, 'PUBCHEM_EXT_DATASOURCE_SMILES'] = correct_isomeric_smiles.loc[correct_isomeric_smiles[0] == cid, 1].values[0]\n","\n","            f.write(f'===\\n')\n","            assay.to_csv(f'{data_folder}/before_finished/step_2/AID{AID}.csv', index=False)       "]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["All SMILES in AID 2282 are isomeric\n","All SMILES in AID 2283 are isomeric\n","All SMILES in AID 2287 are isomeric\n","All SMILES in AID 2558 are isomeric\n","There are some potential non-isomeric SMILES in AID 2239:\n","[3330059.0, 1979247.0, 2999888.0, 1952060.0, 1829082.0, 3730758.0, 2997662.0, 2997957.0, 3593962.0, 3640026.0]\n"]}],"source":["non_isomeric_smi_cids = check_isomeric_smiles(AIDs)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["update_isomeric(AIDs, non_isomeric_smi_cids)"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Import InChIs"]},{"cell_type":"markdown","metadata":{},"source":["We would like to include standard InChI to diversify users' choice of which data they would like to use for their own benchmark."]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# Create a new step folder:\n","if not os.path.exists(f'{data_folder}/before_finished/step_3'):\n","    os.makedirs(f'{data_folder}/before_finished/step_3')"]},{"cell_type":"markdown","metadata":{},"source":["Again, it is convenient to use the PubChem Identifier Exchange Service (https://pubchem.ncbi.nlm.nih.gov/idexchange/idexchange.cgi) with operator type \"same CID\" and Output IDs \"InChI\" to retrieve InChI from a given list of input CIDs. The same CID lists from STEP 2 could be used here. The resulted InChIs could be checked if being standard by indentifying the presence of 'InChI=1S' at the begining of each InChI string."]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["\"\"\"\n","CID lists (in \"step_2\" folder should be submitted to PubChem Identifier Exchange Service)\n","    Operator type: \"same CID\" \n","    Output IDs \"InChI\"\n","    Output method: \"Two column file showing each input output-correspondence\"\n","    Compression: \"No compression\"\n","InChI list should be saved into \"step_3\" folder, named as \"std_inchi_{AID}.txt\" \n","\"\"\"\n","# Import dataframes:\n","for AID in AIDs: \n","    exec(f'AID{AID} = pd.read_csv(\"{data_folder}/before_finished/step_2/AID{AID}.csv\")')\n","    exec(f'AID{AID}_InChI = pd.read_csv(\"{data_folder}/before_finished/step_3/std_inchi_{AID}.txt\", sep=\"\\\\t\", header=None)')"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["All InChI in AID2282 are standard\n","All InChI in AID2283 are standard\n","All InChI in AID2287 are standard\n","All InChI in AID2558 are standard\n","All InChI in AID2239 are standard\n"]}],"source":["#Check if they are all standard InChI:\n","for AID in AIDs:\n","    check_inchi = f\"\"\"\n","non_standard_InChI = []\n","for i in range(len(AID{AID}_InChI[1])):\n","    if not AID{AID}_InChI[1][i].startswith('InChI=1S'):\n","        non_standard_InChI.append(AID{AID}_InChI[1][i])\n","if not non_standard_InChI:\n","    print('All InChI in AID{AID} are standard')\n","else:\n","    print('There are some non-standard InChI in AID{AID}')\n","    print(non_standard_InChI)\n","    print('===')\n","\"\"\"\n","    exec(check_inchi)"]},{"cell_type":"markdown","metadata":{},"source":["Now we concatenate the InChIs in our tables:"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# Update and save the files\n","for AID in AIDs: \n","    update_inchi = f\"\"\"\n","AID{AID}_InChI_dict = dict(zip(AID{AID}_InChI[0], AID{AID}_InChI[1]))\n","AID{AID}['InChI'] = AID{AID}[cid_col].map(AID{AID}_InChI_dict)\n","AID{AID}['InChI'] = AID{AID}['InChI'].astype(str)\n","AID{AID}[cid_col] = AID{AID}[cid_col].astype(int)\n","AID{AID}.to_csv(r\"{data_folder}/before_finished/step_3/AID{AID}.csv\", index=False)\n","\"\"\"\n","    exec(update_inchi)"]},{"cell_type":"markdown","metadata":{},"source":["# 4. Check Duplicates"]},{"cell_type":"markdown","metadata":{},"source":["When checking duplicates in the datasets, we would like to know if there are\n","1) Multiple identical molecules\n","2) Molecules with identical CID but different InChIs or SMILES\n","3) Molecules with identical InChI but with different CIDs or SMILES"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["#import:\n","for AID in AIDs:\n","    exec(f\"AID{AID} = pd.read_csv(r'{data_folder}/before_finished/step_3/AID{AID}.csv', sep=',', header=0)\")\n","\n","#Create a new step folder:\n","if not os.path.exists(f'{data_folder}/before_finished/step_4'):\n","    os.makedirs(f'{data_folder}/before_finished/step_4')"]},{"cell_type":"markdown","metadata":{},"source":["## 4.1. Checking identical molecules"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of AID2282 InChI duplicates:  0\n","Number of AID2282 SMILES duplicates:  0\n","Number of AID2282 CID duplicates:  0\n","Number of AID2283 InChI duplicates:  0\n","Number of AID2283 SMILES duplicates:  0\n","Number of AID2283 CID duplicates:  0\n","Number of AID2287 InChI duplicates:  0\n","Number of AID2287 SMILES duplicates:  0\n","Number of AID2287 CID duplicates:  0\n","Number of AID2558 InChI duplicates:  0\n","Number of AID2558 SMILES duplicates:  0\n","Number of AID2558 CID duplicates:  0\n","Number of AID2239 InChI duplicates:  187\n","Number of AID2239 SMILES duplicates:  139\n","Number of AID2239 CID duplicates:  137\n"]}],"source":["#Return all duplicates by comparing InChI, SMILES, and CIDs:\n","for AID in AIDs:\n","    check_duplicate = f\"\"\"\n","AID{AID}_duplicates_InChI = AID{AID}[AID{AID}.duplicated(subset=['InChI'], keep=False)]\n","AID{AID}_duplicates_SMILES = AID{AID}[AID{AID}.duplicated(subset=[smi_col], keep=False)]\n","AID{AID}_duplicates_CIDs = AID{AID}[AID{AID}.duplicated(subset=[cid_col], keep=False)]\n","print('Number of AID{AID} InChI duplicates: ', len(AID{AID}_duplicates_InChI))\n","print('Number of AID{AID} SMILES duplicates: ', len(AID{AID}_duplicates_SMILES))\n","print('Number of AID{AID} CID duplicates: ', len(AID{AID}_duplicates_CIDs))\n","\"\"\"\n","    exec(check_duplicate)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["#write duplicates to a txt file: \n","with open(f'{data_folder}/before_finished/step_4/duplicates.txt', 'w') as f:\n","    for AID in AIDs: \n","        duplicates_InChI = eval(f'AID{AID}_duplicates_InChI')\n","        duplicates_SMILES = eval(f'AID{AID}_duplicates_SMILES')\n","        duplicates_CIDs = eval(f'AID{AID}_duplicates_CIDs')\n","        f.write(f'\\n\\nAID{AID} InChI duplicates:\\n')\n","        f.write(duplicates_InChI.to_string())\n","        f.write(f'\\nAID{AID} SMILES duplicates:\\n')\n","        f.write(duplicates_SMILES.to_string())\n","        f.write(f'\\nAID{AID} CID duplicates:\\n')\n","        f.write(duplicates_CIDs.to_string())"]},{"cell_type":"markdown","metadata":{},"source":["## 4.2. Same CIDs but different chemical representations"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["#reindex\n","for AID in AIDs: \n","    exec(f\"AID{AID}_duplicates_CIDs.reset_index(drop=True, inplace=True)\")"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["with open(f'{data_folder}/before_finished/step_4/sameCID_different_others.txt', 'w') as f:\n","    for AID in AIDs: \n","        sameCID_differentInChI = []\n","        sameCID_differentSMILES = []\n","        duplicates_CIDs = eval(f'AID{AID}_duplicates_CIDs')\n","        for i in range(len(duplicates_CIDs[cid_col])):\n","            for j in range(i+1, len(duplicates_CIDs[cid_col])):\n","                if duplicates_CIDs[cid_col][i] == duplicates_CIDs[cid_col][j]:\n","                    if duplicates_CIDs['InChI'][i] != duplicates_CIDs['InChI'][j]:\n","                        sameCID_differentInChI.append((duplicates_CIDs[cid_col][i], duplicates_CIDs[cid_col][j]))\n","                    if duplicates_CIDs[smi_col][i] != duplicates_CIDs[smi_col][j]:\n","                        sameCID_differentSMILES.append((duplicates_CIDs[cid_col][i], duplicates_CIDs[cid_col][j]))\n","\n","        if sameCID_differentInChI == []:\n","            f.write(f'No duplicate CIDs with different InChIs in AID{AID}\\n')\n","        else:\n","            f.write('Found duplicate CIDs with different InChIs in AID{AID}:\\n')\n","            f.write('\\n'.join(str(item) for item in sameCID_differentInChI))\n","            f.write(\"\\n\")\n","        \n","        if sameCID_differentSMILES == []:\n","            f.write(f'No duplicate CIDs with different SMILES in AID{AID}\\n')\n","        else:\n","            f.write(f'Found duplicate CIDs with different SMILES in AID{AID}:\\n')\n","            f.write('\\n'.join(str(item) for item in sameCID_differentSMILES))\n","            f.write(\"\\n\")\n","        f.write(\"===\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["## 4.3. Same InChI but with different CIDs or SMILES"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["#reindex\n","for AID in AIDs: \n","    exec(f\"AID{AID}_duplicates_InChI.reset_index(drop=True, inplace=True)\")"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["with open(f'{data_folder}/before_finished/step_4/sameInChI_different_others.txt', 'w') as f:\n","    for AID in AIDs: \n","        sameInChI_differentCID = []\n","        sameInChI_differentSMILES = []\n","        duplicates_InChI = eval(f'AID{AID}_duplicates_InChI')\n","        for i in range(len(duplicates_InChI['InChI'])):\n","            for j in range(i+1, len(duplicates_InChI['InChI'])):\n","                if duplicates_InChI['InChI'][i] == duplicates_InChI['InChI'][j]:\n","                    if duplicates_InChI[cid_col][i] != duplicates_InChI[cid_col][j]:\n","                        sameInChI_differentCID.append((duplicates_InChI[cid_col][i], duplicates_InChI[cid_col][j]))\n","                    if duplicates_InChI[smi_col][i] != duplicates_InChI[smi_col][j]:\n","                        sameInChI_differentSMILES.append((duplicates_InChI[cid_col][i], duplicates_InChI[cid_col][j]))\n","        \n","        if sameInChI_differentCID == []:\n","            f.write(f'No duplicate InChIs with different CIDs in AID{AID}\\n')\n","        else:\n","            f.write('Found duplicate InChIs with different CIDs in AID{AID}:\\n')\n","            f.write('\\n'.join(str(item) for item in sameInChI_differentCID))\n","            f.write(\"\\n\")\n","        \n","        if sameInChI_differentSMILES == []:\n","            f.write(f'No duplicate InChIs with different SMILES in AID{AID}\\n')\n","        else:\n","            f.write(f'Found duplicate InChIs with different SMILES in AID{AID}:\\n')\n","            f.write('\\n'.join(str(item) for item in sameInChI_differentSMILES))\n","            f.write(\"\\n\")\n","        f.write(\"===\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["## 4.4. Same SMILES but with different CIDs or InChIs"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["#reindex\n","for AID in AIDs: \n","    exec(f\"AID{AID}_duplicates_SMILES.reset_index(drop=True, inplace=True)\")"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["with open(f'{data_folder}/before_finished/step_4/sameSMILES_different_others.txt', 'w') as f:\n","    for AID in AIDs: \n","        sameSMILES_differentCID = []\n","        sameSMILES_differentInChI = []\n","        duplicates_SMILES = eval(f'AID{AID}_duplicates_SMILES')\n","        for i in range(len(duplicates_SMILES[smi_col])):\n","            for j in range(i+1, len(duplicates_SMILES[smi_col])):\n","                if duplicates_SMILES[smi_col][i] == duplicates_SMILES[smi_col][j]:\n","                    if duplicates_SMILES[cid_col][i] != duplicates_SMILES[cid_col][j]:\n","                        sameSMILES_differentCID.append((duplicates_SMILES[cid_col][i], duplicates_SMILES[cid_col][j]))\n","                    if duplicates_SMILES['InChI'][i] != duplicates_SMILES['InChI'][j]:\n","                        sameSMILES_differentInChI.append((duplicates_SMILES[cid_col][i], duplicates_SMILES[cid_col][j]))\n","        \n","        if sameSMILES_differentCID == []:\n","            f.write(f'No duplicate SMILES with different CIDs in AID{AID}\\n')\n","        else:\n","            f.write(f'Found duplicate SMILES with different CIDs in AID{AID}:\\n')\n","            f.write('\\n'.join(str(item) for item in sameSMILES_differentCID))\n","            f.write(\"\\n\")\n","        \n","        if sameSMILES_differentInChI == []:\n","            f.write(f'No duplicate SMILES with different InChIs in AID{AID}\\n')\n","        else:\n","            f.write(f'Found duplicate SMILES with different InChIs in AID{AID}:\\n')\n","            f.write('\\n'.join(str(item) for item in sameSMILES_differentInChI))\n","            f.write(\"\\n\")\n","        f.write(\"===\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["## 4.5. Drop duplicates"]},{"cell_type":"markdown","metadata":{},"source":["When dropping duplicates, we will keep the first molecule in a pair or a group of duplicates. For example, if there are 12 duplicates (6 pairs), we keep 6 componds."]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["No more duplicate InChI in AID2282\n","No more duplicate InChI in AID2283\n","No more duplicate InChI in AID2287\n","No more duplicate InChI in AID2558\n","No more duplicate InChI in AID2239\n"]}],"source":["# Keep only the first duplicate in the dataframes:\n","for AID in AIDs: \n","    exec(f\"AID{AID}.drop_duplicates(subset=['InChI'], keep='first', inplace=True)\")\n","\n","    last_check = f\"\"\"\n","if len(AID{AID}[AID{AID}.duplicated(subset=['InChI'], keep=False)]) == 0:\n","    print('No more duplicate InChI in AID{AID}')\n","else:\n","    print('There are still duplicate InChI in AID{AID}')   \n","    \"\"\"\n","    exec(last_check)"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["No more duplicate SMILES in AID2282\n","No more duplicate SMILES in AID2283\n","No more duplicate SMILES in AID2287\n","No more duplicate SMILES in AID2558\n","No more duplicate SMILES in AID2239\n"]}],"source":["for AID in AIDs: \n","    last_check = f\"\"\"\n","if len(AID{AID}[AID{AID}.duplicated(subset=[smi_col], keep=False)]) == 0:\n","    print('No more duplicate SMILES in AID{AID}')\n","else:\n","    print('There are still duplicate SMILES in AID{AID}')   \n","    \"\"\"\n","    exec(last_check)"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["No more duplicate CID in AID2282\n","No more duplicate CID in AID2283\n","No more duplicate CID in AID2287\n","No more duplicate CID in AID2558\n","No more duplicate CID in AID2239\n"]}],"source":["for AID in AIDs: \n","    last_check = f\"\"\"\n","if len(AID{AID}[AID{AID}.duplicated(subset=[cid_col], keep=False)]) == 0:\n","    print('No more duplicate CID in AID{AID}')\n","else:\n","    print('There are still duplicate CID in AID{AID}')   \n","    \"\"\"\n","    exec(last_check)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["# Save the dataframes to csv:\n","for AID in AIDs: \n","    exec(f\"AID{AID}.to_csv(r'{data_folder}/before_finished/step_4/AID{AID}.csv', index=False)\")"]},{"cell_type":"markdown","metadata":{},"source":["# 5. Hierarchical Curation"]},{"cell_type":"markdown","metadata":{},"source":["For the hierarchical curation, there are some rules:\n","\n","(1) All assays used should be on the same or close species/cell lines. Optimally, they should also be from the same project/laboratory.\n","\n","(2) Primary actives (PrA) will have a large false-positive rate. Therefore, they should be tested in follow-up confirmatory screens (optimally dose-reponse).\n","\n","(3) Actives could be promiscuous. Therefore, it is optimal to have counter-screens on different targets to test specificity.\n","\n","(4) For some projects, compounds were tested in multiple rounds. Therefore, assays often have hierarchical relations. From a single primary screen (Pr), active compounds (Pr_A) could be tested in multiple rounds of confirmatory screens (Cf_1, Cf_2, ..., Cf_final) or counter screens (Ct_1, Ct_2, etc.). Actives from confirmatory screens (Cf_actives) have a higher possibility of being true active. If an active compound is tested active in counter screens (Cf_actives), it is likely to be a promiscuous compound and should not be included.\n","\n","(4) It is important to know the relationship between assays. Active sets from downstream screens always have a lower false-positive rate than active sets from upstream screens due to better assay technologies on a smaller set of compounds. Therefore, final hits should be taken from the intersection of the very last confirmatory assays, without tested active in any counter-screen:\n","Final hits = [Cf_final1_actives ∩ Cf_final2_actives ∩ ...] \\ [Ct_1_actives ∪ Ct_2_actives ∪ ...]\n","\n","However, if the confirmatory assays are unrelated (tested on different set of compounds), then we might have to take the union of their active sets instead of the intersections as in this formula.\n","\n","(5) The hierarchical relations should be inspected carefully to see if follow-up confirmatory screens include extra compounds (Ex) that were not tested in earlier screens or tested inactive in earlier screens. If exist, these compounds require manual inspection.\n","\n","(6) Final inactives should be taken from primary inactives (Pr_inactives) (not inconclusive, unspecified, or probes), plus extra compounds that were tested inactive in conformatory screens (Ex_inactives), if justified.\n","Final inactives = Pr_inactives ∪ Ex_inactives"]},{"cell_type":"markdown","metadata":{},"source":["## 5.1. Classify groups of compounds in each assay by activities"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["path = f'{data_folder}/before_finished/step_4' \n","keynumbers = [2239, 2287, 2282, 2283, 2558] # specify the keynumbers you want to import\n","\n","for keynumber in keynumbers:\n","    filename = os.path.join(path, f'AID{keynumber}.csv')\n","    if os.path.exists(filename):\n","        df = pd.read_csv(filename, index_col=None, header=0)\n","        exec(f'AID{keynumber} = df')\n","        exec(f'AID{keynumber}_active = df[df[activity_col]==\"Active\"]')\n","        exec(f'AID{keynumber}_inactive = df[df[activity_col]==\"Inactive\"]')\n","        exec(f'AID{keynumber}_inconclusive = df[df[activity_col]==\"Inconclusive\"]')\n","        exec(f'AID{keynumber}_unspecified = df[df[activity_col]==\"Unspecified\"]')\n","        exec(f'AID{keynumber}_probe = df[df[activity_col]==\"Probe\"]')"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>AID</th>\n","      <th>Tested Compounds</th>\n","      <th>Active</th>\n","      <th>Inactive</th>\n","      <th>Inconclusive</th>\n","      <th>Unspecified</th>\n","      <th>Probe</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AID2239</td>\n","      <td>305575</td>\n","      <td>1644</td>\n","      <td>303931</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>AID2287</td>\n","      <td>1189</td>\n","      <td>804</td>\n","      <td>385</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>AID2282</td>\n","      <td>1189</td>\n","      <td>513</td>\n","      <td>676</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>AID2283</td>\n","      <td>1189</td>\n","      <td>331</td>\n","      <td>858</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>AID2558</td>\n","      <td>936</td>\n","      <td>91</td>\n","      <td>845</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       AID  Tested Compounds  Active  Inactive  Inconclusive  Unspecified  \\\n","0  AID2239            305575    1644    303931             0            0   \n","1  AID2287              1189     804       385             0            0   \n","2  AID2282              1189     513       676             0            0   \n","3  AID2283              1189     331       858             0            0   \n","4  AID2558               936      91       845             0            0   \n","\n","   Probe  \n","0      0  \n","1      0  \n","2      0  \n","3      0  \n","4      0  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["#Create a df with first column the variables name, and the second column the number of rows:\n","df = pd.DataFrame(columns=['AID', 'Tested Compounds', 'Active', 'Inactive', 'Inconclusive', 'Unspecified', 'Probe'])\n","for keynumber in keynumbers:\n","    exec(f'df.loc[len(df)] = [\"AID{keynumber}\", len(AID{keynumber}), len(AID{keynumber}_active), len(AID{keynumber}_inactive), len(AID{keynumber}_inconclusive), len(AID{keynumber}_unspecified), len(AID{keynumber}_probe)]')\n","df"]},{"cell_type":"markdown","metadata":{},"source":["## 5.2. Check the hierachical relations"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def check_is_in(downstream, upstream): \n","    downstream_in_upstream = downstream[downstream[cid_col].isin(upstream[cid_col])]\n","    downstream_notin_upstream = downstream[~downstream[cid_col].isin(upstream[cid_col])]\n","    return downstream_in_upstream, downstream_notin_upstream"]},{"cell_type":"markdown","metadata":{},"source":["### Flow: AID2239 (Pr), AID2287 (Cf), AID2282 (Ct_a), AID2283 (Ct_b), AID2558 (Ct_c)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Among AID2287, 6 were tested inactive in AID2239. Among these, 5 became active\n","Among AID2287, 0 were not tested in the AID2239. Among these, 0 became active\n"]}],"source":["# Check between AID2287 and AID2239\n","a1, a2 = check_is_in(AID2287, AID2239_inactive)\n","a3, a4 = check_is_in(a1, AID2287_active)\n","a5, a6 = check_is_in(AID2287, AID2239)\n","a7, a8 = check_is_in(a6, AID2287_active)\n","print(f'Among AID2287, {len(a1)} were tested inactive in AID2239. Among these, {len(a3)} became active')\n","print(f'Among AID2287, {len(a6)} were not tested in the AID2239. Among these, {len(a7)} became active')"]},{"cell_type":"markdown","metadata":{},"source":["## 5.3. Export the data"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["We ended up with 287 potential actives.\n"]}],"source":["set_2282 = set(AID2282_active[cid_col])\n","set_2283 = set(AID2283_active[cid_col])\n","set_2558 = set(AID2558_active[cid_col])\n","\n","# Union of the three sets\n","not_true_actives = set_2282.union(set_2283).union(set_2558)\n","\n","potential_actives = AID2287_active[~AID2287_active[cid_col].isin(not_true_actives)]\n","potential_actives = potential_actives.drop_duplicates(subset=[cid_col], keep='first')\n","print(f'We ended up with {len(potential_actives)} potential actives.')"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["We ended up with 303926 potential inactives.\n"]}],"source":["potential_inactives = AID2239_inactive[~AID2239_inactive[cid_col].isin(a3[cid_col])] # exclude the extra mols from a3 that became active\n","potential_inactives = potential_inactives.drop_duplicates(subset=[cid_col], keep='first')\n","print(f'We ended up with {len(potential_inactives)} potential inactives.')"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[],"source":["if not os.path.exists(f'{data_folder}/before_finished/step_5'):\n","    os.makedirs(f'{data_folder}/before_finished/step_5')\n","\n","#export the potential actives and inactives to csv:\n","potential_actives.to_csv(f'{data_folder}/before_finished/step_5/potential_actives.csv', index=False)\n","potential_inactives.to_csv(f'{data_folder}/before_finished/step_5/potential_inactives.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# 6. RDkit Parse Check"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["potential_actives = pd.read_csv(f'{data_folder}/before_finished/step_5/potential_actives.csv', sep=',', header=0)\n","potential_inactives = pd.read_csv(f'{data_folder}/before_finished/step_5/potential_inactives.csv', sep=',', header=0)"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["No problems detected\n"]},{"name":"stderr","output_type":"stream","text":["[07:34:51] WARNING: not removing hydrogen atom without neighbors\n","[07:35:47] WARNING: not removing hydrogen atom without neighbors\n"]},{"name":"stdout","output_type":"stream","text":["No problems detected\n"]}],"source":["problems_actives, cannot_parse_actives = filters.rdkit_parse(potential_actives, smi_col, cid_col)\n","problems_inactives, cannot_parse_inactives = filters.rdkit_parse(potential_inactives, smi_col, cid_col)"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["#Create a new step folder:\n","if not os.path.exists(f'{data_folder}/before_finished/step_6'):\n","    os.makedirs(f'{data_folder}/before_finished/step_6')\n","\n","with open(f'{data_folder}/before_finished/step_6/problem_list_actives.txt', 'w') as f:\n","    f.write(\"Problems:\\n\")\n","    for item in problems_actives:\n","        f.write(\"%s\\n\" % item)\n","    f.write(\"Cannot parse:\\n\")\n","    for item in cannot_parse_actives:\n","        f.write(\"%s\\n\" % item)\n","\n","with open(f'{data_folder}/before_finished/step_6/problem_list_inactives.txt', 'w') as f:\n","    f.write(\"Problems:\\n\")\n","    for item in problems_inactives:\n","        f.write(\"%s\\n\" % item)\n","    f.write(\"Cannot parse:\\n\")\n","    for item in cannot_parse_inactives:\n","        f.write(\"%s\\n\" % item)"]},{"cell_type":"markdown","metadata":{},"source":["Our dataset returned no problem or non-parsable molecule."]},{"cell_type":"markdown","metadata":{},"source":["# 7. Inorganics Filter"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Import data\n","potential_actives = pd.read_csv(f'{data_folder}/before_finished/step_5/potential_actives.csv', sep=',', header=0)\n","potential_inactives = pd.read_csv(f'{data_folder}/before_finished/step_5/potential_inactives.csv', sep=',', header=0)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Among actives, there are 287 organic molecules and 0 inorganic molecules\n"]},{"name":"stderr","output_type":"stream","text":["[08:00:04] WARNING: not removing hydrogen atom without neighbors\n","[08:00:04] WARNING: not removing hydrogen atom without neighbors\n","[08:00:56] WARNING: not removing hydrogen atom without neighbors\n","[08:00:56] WARNING: not removing hydrogen atom without neighbors\n"]},{"name":"stdout","output_type":"stream","text":["In inactives, there are 303926 organic molecules and 0 inorganic molecules\n"]}],"source":["inorganic_actives_cids, organic_actives_cids = filters.inorganic_filter(potential_actives, smi_col, cid_col, type='smiles')\n","print(f'Among actives, there are {len(organic_actives_cids)} organic molecules and {len(inorganic_actives_cids)} inorganic molecules')\n","\n","inorganic_inactives_cids, organic_inactives_cids = filters.inorganic_filter(potential_inactives, smi_col, cid_col, type='smiles')\n","print(f'In inactives, there are {len(organic_inactives_cids)} organic molecules and {len(inorganic_inactives_cids)} inorganic molecules')"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Dropped inorganic and saved organic compounds into step_7 folder.\n"]}],"source":["#Create a new step folder:\n","if not os.path.exists(f'{data_folder}/before_finished/step_7'):\n","    os.makedirs(f'{data_folder}/before_finished/step_7')\n","\n","with open(f'{data_folder}/before_finished/step_7/inorganic.txt', 'w') as f:\n","    f.write(\"Actives:\\n\")\n","    for item in inorganic_actives_cids:\n","        f.write(\"%s\\n\" % item)\n","    f.write(\"\\n\\nInactives:\\n\")\n","    for item in inorganic_inactives_cids:\n","        f.write(\"%s\\n\" % item)\n","\n","# Drop inorganics: \n","potential_actives = potential_actives[~potential_actives[cid_col].isin(inorganic_actives_cids)]\n","potential_inactives = potential_inactives[~potential_inactives[cid_col].isin(inorganic_inactives_cids)]\n","\n","#save: \n","potential_actives.to_csv(f'{data_folder}/before_finished/step_7/organic_actives.csv', index=False)\n","potential_inactives.to_csv(f'{data_folder}/before_finished/step_7/organic_inactives.csv', index=False)\n","\n","print('Dropped inorganic and saved organic compounds into step_7 folder.')"]},{"cell_type":"markdown","metadata":{},"source":["# 8. Mixtures Handling"]},{"cell_type":"markdown","metadata":{},"source":["## 8.1. Quick Check"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["#import: \n","organic_actives = pd.read_csv(f'{data_folder}/before_finished/step_7/organic_actives.csv', sep=',', header=0)\n","organic_inactives = pd.read_csv(f'{data_folder}/before_finished/step_7/organic_inactives.csv', sep=',', header=0)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of mixtures in actives is 5\n","Total number of mixtures in inactives is 11935\n"]}],"source":["filters.quick_check_mixtures('actives', organic_actives[smi_col])\n","filters.quick_check_mixtures('inactives', organic_inactives[smi_col])"]},{"cell_type":"markdown","metadata":{},"source":["## 8.2. Handling Mixtures"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Big organic molecule for CID 15944931 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891796 does not pass Lipinski's rule of five\n","Cannot decide between ['CC1=NC2=C(O1)C3=CC=CC=C3C=C2', 'C1=C(C=C(C(=C1[N+](=O)[O-])O)[N+](=O)[O-])[N+](=O)[O-]'] for CID 3241713\n","Big organic molecule for CID 11948854 does not pass Lipinski's rule of five\n","Cannot decide between ['CN(C)C1=NC2=C(CCC2)C(=C1)N', 'C1=C(C=NC=C1O)C(=O)O'] for CID 652177\n","Big organic molecule for CID 24892460 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24761675 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24816525 does not pass Lipinski's rule of five\n","Cannot decide between ['CN(C)C1=NC2=CC=CC=C2C(=C1)N', 'C1=C(NC(=O)NC1=O)C(=O)O'] for CID 646688\n","Cannot decide between ['CC1=NCCC2=C1NC3=CC=CC=C23', 'C1=C(C=C(C(=C1[N+](=O)[O-])O)[N+](=O)[O-])[N+](=O)[O-]'] for CID 135497979\n","Big organic molecule for CID 135691036 does not pass Lipinski's rule of five\n","Big organic molecule for CID 12004634 does not pass Lipinski's rule of five\n","Cannot decide between ['C1=CC=C2C=C(C=CC2=C1)S(=O)(=O)[O-]', 'C1=CC(=C[N+](=C1)CC(=O)NC2=CC=C(C=C2)Br)O'] for CID 16196732\n","Big organic molecule for CID 16682212 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24816523 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24816521 does not pass Lipinski's rule of five\n","Big organic molecule for CID 8566 does not pass Lipinski's rule of five\n","Big organic molecule for CID 3244813 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892713 does not pass Lipinski's rule of five\n","Big organic molecule for CID 135675926 does not pass Lipinski's rule of five\n","Big organic molecule for CID 12005524 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891784 does not pass Lipinski's rule of five\n","Big organic molecule for CID 14291980 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892602 does not pass Lipinski's rule of five\n","Big organic molecule for CID 11958904 does not pass Lipinski's rule of five\n","Cannot decide between ['CCCCC1=NC2=CC=CC=C2C(=C1CCC)N', 'C1=CC(=C(C=C1[N+](=O)[O-])C(=O)O)Cl'] for CID 6611006\n","Cannot decide between ['C1=NC2=NC=NC(=C2N1)N', 'OS(=O)(=O)O'] for CID 118738\n","Cannot decide between ['C(C1=NC(=NN1)N)O', 'C(C(=O)O)O'] for CID 222696\n","Big organic molecule for CID 15945399 does not pass Lipinski's rule of five\n","Big organic molecule for CID 60934 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891794 does not pass Lipinski's rule of five\n","Cannot decide between ['CN1C(=O)C2=C(N=C(N2)Cl)N(C1=O)C(=O)[O-]', 'CN(C)CCOC(C1=CC=CC=C1)C2=CC=CC=C2'] for CID 657227\n","Big organic molecule for CID 24891788 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891782 does not pass Lipinski's rule of five\n","Cannot decide between ['C1CN(CCN1CCOCCO)C(C2=CC=CC=C2)C3=CC=C(C=C3)Cl', 'C1=CC=C2C(=C1)C=C(C(=C2CC3=C(C(=CC4=CC=CC=C43)C(=O)O)O)O)C(=O)O'] for CID 25096\n","Big organic molecule for CID 24891760 does not pass Lipinski's rule of five\n","Big organic molecule for CID 15944995 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891822 does not pass Lipinski's rule of five\n","Big organic molecule for CID 16193567 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891804 does not pass Lipinski's rule of five\n","Big organic molecule for CID 11958671 does not pass Lipinski's rule of five\n","Cannot decide between ['CN1CCCN=C1/C=C/C2=CC=CS2', 'C(C(C(=O)O)O)(C(=O)O)O'] for CID 6419953\n","Cannot decide between ['C1CC1C(C2CC2)NC3=NCCO3', 'C(=C/C(=O)O)\\\\C(=O)O'] for CID 5388964\n","Big organic molecule for CID 9847786 does not pass Lipinski's rule of five\n","Big organic molecule for CID 15945589 does not pass Lipinski's rule of five\n","Big organic molecule for CID 5344271 does not pass Lipinski's rule of five\n","Cannot decide between ['CC1=CC=C(C=C1)S(=O)(=O)[O-]', 'CN1C=C[N+](=C1COC(=O)N(C)C)C'] for CID 15945791\n","Cannot decide between ['C1C2(CN3CN1CN(C2)C3)N', 'C1=CC(=CN=C1)C(=O)O'] for CID 648270\n","Cannot decide between ['CNC[C@@H](C1=CC(=C(C=C1)O)O)O', 'C(C(C(=O)O)O)(C(=O)O)O'] for CID 6852374\n","Cannot decide between ['C1=CC2=C(C3=C(C=C2)N=C(C=C3)N)N=C1', 'C1=C(C=C(C(=C1[N+](=O)[O-])O)[N+](=O)[O-])[N+](=O)[O-]'] for CID 23723893\n","Cannot decide between ['CC(=O)OCC[N+](C)(C)C', '[O-]Cl(=O)(=O)=O'] for CID 93565\n","Big organic molecule for CID 657180 does not pass Lipinski's rule of five\n","Cannot decide between ['CSC1=NC=C(C(=N1)C(=O)[O-])Cl', 'C1=CC=C(C=C1)CC[NH3+]'] for CID 9552033\n","Big organic molecule for CID 24892288 does not pass Lipinski's rule of five\n","Cannot decide between ['C1CCC(C(C1)N)N', 'Cl[Pt]Cl'] for CID 151689\n","Cannot decide between ['CN1CCC2=C(C3=CC=CC=C3N=C21)N', 'C1=CC(=C(C=C1[N+](=O)[O-])C(=O)O)Cl'] for CID 23724359\n","Big organic molecule for CID 24891800 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24982687 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24981418 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891778 does not pass Lipinski's rule of five\n","Big organic molecule for CID 135712454 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891808 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892325 does not pass Lipinski's rule of five\n","Cannot decide between ['CC[N+](C)(C)CC1=CC=CC=C1Br', 'CC1=CC=C(C=C1)S(=O)(=O)[O-]'] for CID 6100\n","Big organic molecule for CID 24892327 does not pass Lipinski's rule of five\n","Cannot decide between ['CC1=C(SC=C1)/C=C/C2=NCCCN2C', 'C(C(C(=O)O)O)(C(=O)O)O'] for CID 6419965\n","Big organic molecule for CID 15945076 does not pass Lipinski's rule of five\n","Big organic molecule for CID 16396156 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891776 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891766 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891786 does not pass Lipinski's rule of five\n","Cannot decide between ['CCN(CC)C(=O)N1CCN(CC1)C', 'C(C(=O)O)C(CC(=O)O)(C(=O)O)O'] for CID 15432\n","Big organic molecule for CID 24892699 does not pass Lipinski's rule of five\n","Big organic molecule for CID 135517121 does not pass Lipinski's rule of five\n","Big organic molecule for CID 12005684 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892299 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24982711 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892333 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891770 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891764 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892552 does not pass Lipinski's rule of five\n","Big organic molecule for CID 15944745 does not pass Lipinski's rule of five\n","Cannot decide between ['CNC1=C2CCCCC2=NN1C', 'C(=C\\\\C(=O)O)\\\\C(=O)O'] for CID 6450249\n","Big organic molecule for CID 135490316 does not pass Lipinski's rule of five\n","Big organic molecule for CID 135501964 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892442 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24816488 does not pass Lipinski's rule of five\n","Cannot decide between ['C1=CC=C(C=C1)OC2=CC=NC=C2', 'C1=C(C=C(C(=C1[N+](=O)[O-])O)[N+](=O)[O-])[N+](=O)[O-]'] for CID 23723127\n","Big organic molecule for CID 135512395 does not pass Lipinski's rule of five\n","Cannot decide between ['C1=CC=C(C=C1)CCNN', 'OS(=O)(=O)O'] for CID 61100\n","Cannot decide between ['CCC(C1=NC(CC2=CC=CC=C21)(C)C)C(=O)OCC', 'C1=C(C=C(C(=C1[N+](=O)[O-])O)[N+](=O)[O-])[N+](=O)[O-]'] for CID 16192930\n","Big organic molecule for CID 24892697 does not pass Lipinski's rule of five\n","Cannot decide between ['CC(C)NC[C@H](C1=CC(=C(C=C1)O)O)O', 'C(C(C(=O)O)O)(C(=O)O)O'] for CID 6852409\n","Big organic molecule for CID 24892440 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892464 does not pass Lipinski's rule of five\n","Big organic molecule for CID 23723054 does not pass Lipinski's rule of five\n","Big organic molecule for CID 16193495 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892292 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891762 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892599 does not pass Lipinski's rule of five\n","Big organic molecule for CID 15944957 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892438 does not pass Lipinski's rule of five\n","Cannot decide between ['CC1=CC=C(C=C1)S(=O)(=O)[O-]', 'CN1C=C[N+](=C1CCOC(=O)N(C)C)C'] for CID 15945641\n","Cannot decide between ['CC1=NC(CC2=CC=CC=C12)(C)C', 'C1=CC=C(C(=C1)C(=O)O)O'] for CID 9549466\n","Big organic molecule for CID 15945428 does not pass Lipinski's rule of five\n","Cannot decide between ['C[N+](C)(CCOC1=CC=CC=C1)CC2=CC=CC=C2', 'C1=CC=C2C(=C1)C=C(C(=C2Br)[O-])C(=O)O'] for CID 54732065\n","Cannot decide between ['CC1=CC=C(C=C1)S(=O)(=O)[O-]', 'C1=CC2=C(C3=C(C=CC=N3)C=C2)[NH+]=C1'] for CID 16196049\n","Cannot decide between ['CC(=C)[C@@H]1[C@@H]2[C@@H]3[C@@]4([C@]([C@H]1C(=O)O2)(C[C@@H]5[C@]4(O5)C(=O)O3)O)C', 'C[C@@]12[C@H]3[C@H]4[C@H]([C@@H]([C@@]1(C[C@@H]5[C@]2(O5)C(=O)O3)O)C(=O)O4)C(C)(C)O'] for CID 6473767\n","Big organic molecule for CID 16745857 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892532 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891774 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891812 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892280 does not pass Lipinski's rule of five\n"]},{"name":"stderr","output_type":"stream","text":["[08:52:39] WARNING: not removing hydrogen atom without neighbors\n","[08:52:39] WARNING: not removing hydrogen atom without neighbors\n"]},{"name":"stdout","output_type":"stream","text":["Big organic molecule for CID 23640915 does not pass Lipinski's rule of five\n","Big organic molecule for CID 56642840 does not pass Lipinski's rule of five\n","Big organic molecule for CID 5284439 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892536 does not pass Lipinski's rule of five\n","Cannot decide between ['CCCC1=NCCN2C1=CC=C2', 'C(=C/C(=O)O)\\\\C(=O)O'] for CID 5717182\n","Big organic molecule for CID 24982214 does not pass Lipinski's rule of five\n","Cannot decide between ['C(CS)N', 'Cl'] for CID 9082\n","Big organic molecule for CID 14219807 does not pass Lipinski's rule of five\n","Big organic molecule for CID 135433258 does not pass Lipinski's rule of five\n","Big organic molecule for CID 62881 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892538 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24816519 does not pass Lipinski's rule of five\n","Cannot decide between ['CC1=CC(=C(C=N1)C)C2=CC=CC3=CC=CC=C32', 'C1=C(C=C(C(=C1[N+](=O)[O-])O)[N+](=O)[O-])[N+](=O)[O-]'] for CID 16192548\n","Big organic molecule for CID 24892341 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892466 does not pass Lipinski's rule of five\n","Big organic molecule for CID 16240588 does not pass Lipinski's rule of five\n","Big organic molecule for CID 12005677 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891814 does not pass Lipinski's rule of five\n","Big organic molecule for CID 16193568 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24816492 does not pass Lipinski's rule of five\n","Cannot decide between ['C1CCC2=C(C1)C(=C3CCCCC3=N2)N', 'C1=CNC(=O)C=C1C(=O)O'] for CID 23724223\n","Big organic molecule for CID 24891874 does not pass Lipinski's rule of five\n","Big organic molecule for CID 16193570 does not pass Lipinski's rule of five\n","Big organic molecule for CID 11948864 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24982679 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891886 does not pass Lipinski's rule of five\n","Big organic molecule for CID 16219016 does not pass Lipinski's rule of five\n","Big organic molecule for CID 14219810 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892468 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891880 does not pass Lipinski's rule of five\n","Big organic molecule for CID 5284352 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892293 does not pass Lipinski's rule of five\n","Big organic molecule for CID 9551917 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892529 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891772 does not pass Lipinski's rule of five\n","Big organic molecule for CID 5729990 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891836 does not pass Lipinski's rule of five\n","Big organic molecule for CID 16219228 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891818 does not pass Lipinski's rule of five\n","Big organic molecule for CID 444034 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891802 does not pass Lipinski's rule of five\n","Big organic molecule for CID 15944844 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892478 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891816 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891798 does not pass Lipinski's rule of five\n","Big organic molecule for CID 9549634 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891792 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892454 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892462 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892474 does not pass Lipinski's rule of five\n"]},{"name":"stderr","output_type":"stream","text":["[08:52:42] WARNING: not removing hydrogen atom without neighbors\n","[08:52:42] WARNING: not removing hydrogen atom without neighbors\n"]},{"name":"stdout","output_type":"stream","text":["Big organic molecule for CID 6420009 does not pass Lipinski's rule of five\n","Big organic molecule for CID 5718631 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892534 does not pass Lipinski's rule of five\n","Big organic molecule for CID 64142 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891806 does not pass Lipinski's rule of five\n","Big organic molecule for CID 3005572 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891790 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891820 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892470 does not pass Lipinski's rule of five\n","Big organic molecule for CID 12005527 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892527 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24981434 does not pass Lipinski's rule of five\n","Big organic molecule for CID 9549148 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892472 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891868 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891838 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891824 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892525 does not pass Lipinski's rule of five\n","Big organic molecule for CID 9896684 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891780 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891768 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24891810 does not pass Lipinski's rule of five\n","Big organic molecule for CID 3033832 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24816489 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24892636 does not pass Lipinski's rule of five\n","Big organic molecule for CID 2733525 does not pass Lipinski's rule of five\n","Big organic molecule for CID 24816490 does not pass Lipinski's rule of five\n","Big organic molecule for CID 9549642 does not pass Lipinski's rule of five\n","Big organic molecule for CID 10864994 does not pass Lipinski's rule of five\n"]}],"source":["processed_actives, removed_actives, small_organic_actives, small_inorganic_actives, not_lipinski_actives, cleaned_actives = filters.process_smi_mixtures(organic_actives, smi_col, cid_col)\n","processed_inactives, removed_inactives, small_organic_inactives, small_inorganic_inactives, not_lipinski_inactives, cleaned_inactives = filters.process_smi_mixtures(organic_inactives, smi_col, cid_col)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Create a new step folder\n","if not os.path.exists(f'{data_folder}/before_finished/step_8'):\n","    os.makedirs(f'{data_folder}/before_finished/step_8')\n","\n","#Generate df with the smiles column in the cleaned_actives or cleaned_inactives dictionary:\n","cleaned_actives_df = pd.DataFrame(list(cleaned_actives.values()), columns=[smi_col])\n","cleaned_inactives_df = pd.DataFrame(list(cleaned_inactives.values()), columns=[smi_col])\n","\n","#Export the cleaned hits and inactives to csv:\n","cleaned_actives_df.to_csv(f'{data_folder}/before_finished/step_8/cleaned_mixtures_actives.csv', index=False, header=False)\n","cleaned_inactives_df.to_csv(f'{data_folder}/before_finished/step_8/cleaned_mixtures_inactives.csv', index=False, header=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["processed_hits_df = filters.process_mixture_df('actives_KCNQ2_Potassium_Channel', organic_actives, processed_actives, removed_actives, small_organic_actives, small_inorganic_actives, smi_col, cid_col)\n","processed_inactives_df = filters.process_mixture_df('inactives_KCNQ2_Potassium_Channel', organic_inactives, processed_inactives, removed_inactives, small_organic_inactives, small_inorganic_inactives, smi_col, cid_col)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataframes saved successfully\n"]}],"source":["with open(f'{data_folder}/before_finished/step_8/mixture.txt', 'w') as f:\n","    f.write(f\"\"\"\n","Hits before processing: {len(organic_actives)}\n","Hits before processing: {len(organic_actives)}\n","Hits after processing: {len(processed_hits_df)}\n","Mixtures detected: {len(removed_actives)}\n","Mixtures with small inorganic molecules: {len(small_inorganic_actives)}\n","Mixtures with big organic molecules passing Lipinski: {len(small_organic_actives)}\n","Mixtures with big organic molecules not passing Lipinski: {len(not_lipinski_actives)}\n","\n","Inactives before processing: {len(organic_inactives)}\n","Inactives after processing: {len(processed_inactives_df)}\n","Mixtures detected: {len(removed_inactives)}\n","Mixtures with small inorganic molecules: {len(small_inorganic_inactives)}\n","Mixtures with big organic molecules passing Lipinski: {len(small_organic_inactives)}\n","Mixtures with big organic molecules not passing Lipinski: {len(not_lipinski_inactives)}\n","\"\"\")\n","\n","# Save the processed dataframes to csv\n","processed_hits_df.to_csv(f'{data_folder}/before_finished/step_8/post8_actives.csv', index=False)\n","processed_inactives_df.to_csv(f'{data_folder}/before_finished/step_8/post8_inactives.csv', index=False)\n","\n","print('Dataframes saved successfully')"]},{"cell_type":"markdown","metadata":{},"source":["# 9. Neutralize & 10. Aromatize Molecules"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Create a new step folder:\n","if not os.path.exists(f'{data_folder}/before_finished/step_9_10'):\n","    os.makedirs(f'{data_folder}/before_finished/step_9_10')\n","\n","#import:\n","pre9_actives = pd.read_csv(f'{data_folder}/before_finished/step_8/post8_actives.csv', sep=',', header=0)\n","pre9_inactives = pd.read_csv(f'{data_folder}/before_finished/step_8/post8_inactives.csv', sep=',', header=0)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["updated_smi = []\n","\n","#Update dataset with neutralized, aromatic SMILES\n","for smi in pre9_actives[smi_col]: \n","    mol = Chem.MolFromSmiles(smi)\n","    mol_neu = utils.neutralize_atoms(mol)\n","    smi_arom = utils.aromatize_smile(mol_neu)\n","    updated_smi.append(smi_arom)\n","    \n","#update the smiles in this df\n","pre9_actives[smi_col] = updated_smi"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["updated_smi = []\n","\n","#Update dataset with neutralized, aromatic SMILES\n","for smi in pre9_inactives[smi_col]: \n","    mol = Chem.MolFromSmiles(smi)\n","    mol_neu = utils.neutralize_atoms(mol)\n","    smi_arom = utils.aromatize_smile(mol_neu)\n","    updated_smi.append(smi_arom)\n","\n","#update the smiles in this df\n","pre9_inactives[smi_col] = updated_smi"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["#Save\n","pre9_actives.to_csv(f'{data_folder}/before_finished/step_9_10/post10_actives.csv', index=False)\n","pre9_inactives.to_csv(f'{data_folder}/before_finished/step_9_10/post10_inactives.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Post 9+10: Update InChIs"]},{"cell_type":"markdown","metadata":{},"source":["Is it important to now update InChI in our datasets, for 2 reasons:\n","\n","(1) Some mixture compounds have been modified (removal of small inorganic or organic molecules) in SMILES representation but not InChIs.\n","\n","(2) The SMILES representations have been neutralized and aromatized, but not InChIs."]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["#export the smiles columns to txt\n","pre9_actives[smi_col].to_csv(f'{data_folder}/before_finished/step_9_10/smiles_actives.txt', index=False, header=False)\n","pre9_inactives[smi_col].to_csv(f'{data_folder}/before_finished/step_9_10/smiles_inactives.txt', index=False, header=False)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["\"\"\"\n","Submit the smiles files to PubChem Identifier Exchange Service: \n","    Input IDs: \"SMILES\"\n","    Operator type: \"same CID\" \n","    Output IDs: \"InChI\"\n","    Output method: \"Two column file showing each input output-correspondence\"\n","    Compression: \"No compression\"\n","InChI list should be saved into \"step_9_10\" folder, named as \"inchi_actives.txt\" and \"inchi_inactives\" \n","\"\"\"\n","#Import the converted InChIs\n","cleaned_inchi_hits = pd.read_csv(f'{data_folder}/before_finished/step_9_10/inchi_actives.txt', sep='\\t', header=None)\n","cleaned_inchi_inactives = pd.read_csv(f'{data_folder}/before_finished/step_9_10/inchi_inactives.txt', sep='\\t', header=None)\n","\n","#a dictionary of smiles and corresponding inchi in cleaned_inchi_hits\n","hits_smi_inchi_dict = dict(zip(cleaned_inchi_hits[0], cleaned_inchi_hits[1]))\n","inactives_smi_inchi_dict = dict(zip(cleaned_inchi_inactives[0], cleaned_inchi_inactives[1]))\n","                             \n","#update the pre9_hits by matching the smiles with keys and replace inchi with values:\n","pre9_actives['InChI'] = pre9_actives[smi_col].map(hits_smi_inchi_dict) \n","pre9_inactives['InChI'] = pre9_inactives[smi_col].map(inactives_smi_inchi_dict)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["#export: \n","pre9_actives.to_csv(f'{data_folder}/before_finished/step_9_10/post10_actives.csv', index=False)\n","pre9_inactives.to_csv(f'{data_folder}/before_finished/step_9_10/post10_inactives.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# 11. PAIN Filters"]},{"cell_type":"markdown","metadata":{},"source":["## 11.1. Frequency of Hits (FoH) Filter"]},{"cell_type":"markdown","metadata":{},"source":["Frequency of Hits is a complex concept that requires a merticulous approach. In general, the rule is if a compound was tested active in multiple assays, it is likely to be a promiscuous compound.\n","1. For each compounds, retrieve the information on its tested assays\n","2. For each of the assay tested, retrieve the sequence of the protein target.\n","3. Given all sequence of the protein tested, do a multiple sequence alignment to find the percentage Percent Identity (similarty) between these proteins. If an assay has high percentage to other targets, then these assays contribute less to promiscuousity of the compound.\n","4. Use the percentage identity as a weight:\n","w = 1 - %SI/100\n","Calculate the frequency of hits for each compound:\n","FoH = wACC/TAC\n","wACC is the weighed total number of assay tested where the compounds were identified acitives. TAC is the total number of assays tested."]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["pre11_actives = pd.read_csv(f'{data_folder}/before_finished/step_9_10/post10_actives.csv', sep=',', header=0)\n","pre11_inactives = pd.read_csv(f'{data_folder}/before_finished/step_9_10/post10_inactives.csv', sep=',', header=0)\n","\n","# Create a new step folder:\n","if not os.path.exists(f'{data_folder}/before_finished/step_11/11_1'):\n","    os.makedirs(f'{data_folder}/before_finished/step_11/11_1')"]},{"cell_type":"markdown","metadata":{},"source":["### 11.1.1. PubChem testing information for each compound"]},{"cell_type":"markdown","metadata":{},"source":["This part illustrates how to retrieve the information of how each compound was tested from the PubChem database. Bulk data retrieval from the ftp server is used to get the information of every bioassay in PubChem:"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloaded to S:\\coding\\WelQrate\\pubchem_sum\\bioassays.tsv.gz\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\dongn\\AppData\\Local\\Temp\\ipykernel_35608\\1796722102.py:18: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n","  all_bioassay = pd.read_csv(path, delimiter='\\t')\n"]}],"source":["url = 'https://ftp.ncbi.nlm.nih.gov/pubchem/Bioassay/Extras/bioassays.tsv.gz' #this FTP file records the summary data of all available AIDs in PubChem\n","\n","local_save_dir = 'S:\\coding\\WelQrate\\pubchem_sum'\n","local_save_path = os.path.join(local_save_dir, 'bioassays.tsv.gz')\n","\n","if not os.path.exists(local_save_dir):\n","    os.makedirs(local_save_dir)\n","r = requests.get(url, stream=True)\n","\n","with open(local_save_path, 'wb') as f:\n","    for chunk in r.iter_content(chunk_size=8192):\n","        f.write(chunk)\n","print('Downloaded to %s' % local_save_path)\n","\n","path = 'pubchem_sum/bioassays.tsv.gz'\n","\n","# Read the TSV file\n","all_bioassay = pd.read_csv(path, delimiter='\\t')"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>AID</th>\n","      <th>BioAssay Name</th>\n","      <th>Deposit Date</th>\n","      <th>Modify Date</th>\n","      <th>Source Name</th>\n","      <th>Source ID</th>\n","      <th>Substance Type</th>\n","      <th>Outcome Type</th>\n","      <th>Project Category</th>\n","      <th>BioAssay Group</th>\n","      <th>BioAssay Types</th>\n","      <th>Protein Accessions</th>\n","      <th>UniProts IDs</th>\n","      <th>Gene IDs</th>\n","      <th>Target TaxIDs</th>\n","      <th>Taxonomy IDs</th>\n","      <th>Number of Tested SIDs</th>\n","      <th>Number of Active SIDs</th>\n","      <th>Number of Tested CIDs</th>\n","      <th>Number of Active CIDs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>20040815</td>\n","      <td>20240410</td>\n","      <td>DTP/NCI</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>small-molecule</td>\n","      <td>Confirmatory</td>\n","      <td>Other</td>\n","      <td>NCI-60_DOSERESP</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>55228</td>\n","      <td>3318</td>\n","      <td>53214</td>\n","      <td>3094</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>20040815</td>\n","      <td>20240410</td>\n","      <td>DTP/NCI</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>small-molecule</td>\n","      <td>Confirmatory</td>\n","      <td>Other</td>\n","      <td>NCI-60_DOSERESP</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>51435</td>\n","      <td>2615</td>\n","      <td>49564</td>\n","      <td>2467</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>20040815</td>\n","      <td>20240410</td>\n","      <td>DTP/NCI</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>small-molecule</td>\n","      <td>Confirmatory</td>\n","      <td>Other</td>\n","      <td>NCI-60_DOSERESP</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>54079</td>\n","      <td>2503</td>\n","      <td>52046</td>\n","      <td>2317</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>20040815</td>\n","      <td>20240410</td>\n","      <td>DTP/NCI</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>small-molecule</td>\n","      <td>Confirmatory</td>\n","      <td>Other</td>\n","      <td>NCI-60_DOSERESP</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>54062</td>\n","      <td>4335</td>\n","      <td>52033</td>\n","      <td>4098</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>20040815</td>\n","      <td>20240410</td>\n","      <td>DTP/NCI</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>small-molecule</td>\n","      <td>Confirmatory</td>\n","      <td>Other</td>\n","      <td>NCI-60_DOSERESP</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>53977</td>\n","      <td>3159</td>\n","      <td>52001</td>\n","      <td>2981</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   AID                                      BioAssay Name  Deposit Date  \\\n","0    1  NCI human tumor cell line growth inhibition as...      20040815   \n","1    3  NCI human tumor cell line growth inhibition as...      20040815   \n","2    5  NCI human tumor cell line growth inhibition as...      20040815   \n","3    7  NCI human tumor cell line growth inhibition as...      20040815   \n","4    9  NCI human tumor cell line growth inhibition as...      20040815   \n","\n","   Modify Date Source Name                                          Source ID  \\\n","0     20240410     DTP/NCI  NCI human tumor cell line growth inhibition as...   \n","1     20240410     DTP/NCI  NCI human tumor cell line growth inhibition as...   \n","2     20240410     DTP/NCI  NCI human tumor cell line growth inhibition as...   \n","3     20240410     DTP/NCI  NCI human tumor cell line growth inhibition as...   \n","4     20240410     DTP/NCI  NCI human tumor cell line growth inhibition as...   \n","\n","   Substance Type  Outcome Type Project Category   BioAssay Group  \\\n","0  small-molecule  Confirmatory            Other  NCI-60_DOSERESP   \n","1  small-molecule  Confirmatory            Other  NCI-60_DOSERESP   \n","2  small-molecule  Confirmatory            Other  NCI-60_DOSERESP   \n","3  small-molecule  Confirmatory            Other  NCI-60_DOSERESP   \n","4  small-molecule  Confirmatory            Other  NCI-60_DOSERESP   \n","\n","  BioAssay Types Protein Accessions UniProts IDs Gene IDs  Target TaxIDs  \\\n","0            NaN                NaN          NaN      NaN            NaN   \n","1            NaN                NaN          NaN      NaN            NaN   \n","2            NaN                NaN          NaN      NaN            NaN   \n","3            NaN                NaN          NaN      NaN            NaN   \n","4            NaN                NaN          NaN      NaN            NaN   \n","\n","  Taxonomy IDs  Number of Tested SIDs  Number of Active SIDs  \\\n","0          NaN                  55228                   3318   \n","1          NaN                  51435                   2615   \n","2          NaN                  54079                   2503   \n","3          NaN                  54062                   4335   \n","4          NaN                  53977                   3159   \n","\n","   Number of Tested CIDs  Number of Active CIDs  \n","0                  53214                   3094  \n","1                  49564                   2467  \n","2                  52046                   2317  \n","3                  52033                   4098  \n","4                  52001                   2981  "]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["all_bioassay.head()"]},{"cell_type":"markdown","metadata":{},"source":["### 11.1.2 Retrieving protein sequences for assays tested:"]},{"cell_type":"markdown","metadata":{},"source":["Then, the testing information for each compound is retrieved from the PugREST API"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["# Cache to store the number of compounds tested per AID to avoid redundant call. \n","num_compounds_tested_cache = {}\n","\n","def get_num_compounds_tested(aid, all_bioassay=all_bioassay):\n","    \"\"\"\n","    This function retrieves the information of how many compounds were tested in a given assay (by AID).\n","    \"\"\"\n","    if aid in num_compounds_tested_cache:\n","        return num_compounds_tested_cache[aid]\n","    else: \n","        #return the 'Number of Tested CIDs' column value at the row where the 'AID' column is equal to aid in the all_bioassay dataframe\n","        num_compounds_tested = all_bioassay[all_bioassay['AID'] == aid]['Number of Tested CIDs'].values[0]\n","    return num_compounds_tested\n","\n","def get_assay_data(cid):\n","    \"\"\"\n","    Return a dictionary of all targets that a given compound (by CID) was tested on in PubChem \n","    and the activity values of the compound. \n","    \"\"\"\n","    url = f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/{cid}/assaysummary/JSON\" #PUG-REST compound summary by CID\n","    response = requests.get(url)\n","    data = response.json()\n","\n","    target_activity = {}\n","\n","    if 'Table' in data and 'Row' in data['Table']:\n","        for row in data['Table']['Row']:\n","            cells = row['Cell']\n","            aid = int(cells[0])  # Extracting the AID from the first cell\n","\n","            # Proceed only if the assay is a screening assay\n","            if cells[10] == 'Screening':\n","\n","                # Proceed only if more than 10,000 compounds were tested\n","                num_compounds_tested = get_num_compounds_tested(aid)\n","                if num_compounds_tested > 10000:\n","                    target_gi = cells[5] # Retrieve the protein target's GI\n","                    activity_outcome = cells[4].lower()\n","\n","                    if target_gi not in target_activity:\n","                        target_activity[target_gi] = activity_outcome == 'active'\n","                    elif activity_outcome == 'active':\n","                        target_activity[target_gi] = True # If a compound was tested multiple times on the same protein, priotize \"active\" outcome.\n","            \n","            else:\n","                continue\n","\n","    return (cid, target_activity)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing CIDs: 100%|██████████| 287/287 [03:02<00:00,  1.58it/s]\n"]}],"source":["import requests\n","from concurrent.futures import ThreadPoolExecutor, as_completed\n","from tqdm import tqdm\n","\n","cids_list = pre11_actives[cid_col].tolist()\n","\n","def execute_with_multiprocessing(cids_list):\n","    \"\"\"\n","    For a given list of CIDs, return a dictionary of dictionaries \n","    of protein targets these compounds were tested on and the activity outcomes\n","    Input: \n","        [list of CIDs]\n","    Output: \n","        Dictionary of testing information for all CIDs, such as:\n","        {CID1:{target1:activity1, target3:activity3, ...},{CID2:{target2:activity2, target4:activity4, ...}, ...}}\n","    \"\"\"\n","    results_dict = {}\n","    with ThreadPoolExecutor(max_workers=10) as executor:\n","        # Prepare futures for all CIDs\n","        futures = [executor.submit(get_assay_data, cid) for cid in cids_list]\n","        \n","        # Process futures as they complete\n","        for future in tqdm(as_completed(futures), total=len(cids_list), desc=\"Processing CIDs\"):\n","            try:\n","                cid, target_activity = future.result()\n","                results_dict[cid] = target_activity\n","            except Exception as e:\n","                print(f\"Error processing CID: {e}\")\n","    return results_dict\n","\n","results_dict = execute_with_multiprocessing(cids_list)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["#export results_dict\n","with open(f'{data_folder}/before_finished/step_11/11_1/results_dict.json', 'w') as f:\n","    json.dump(results_dict, f)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['296434520', '54112432', '14719829', '6708281', '13027636', '16130689', '224028257', '5729858', '433552101', '47132611', '216548193', '9629363', '34330186', '21489979', '4758208', '1762973', '190938', '4506055', '881546', '1302091', '166202459', '2702319', '56790945', '55584151', '9937384', '14389423', '167013344', '21595511', '134304838', '14149746', '4507615', '110611243', '4505447', '42794767', '47132585', '37622910', '52426748', '74315350', '62362414', '28949057', '21361095', '15609874', '2501205', '73745819', '4826834', '10835145', '929524245', '139424501', '62740231', '6831552', '7582271', '23893623', '998701', '16306916', '166209887', '4507593', '119607128', '28373018', '2578455', '16130726', '124486680', '171229', '76364066', '4506243', '119607129', '83699673', '187960042', '42741659', '38174238', '4507681', '1575471', '56417702', '4757950', '155969707', '88702791', '113121', '4503219', '285809906', '223468676', '148745659', '56786138', '4504843', '45269145', '63477962', '71746704', '38258652', '32479527', '49574532', '40254439', '32307126', '55958172', '13699818', '15680217', '67191027', '126642418', '118341367', '16130724', '6166485', '15610945', '153217451', '115529463', '730163', '17391426', '11141885', '48145933', '63102437', '23510348', '13236497', '116734717', '154146191', '47678551', '4503907', '4503779', '27368096', '7108336', '15610601', '20070193', '2498404', '487738', '89348172', '38027923', '22538455', '147728', '124376142', '21464101', '46909587', '74355113', '55956923', '27807367', '41872583', '5730106', '223460826', '27894344', '187952397', '1709543', '224494019', '11528014', '2358024', '40807040', '56202836', '24119166', '4505209', '124513266', '216409728', '223459640', '109637798', '13272532', '1679362728', '28373962', '115496662', '578162', '528078313', '10190672', '21315078', '31542303', '119622516', '124263658', '13124881', '160877737', '120997', '597517265', '116516899', '15645703', '7657550', '31881630', '27753985', '4826706', '12830367', '62868213', '301171662', '5174513', '7108463', '1111959238', '34577122', '253722402', '222080095', '378544807', '270133071', '38156699', '32400300', '120538355', '12644416', '5032039', '231632', '119579178', '11093520', '67463989', '317373446', '49168602', '116907', '4758484', '119603173', '15929025', '4503351', '16128424', '62203298', '225543099', '312275222', '1781172', '180352', '119579215', '47496637', '46577642', '41872631', '31563518', '21595776', '47123300', '88501734', '2853980', '118764400', '21392848', '21264324', '510901', '156416009', '68565218', '156104889', '83779224', '13399304', '1166512', '4506113', '68476498', '1246761', '32400299', '71987181', '23505220', '19860819', '112822', '3183518', '218931251', '121945198', '398366139', '780303193', '13325293', '37589898', '62526033', '76496497', '168184763', '1797100823', '10835013', '116076351', '148378801', '5016090', '15927174', '13177715', '124487323', '597517618', '262118306', '38788193', '4758204', '68474550', '130375', '11275980', '4507793', '119580345', '342179211', '23110962', '78486550', '9966877', '60391226', '48255881', '1927', '499328', '48146199', '86301151', '160707929', '81899072', '1730321', '194068499', '4502331', '7657508', '116077694', '4757840', '53832009', '115347926', '6978787', '6323930', '15610807', '89993689', '83318444', '4507791', '139472804', '14790033', '1708272', '4506537', '21327705', '15646160', '70832125', '1782953264', '1654220559', '75495260', '12381848', '124809506', '1572493', '78070770', '55960760', '32425330', '219518789', '21361340', '117940060', '20336229', '8574038', '493539358', '195969650', '194306653', '55662034', '116292172', '302699239', '37187860', '2393947', '10092597', '15610402', '124809271', '54112388', '73586699', '4502495', '257380', '160333370', '111305821', '67463988', '19923198', '16130723', '59036749', '25148072', '148539876', '7381449', '109633019', '85666113', '12803275', '4502169', '296080766', '6912644', '164058', '2507196', '11094021', '30219', '20072248', '83627717', '16878311', '536029', '14790119', '994798', '5453722', '48428097', '29788785', '4504343', '1937369734', '134142337', '1655766739', '21955158', '22035600', '68565074', '7706135', '89191863', '6755076', '21359873', '20336315', '151101270', '27597073', '4885057', '126698238', '86990435', '1237937630', '1628587', '46367787', '10864009', '735367775', '218891639', '115430235', '6016094', '7706645', '23943882', '68989256', '4503383', '10567816', '15607504', '111034851', '6680530', '74734243', '341916350', '23893668', '486173', '6009644', '13128862', '534286618', '2935630', '4758878', '291463269', '90111653', '1519312078', '351542238', '6325022', '9955963', '9629361', '613504304', '6679827', '90652859', '74752344', '125541954', '15675770', '90421313', '17507875', '119508433', '285814664', '83758679', '216548487', '4581413', '2182777540', '55976631', '38349113', '74356043', '149631', '5454102', '4505445', '6274552', '7669492', '62201602', '339641', '4503155', '32307152', '82503229', '4502003', '4503385', '134244587', '73747889']\n","Require multiple sequencing alignment for 424 proteins.\n"]}],"source":["#import results_dict:\n","with open(f'{data_folder}/before_finished/step_11/11_1/results_dict.json', 'r') as f:\n","    results_dict = json.load(f)\n","\n","#get the list of all keys of the values in the dictionary:\n","protein_ids = []\n","for value in results_dict.values():\n","    protein_ids.extend(value.keys())\n","\n","#clean the list\n","protein_ids = list(set(protein_ids))\n","protein_ids = [id for id in protein_ids if id != '']\n","\n","print(protein_ids)\n","print(f'Require multiple sequencing alignment for {len(protein_ids)} proteins.')"]},{"cell_type":"markdown","metadata":{},"source":["Now we retrieve all the FASTA sequences of proteins tested for all of our compounds with Biopython API to Entrez of NCBI. The FASTA sequence is saved as \"sequences.fasta\""]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["# Always tell NCBI who you are\n","Entrez.email = \"hdong26@amherst.edu\"\n","\n","# The filename where you want to save the sequences\n","output_filename = f'{data_folder}/before_finished/step_11/11_1/sequences.fasta'\n","\n","# Open a file to write the sequences\n","with open(output_filename, \"w\") as output_file:\n","    for id in protein_ids:\n","        try:\n","            # Fetch the sequence from NCBI\n","            handle = Entrez.efetch(db=\"protein\", id=id, rettype=\"fasta\", retmode=\"text\")\n","            sequence_data = handle.read()\n","            handle.close()\n","            \n","            # Write the sequence data to the file\n","            output_file.write(sequence_data)\n","        except Exception as e:\n","            print(f\"An error occurred while fetching {id}: {e}\")"]},{"cell_type":"markdown","metadata":{},"source":["From the FASTA sequence, we also need to retrieve the list of protein names, since these are different from the protein GIs."]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["def extract_protein_names(file_path):\n","    protein_names = []\n","    with open(file_path, 'r') as file:\n","        for line in file:\n","            if line.startswith('>'):\n","                # Split the line at spaces and take the first item\n","                parts = line.split(' ')\n","                protein_name = parts[0]\n","                # Remove the leading '>' character\n","                protein_name = protein_name[1:]\n","                protein_names.append(protein_name)\n","    return protein_names\n","\n","file_path = f'{data_folder}/before_finished/step_11/11_1/sequences.fasta'\n","protein_names = extract_protein_names(file_path)\n","\n","# Create a dictionary to map protein IDs to protein names by index \n","protein_id_to_name = {protein_ids[i]: protein_names[i] for i in range(len(protein_ids))}"]},{"cell_type":"markdown","metadata":{},"source":["### 11.1.3. Percent Sequence Identity by Multiple Sequence Alignment"]},{"cell_type":"markdown","metadata":{},"source":["The sequences.fasta file is submitted to https://www.ebi.ac.uk/jdispatcher/msa/clustalo for multiple sequencing alignment. The resulted table of percent sequence identity matrix is saved and imported for the calculation of FoH"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["\"\"\"\n","Submit sequences.fasta to https://www.ebi.ac.uk/jdispatcher/msa/clustalo\n","    Input sequence type: Protein\n","    Output format: ClustalW with character counts\n","Download the resulted Percent Identity Matrix file file and save as \"percent_identity_matrix.txt\"\n","\"\"\"\n","\n","#import the identity matrix:\n","protein_si = pd.read_csv(\n","    f'{data_folder}/before_finished/step_11/11_1/percent_identity_matrix.txt',\n","    delimiter='\\s+',\n","    header=None,\n","    skiprows=6 \n",")"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["#remove the first column:\n","protein_si = protein_si.drop(protein_si.columns[0], axis=1)\n","\n","name = protein_si[1].tolist()\n","name = ['protein name'] + name\n","protein_si.columns = name"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>protein name</th>\n","      <th>ABM97548.1</th>\n","      <th>NP_004986.1</th>\n","      <th>NP_001725.1</th>\n","      <th>NP_001123617.1</th>\n","      <th>AAC63054.1</th>\n","      <th>XP_718648.1</th>\n","      <th>AAB34216.1</th>\n","      <th>XP_822407.1</th>\n","      <th>NP_579856.2</th>\n","      <th>...</th>\n","      <th>NP_001167549.1</th>\n","      <th>AAG02439.1</th>\n","      <th>NP_001370.1</th>\n","      <th>AAH02453.1</th>\n","      <th>NP_003989.2</th>\n","      <th>NP_066921.2</th>\n","      <th>AAH70052.1</th>\n","      <th>NP_004944.3</th>\n","      <th>NP_004095.4</th>\n","      <th>NP_004283.2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ABM97548.1</td>\n","      <td>100.00</td>\n","      <td>15.62</td>\n","      <td>12.50</td>\n","      <td>11.51</td>\n","      <td>14.47</td>\n","      <td>11.69</td>\n","      <td>14.14</td>\n","      <td>14.39</td>\n","      <td>13.14</td>\n","      <td>...</td>\n","      <td>13.73</td>\n","      <td>6.36</td>\n","      <td>11.11</td>\n","      <td>9.86</td>\n","      <td>10.76</td>\n","      <td>13.75</td>\n","      <td>6.49</td>\n","      <td>5.88</td>\n","      <td>9.68</td>\n","      <td>11.11</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NP_004986.1</td>\n","      <td>15.62</td>\n","      <td>100.00</td>\n","      <td>13.08</td>\n","      <td>14.20</td>\n","      <td>13.74</td>\n","      <td>8.93</td>\n","      <td>17.76</td>\n","      <td>15.15</td>\n","      <td>11.63</td>\n","      <td>...</td>\n","      <td>10.94</td>\n","      <td>11.48</td>\n","      <td>13.46</td>\n","      <td>11.30</td>\n","      <td>12.86</td>\n","      <td>16.18</td>\n","      <td>9.68</td>\n","      <td>10.68</td>\n","      <td>14.55</td>\n","      <td>8.51</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NP_001725.1</td>\n","      <td>12.50</td>\n","      <td>13.08</td>\n","      <td>100.00</td>\n","      <td>15.05</td>\n","      <td>14.79</td>\n","      <td>12.78</td>\n","      <td>10.60</td>\n","      <td>12.68</td>\n","      <td>9.87</td>\n","      <td>...</td>\n","      <td>9.73</td>\n","      <td>6.25</td>\n","      <td>10.33</td>\n","      <td>4.17</td>\n","      <td>10.93</td>\n","      <td>12.37</td>\n","      <td>10.91</td>\n","      <td>11.39</td>\n","      <td>10.51</td>\n","      <td>10.00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NP_001123617.1</td>\n","      <td>11.51</td>\n","      <td>14.20</td>\n","      <td>15.05</td>\n","      <td>100.00</td>\n","      <td>10.67</td>\n","      <td>12.73</td>\n","      <td>12.95</td>\n","      <td>15.43</td>\n","      <td>15.66</td>\n","      <td>...</td>\n","      <td>12.44</td>\n","      <td>12.57</td>\n","      <td>13.55</td>\n","      <td>16.22</td>\n","      <td>9.50</td>\n","      <td>16.13</td>\n","      <td>8.33</td>\n","      <td>8.33</td>\n","      <td>13.82</td>\n","      <td>15.62</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>AAC63054.1</td>\n","      <td>14.47</td>\n","      <td>13.74</td>\n","      <td>14.79</td>\n","      <td>10.67</td>\n","      <td>100.00</td>\n","      <td>8.25</td>\n","      <td>11.30</td>\n","      <td>16.03</td>\n","      <td>13.67</td>\n","      <td>...</td>\n","      <td>13.43</td>\n","      <td>8.33</td>\n","      <td>12.26</td>\n","      <td>7.53</td>\n","      <td>10.53</td>\n","      <td>9.96</td>\n","      <td>9.80</td>\n","      <td>7.61</td>\n","      <td>13.10</td>\n","      <td>10.00</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>419</th>\n","      <td>NP_066921.2</td>\n","      <td>13.75</td>\n","      <td>16.18</td>\n","      <td>12.37</td>\n","      <td>16.13</td>\n","      <td>9.96</td>\n","      <td>11.98</td>\n","      <td>17.42</td>\n","      <td>13.86</td>\n","      <td>13.80</td>\n","      <td>...</td>\n","      <td>19.03</td>\n","      <td>18.09</td>\n","      <td>14.43</td>\n","      <td>17.69</td>\n","      <td>19.97</td>\n","      <td>100.00</td>\n","      <td>13.60</td>\n","      <td>16.27</td>\n","      <td>21.43</td>\n","      <td>15.06</td>\n","    </tr>\n","    <tr>\n","      <th>420</th>\n","      <td>AAH70052.1</td>\n","      <td>6.49</td>\n","      <td>9.68</td>\n","      <td>10.91</td>\n","      <td>8.33</td>\n","      <td>9.80</td>\n","      <td>8.47</td>\n","      <td>12.50</td>\n","      <td>7.58</td>\n","      <td>4.96</td>\n","      <td>...</td>\n","      <td>5.26</td>\n","      <td>7.14</td>\n","      <td>11.00</td>\n","      <td>10.30</td>\n","      <td>11.37</td>\n","      <td>13.60</td>\n","      <td>100.00</td>\n","      <td>13.42</td>\n","      <td>21.32</td>\n","      <td>14.94</td>\n","    </tr>\n","    <tr>\n","      <th>421</th>\n","      <td>NP_004944.3</td>\n","      <td>5.88</td>\n","      <td>10.68</td>\n","      <td>11.39</td>\n","      <td>8.33</td>\n","      <td>7.61</td>\n","      <td>9.35</td>\n","      <td>9.33</td>\n","      <td>10.08</td>\n","      <td>9.72</td>\n","      <td>...</td>\n","      <td>14.79</td>\n","      <td>12.61</td>\n","      <td>13.37</td>\n","      <td>15.35</td>\n","      <td>12.47</td>\n","      <td>16.27</td>\n","      <td>13.42</td>\n","      <td>100.00</td>\n","      <td>21.53</td>\n","      <td>17.60</td>\n","    </tr>\n","    <tr>\n","      <th>422</th>\n","      <td>NP_004095.4</td>\n","      <td>9.68</td>\n","      <td>14.55</td>\n","      <td>10.51</td>\n","      <td>13.82</td>\n","      <td>13.10</td>\n","      <td>13.33</td>\n","      <td>12.02</td>\n","      <td>13.36</td>\n","      <td>11.70</td>\n","      <td>...</td>\n","      <td>14.60</td>\n","      <td>14.31</td>\n","      <td>15.13</td>\n","      <td>14.24</td>\n","      <td>17.38</td>\n","      <td>21.43</td>\n","      <td>21.32</td>\n","      <td>21.53</td>\n","      <td>100.00</td>\n","      <td>25.11</td>\n","    </tr>\n","    <tr>\n","      <th>423</th>\n","      <td>NP_004283.2</td>\n","      <td>11.11</td>\n","      <td>8.51</td>\n","      <td>10.00</td>\n","      <td>15.62</td>\n","      <td>10.00</td>\n","      <td>3.77</td>\n","      <td>10.53</td>\n","      <td>8.62</td>\n","      <td>12.68</td>\n","      <td>...</td>\n","      <td>12.14</td>\n","      <td>13.92</td>\n","      <td>9.85</td>\n","      <td>14.39</td>\n","      <td>19.25</td>\n","      <td>15.06</td>\n","      <td>14.94</td>\n","      <td>17.60</td>\n","      <td>25.11</td>\n","      <td>100.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>424 rows × 425 columns</p>\n","</div>"],"text/plain":["       protein name  ABM97548.1  NP_004986.1  NP_001725.1  NP_001123617.1  \\\n","0        ABM97548.1      100.00        15.62        12.50           11.51   \n","1       NP_004986.1       15.62       100.00        13.08           14.20   \n","2       NP_001725.1       12.50        13.08       100.00           15.05   \n","3    NP_001123617.1       11.51        14.20        15.05          100.00   \n","4        AAC63054.1       14.47        13.74        14.79           10.67   \n","..              ...         ...          ...          ...             ...   \n","419     NP_066921.2       13.75        16.18        12.37           16.13   \n","420      AAH70052.1        6.49         9.68        10.91            8.33   \n","421     NP_004944.3        5.88        10.68        11.39            8.33   \n","422     NP_004095.4        9.68        14.55        10.51           13.82   \n","423     NP_004283.2       11.11         8.51        10.00           15.62   \n","\n","     AAC63054.1  XP_718648.1  AAB34216.1  XP_822407.1  NP_579856.2  ...  \\\n","0         14.47        11.69       14.14        14.39        13.14  ...   \n","1         13.74         8.93       17.76        15.15        11.63  ...   \n","2         14.79        12.78       10.60        12.68         9.87  ...   \n","3         10.67        12.73       12.95        15.43        15.66  ...   \n","4        100.00         8.25       11.30        16.03        13.67  ...   \n","..          ...          ...         ...          ...          ...  ...   \n","419        9.96        11.98       17.42        13.86        13.80  ...   \n","420        9.80         8.47       12.50         7.58         4.96  ...   \n","421        7.61         9.35        9.33        10.08         9.72  ...   \n","422       13.10        13.33       12.02        13.36        11.70  ...   \n","423       10.00         3.77       10.53         8.62        12.68  ...   \n","\n","     NP_001167549.1  AAG02439.1  NP_001370.1  AAH02453.1  NP_003989.2  \\\n","0             13.73        6.36        11.11        9.86        10.76   \n","1             10.94       11.48        13.46       11.30        12.86   \n","2              9.73        6.25        10.33        4.17        10.93   \n","3             12.44       12.57        13.55       16.22         9.50   \n","4             13.43        8.33        12.26        7.53        10.53   \n","..              ...         ...          ...         ...          ...   \n","419           19.03       18.09        14.43       17.69        19.97   \n","420            5.26        7.14        11.00       10.30        11.37   \n","421           14.79       12.61        13.37       15.35        12.47   \n","422           14.60       14.31        15.13       14.24        17.38   \n","423           12.14       13.92         9.85       14.39        19.25   \n","\n","     NP_066921.2  AAH70052.1  NP_004944.3  NP_004095.4  NP_004283.2  \n","0          13.75        6.49         5.88         9.68        11.11  \n","1          16.18        9.68        10.68        14.55         8.51  \n","2          12.37       10.91        11.39        10.51        10.00  \n","3          16.13        8.33         8.33        13.82        15.62  \n","4           9.96        9.80         7.61        13.10        10.00  \n","..           ...         ...          ...          ...          ...  \n","419       100.00       13.60        16.27        21.43        15.06  \n","420        13.60      100.00        13.42        21.32        14.94  \n","421        16.27       13.42       100.00        21.53        17.60  \n","422        21.43       21.32        21.53       100.00        25.11  \n","423        15.06       14.94        17.60        25.11       100.00  \n","\n","[424 rows x 425 columns]"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["protein_si"]},{"cell_type":"markdown","metadata":{},"source":["### 11.1.4. Calculation of FoHs:"]},{"cell_type":"markdown","metadata":{},"source":["Until now, we have a dictionary of (cid: assays tested); (assay_tested:protein name), and percentage identity matrix with first columns as protein names.\n","For each compound, we retrieve the list of all protein names tested on that compounds by matching between the two first dictionary. From this list, we retrieve the corresponding matrix of percentages identitiy of these proteins corresponding to these compounds and calculate the FoH."]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["protein_si_dict = {}\n","for name in protein_si['protein name']: \n","    for other_name in protein_si['protein name']: \n","        if other_name != name: \n","            protein_si_dict[(name, other_name)] = protein_si.loc[protein_si['protein name'] == name, other_name].values[0]"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 287/287 [00:25<00:00, 11.06it/s]\n"]}],"source":["foh_dict = {}\n","\n","for cid, targets in tqdm.tqdm(results_dict.items()):\n","    active_weight_list = []\n","    total_weight_list = []\n","\n","    for target_id, result in targets.items():\n","        if target_id == '':\n","            continue\n","\n","        protein_name = protein_id_to_name[target_id]\n","        max_weight = 0\n","\n","        for other_id, other_result in targets.items():\n","            if other_id != target_id and other_id != '':\n","                other_protein_name = protein_id_to_name[other_id]\n","                value = protein_si_dict[(protein_name, other_protein_name)]\n","                max_weight = max(max_weight, value)\n","\n","        target_weight = 1 - max_weight / 100\n","\n","        if result:\n","            active_weight_list.append(target_weight)\n","        total_weight_list.append(target_weight)\n","\n","    if total_weight_list:\n","        foh_score = sum(active_weight_list) / sum(total_weight_list)\n","        foh_dict[cid] = foh_score\n","    else: \n","        foh_dict[cid] = 0"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["#export foh_dict\n","with open(f'{data_folder}/before_finished/step_11/11_1/foh_dict.json', 'w') as f:\n","    json.dump(foh_dict, f)"]},{"cell_type":"markdown","metadata":{},"source":["For compounds with FoH larger than 0.26, we remove them"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Dropped 0 compounds with FoH larger than 0.26\n"]}],"source":["to_drop = []\n","for cid, foh_score in foh_dict.items():\n","    if foh_score > 0.26: \n","        to_drop.append(cid)\n","\n","post_FoH_actives = pre11_actives[~pre11_actives[cid_col].isin(to_drop)]\n","print(f'Dropped {(len(to_drop))} compounds with FoH larger than 0.26')"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["post_FoH_actives.to_csv(f'{data_folder}/before_finished/step_11/11_1/post_FoH_actives.csv', index=False)\n","pre11_inactives.to_csv(f'{data_folder}/before_finished/step_11/11_1/post_FoH_inactives.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["## 11.2. Autofluoresence Filter"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["post_FoH_actives = pd.read_csv(f'{data_folder}/before_finished/step_11/11_1/post_FoH_actives.csv', sep=',', header=0)\n","post_FoH_inactives = pd.read_csv(f'{data_folder}/before_finished/step_11/11_1/post_FoH_inactives.csv', sep=',', header=0)"]},{"cell_type":"markdown","metadata":{},"source":["When finding false positive due to autofluorescence and luceferase inhibition, it is important to check if the particular assays use one of these technologies. Here, all three assays (AID626, AID1488, and AID1741) use fluorescence technologies, so it is optimal to remove compounds that are active in AIDs: 587, 588, 590, 591, 592, 593, 594"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading autofluorescence data:   0%|          | 0/7 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["Downloading autofluorescence data: 100%|██████████| 7/7 [00:28<00:00,  4.11s/it]"]},{"name":"stdout","output_type":"stream","text":["Autofluorescence compounds imported successfully!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["autofluorescence_cids = filters.load_autofluorescence_cids(data_folder)"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Dropped 0 autofluorescence compounds\n"]}],"source":["to_drop_actives = []\n","for cid in post_FoH_actives: \n","    if cid in autofluorescence_cids:\n","        to_drop.append(cid)\n","post_autofluorescence_actives = post_FoH_actives[~post_FoH_actives['PUBCHEM_CID'].isin(to_drop_actives)]\n","print(f'Dropped {(len(to_drop_actives))} autofluorescence compounds')"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["if not os.path.exists(f'{data_folder}/before_finished/step_11/11_2'):\n","    os.makedirs(f'{data_folder}/before_finished/step_11/11_2')\n","\n","#save: \n","post_autofluorescence_actives.to_csv(f'{data_folder}/before_finished/step_11/11_2/post_autofluorescence_actives.csv', index=False)\n","pre11_inactives.to_csv(f'{data_folder}/before_finished/step_11/11_2/post_autofluorescence_inactives.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["## 11.3 RDKit PAIN Filter"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["post_autofluorescence_actives = pd.read_csv(f'{data_folder}/before_finished/step_11/11_2/post_autofluorescence_actives.csv', sep=',', header=0)\n","post_autofluorescence_inactives = pd.read_csv(f'{data_folder}/before_finished/step_11/11_2/post_autofluorescence_inactives.csv', sep=',', header=0)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1 pains detected\n","2 pains detected\n","3 pains detected\n","4 pains detected\n","5 pains detected\n","6 pains detected\n","7 pains detected\n","8 pains detected\n","9 pains detected\n","10 pains detected\n","11 pains detected\n","12 pains detected\n","13 pains detected\n","14 pains detected\n","15 pains detected\n","16 pains detected\n","17 pains detected\n","18 pains detected\n","19 pains detected\n","20 pains detected\n","21 pains detected\n","22 pains detected\n","23 pains detected\n","24 pains detected\n","25 pains detected\n","26 pains detected\n","27 pains detected\n","28 pains detected\n"]}],"source":["pains_actives = filters.detect_pains(post_autofluorescence_actives, smi_col, cid_col)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["post_pains_actives = post_autofluorescence_actives[~post_autofluorescence_actives['PUBCHEM_CID'].isin(pains_actives)]"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["if not os.path.exists(f'{data_folder}/before_finished/step_11/11_3'):\n","    os.makedirs(f'{data_folder}/before_finished/step_11/11_3')\n","\n","post_pains_actives.to_csv(f'{data_folder}/before_finished/step_11/11_3/post_pains_actives.csv', index=False)\n","post_autofluorescence_inactives.to_csv(f'{data_folder}/before_finished/step_11/11_3/post_pains_inactives.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# 12. Drug-likeness Filter"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["pre12_actives = pd.read_csv(f'{data_folder}/before_finished/step_11/11_3/post_pains_actives.csv', sep=',', header=0)\n","pre12_inactives = pd.read_csv(f'{data_folder}/before_finished/step_11/11_3/post_pains_inactives.csv', sep=',', header=0)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing SMILES: 100%|██████████| 259/259 [00:00<?, ?it/s]\n"]}],"source":["not_drug_actives = filters.drug_likeness_filter_multiprocessing(pre12_actives, smi_col, cid_col)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing SMILES: 100%|██████████| 303734/303734 [00:14<00:00, 20500.91it/s] \n"]}],"source":["not_drug_inactives = filters.drug_likeness_filter_multiprocessing(pre12_inactives, smi_col, cid_col)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Dropped 12 hit compounds that do not pass the drug likeness filter\n","Dropped 17409 inactive compounds that do not pass the drug likeness filter\n"]}],"source":["post12_actives = pre12_actives[~pre12_actives['PUBCHEM_CID'].isin(not_drug_actives)]\n","post12_inactives = pre12_inactives[~pre12_inactives['PUBCHEM_CID'].isin(not_drug_inactives)]\n","\n","print(f'Dropped {(len(not_drug_actives))} hit compounds that do not pass the drug likeness filter')\n","print(f'Dropped {(len(not_drug_inactives))} inactive compounds that do not pass the drug likeness filter')"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["if not os.path.exists(f'{data_folder}/before_finished/step_12'):\n","    os.makedirs(f'{data_folder}/before_finished/step_12')\n","\n","#Export not_drug_actives and inactives:\n","with open(f'{data_folder}/before_finished/step_12/not_drug_actives.json', 'w') as f:\n","    json.dump(not_drug_actives, f)\n","with open(f'{data_folder}/before_finished/step_12/not_drug_inactives.json', 'w') as f:\n","    json.dump(not_drug_inactives, f)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# save: \n","post12_actives.to_csv(f'{data_folder}/before_finished/step_12/post12_actives.csv', index=False)\n","post12_inactives.to_csv(f'{data_folder}/before_finished/step_12/post12_inactives.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# 13. ChemBL Curation Pipeline"]},{"cell_type":"markdown","metadata":{},"source":["Besides PubChem, the ChEMBL database is one of several public databases containing bioactivity data on small molecule compounds curated from various sources. Incoming compounds are typically not standardized according to consistent rules. To maintain the quality of the final database and to facilitate the comparison and integration of data on the same compound from different sources, it is essential to appropriately standardize the chemical structures in the database. This chemical curation pipeline has been developed by Bento, A.P, et al., using the open-source toolkit RDKit, including a Checker module that tests the validity of chemical structures and flags any serious errors. For ChEMBL, a penalty score of 7 is considered a fatal error, and the molfile is not loaded into the database.\n","\n","In our dataset, we passed all compounds through this Checker module to evaluate the validity of the included chemical structures. For compounds that returned a penalty score of 7, we will check them manually.\n","\n","Reference:\n","Bento, A.P., Hersey, A., Félix, E. et al. An open source chemical structure curation pipeline using RDKit. J Cheminform 12, 51 (2020). https://doi.org/10.1186/s13321-020-00456-1"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["pre13_actives = pd.read_csv(f'{data_folder}/before_finished/step_12/post12_actives.csv', sep=',', header=0)\n","pre13_inactives = pd.read_csv(f'{data_folder}/before_finished/step_12/post12_inactives.csv', sep=',', header=0)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing SMILES: 100%|██████████| 247/247 [00:00<?, ?it/s]\n","[15:01:18] Warning: ambiguous stereochemistry - linear bond arrangement - at atom 6 ignored\n","[15:01:18] Warning: ambiguous stereochemistry - linear bond arrangement - at atom 6 ignored\n","[15:03:36] Warning: ambiguous stereochemistry - linear bond arrangement - at atom 8 ignored\n","[15:03:36] Warning: ambiguous stereochemistry - linear bond arrangement - at atom 8 ignored\n","[15:03:47] Warning: ambiguous stereochemistry - linear bond arrangement - at atom 12 ignored\n","[15:03:47] Warning: ambiguous stereochemistry - linear bond arrangement - at atom 12 ignored\n","[15:03:50] Warning: ambiguous stereochemistry - linear bond arrangement - at atom 4 ignored\n","[15:03:50] Warning: ambiguous stereochemistry - linear bond arrangement - at atom 15 ignored\n","[15:03:50] Warning: ambiguous stereochemistry - linear bond arrangement - at atom 4 ignored\n","[15:03:50] Warning: ambiguous stereochemistry - linear bond arrangement - at atom 15 ignored\n","[15:04:08] Warning: ambiguous stereochemistry - linear bond arrangement - at atom 14 ignored\n","[15:04:08] Warning: ambiguous stereochemistry - linear bond arrangement - at atom 14 ignored\n","[15:04:09] Warning: ambiguous stereochemistry - linear bond arrangement - at atom 7 ignored\n","[15:04:09] Warning: ambiguous stereochemistry - linear bond arrangement - at atom 7 ignored\n","[15:05:39] Warning: ambiguous stereochemistry - linear bond arrangement - at atom 5 ignored\n","[15:05:39] Warning: ambiguous stereochemistry - linear bond arrangement - at atom 5 ignored\n","[15:06:42] Warning: ambiguous stereochemistry - linear bond arrangement - at atom 4 ignored\n","[15:06:42] Warning: ambiguous stereochemistry - linear bond arrangement - at atom 20 ignored\n","[15:06:42] Warning: ambiguous stereochemistry - linear bond arrangement - at atom 4 ignored\n","[15:06:42] Warning: ambiguous stereochemistry - linear bond arrangement - at atom 20 ignored\n","[15:07:09] Warning: ambiguous stereochemistry - linear bond arrangement - at atom 12 ignored\n","[15:07:09] Warning: ambiguous stereochemistry - linear bond arrangement - at atom 12 ignored\n","[15:07:15] Warning: ambiguous stereochemistry - overlapping neighbors  - at atom 18 ignored\n","[15:07:15] Warning: ambiguous stereochemistry - overlapping neighbors  - at atom 18 ignored\n","[15:08:27] Warning: ambiguous stereochemistry - linear bond arrangement - at atom 14 ignored\n","[15:08:27] Warning: ambiguous stereochemistry - linear bond arrangement - at atom 14 ignored\n","Processing SMILES: 100%|██████████| 286325/286325 [01:16<00:00, 3764.78it/s]  \n"]}],"source":["# Apply the ChemBL Curation Pipeline Checker module:\n","score_actives = utils.checker_multiprocessing(pre13_actives, smi_col, cid_col)\n","score_inactives = utils.checker_multiprocessing(pre13_inactives, smi_col, cid_col)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{0, 2}\n","{0, 2, 5, 6}\n"]}],"source":["#print all unique values in the dictionary:\n","print(set(score_actives.values()))\n","print(set(score_inactives.values()))"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Create a new step folder\n","if not os.path.exists(f'{data_folder}/before_finished/step_13'):\n","    os.makedirs(f'{data_folder}/before_finished/step_13')\n","\n","# save the scores:\n","with open(f'{data_folder}/before_finished/step_13/score_actives.json', 'w') as f:\n","    json.dump(score_actives, f)\n","with open(f'{data_folder}/before_finished/step_13/score_inactives.json', 'w') as f:\n","    json.dump(score_inactives, f)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["#drop all compounds with a penalty score of 7:\n","to_drop_actives = []\n","to_drop_inactives = []\n","for cid, penalty_score in score_actives.items():\n","    if penalty_score == 7:\n","        to_drop_actives.append(cid)\n","for cid, penalty_score in score_inactives.items():\n","    if penalty_score == 7:\n","        to_drop_inactives.append(cid)\n","\n","post13_actives = pre13_actives[~pre13_actives[cid_col].isin(to_drop_actives)]\n","post13_inactives = pre13_inactives[~pre13_inactives[cid_col].isin(to_drop_inactives)]"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["#save final_hits and inactives:\n","post13_actives.to_csv(f'{data_folder}/before_finished/step_13/post13_actives.csv', index=False)\n","post13_inactives.to_csv(f'{data_folder}/before_finished/step_13/post13_inactives.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# 14. Final handling of chemical representation"]},{"cell_type":"markdown","metadata":{},"source":["Any kind of molecular processing should come with a special attention to post-processing adjustment. This is because during molecular processing, changes in data representation and format could lead to inconsistency or redundancy in the datasets. Below are the two adjustments performed on our datasets. \n","\n","(1) Some of the InChIs in our datasets should be updated. This is because some of the InChI will be missing, since the PubChem Identifier Exchange service might not able to find the corresponding InChI for the aromatized, neutralized SMILES.\n","\n","(2) Presence of some additional duplicates resulted from molecular processing: While handling mixtures, there might be some mixtures whose component molecules are identical. For example, mixtures of organic and inorganic molecules (molX-ionA and molX-ionB) after removed the ions (ionA and ionB) will result in duplicates (molX). Moreover, since the original mixtures are different, their activities could be different. Therefore, we also need to check their activities while handling these duplicates.\n","- If all duplicates share the same results (active/inactive), we keep one of them, since it is likely that the organic molecule kept contributed more significantly to the activity of the mixture. \n","- If duplicates of the same molecules returned different activity, it is safer to remove both of them."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["#import: \n","pre14_actives = pd.read_csv(f'{data_folder}/before_finished/step_13/post13_actives.csv', sep=',', header=0)\n","pre14_inactives = pd.read_csv(f'{data_folder}/before_finished/step_13/post13_inactives.csv', sep=',', header=0)"]},{"cell_type":"markdown","metadata":{},"source":["## 14.1 Update InChI"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def smi_to_inchi(smi):\n","    mol = Chem.MolFromSmiles(smi)\n","    inchi = Chem.inchi.MolToInchi(mol)\n","    return inchi"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Updated 0 InChI values in pre14_actives\n"]},{"name":"stderr","output_type":"stream","text":["[15:17:03] WARNING: Omitted undefined stereo\n","\n","[15:17:03] WARNING: Omitted undefined stereo\n","\n","[15:17:04] WARNING: Omitted undefined stereo\n","\n","[15:17:04] WARNING: Proton(s) added/removed\n","\n","[15:17:04] WARNING: Omitted undefined stereo\n","\n","[15:17:05] WARNING: Omitted undefined stereo\n","\n","[15:17:05] WARNING: Charges were rearranged\n","\n","[15:17:05] WARNING: Omitted undefined stereo\n","\n","[15:17:06] WARNING: Omitted undefined stereo\n","\n","[15:17:06] WARNING: Omitted undefined stereo\n","\n","[15:17:06] WARNING: Charges were rearranged\n","\n","[15:17:06] WARNING: Charges were rearranged\n","\n","[15:17:07] WARNING: Proton(s) added/removed\n","\n","[15:17:07] WARNING: Omitted undefined stereo\n","\n","[15:17:07] WARNING: Proton(s) added/removed; Omitted undefined stereo\n","\n","[15:17:07] WARNING: Omitted undefined stereo\n","\n","[15:17:07] WARNING: Proton(s) added/removed\n","\n","[15:17:07] WARNING: Omitted undefined stereo\n","\n","[15:17:08] WARNING: Charges were rearranged; Omitted undefined stereo\n","\n","[15:17:08] WARNING: Omitted undefined stereo\n","\n","[15:17:08] WARNING: Omitted undefined stereo\n","\n","[15:17:08] WARNING: Omitted undefined stereo\n","\n","[15:17:08] WARNING: Omitted undefined stereo\n","\n","[15:17:08] WARNING: Omitted undefined stereo\n","\n","[15:17:09] WARNING: Omitted undefined stereo\n","\n","[15:17:09] WARNING: Charges were rearranged; Omitted undefined stereo\n","\n","[15:17:09] WARNING: Omitted undefined stereo\n","\n","[15:17:09] WARNING: Omitted undefined stereo\n","\n","[15:17:09] WARNING: Omitted undefined stereo\n","\n","[15:17:09] WARNING: Proton(s) added/removed\n","\n","[15:17:09] WARNING: Omitted undefined stereo\n","\n","[15:17:09] WARNING: Charges were rearranged\n","\n","[15:17:10] WARNING: Omitted undefined stereo\n","\n","[15:17:10] WARNING: Charges were rearranged\n","\n"]},{"name":"stdout","output_type":"stream","text":["Updated 69 InChI values in pre14_inactives\n"]}],"source":["count = 0 \n","for index, row in pre14_actives.iterrows():\n","    if row['InChI'] != row['InChI']:\n","        pre14_actives.at[index, 'InChI'] = smi_to_inchi(row[smi_col])\n","        count += 1\n","print(f'Updated {count} InChI values in pre14_actives')\n","\n","count = 0\n","for index, row in pre14_inactives.iterrows():\n","    if row['InChI'] != row['InChI']:\n","        pre14_inactives.at[index, 'InChI'] = smi_to_inchi(row[smi_col])\n","        count += 1\n","print(f'Updated {count} InChI values in pre14_inactives')"]},{"cell_type":"markdown","metadata":{},"source":["## 14.2 Handle Duplicates"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of InChI duplicates in actives:  0\n","Number of InChI duplicates in inactives:  285\n","Number of SMILES duplicates in actives:  0\n","Number of SMILES duplicates in inactives:  283\n"]}],"source":["#Check if a mol in active set appeared in inactive set:\n","for i in pre14_actives[smi_col]:\n","    if i in list(pre14_inactives[smi_col]):\n","        print(f'{i} SMILES appeared in both active and inactive sets')\n","for i in pre14_actives['InChI']:\n","    if i in list(pre14_inactives['InChI']):\n","        print(f'{i} InChI appeared in both active and inactive sets')\n","\n","#Return all duplicates by comparing InChI:\n","final_actives_duplicates_InChI = pre14_actives[pre14_actives.duplicated(subset=['InChI'], keep=False)]\n","final_inactives_duplicates_InChI = pre14_inactives[pre14_inactives.duplicated(subset=['InChI'], keep=False)]\n","final_actives_duplicates_smi = pre14_actives[pre14_actives.duplicated(subset=[smi_col], keep=False)]\n","final_inactives_duplicates_smi = pre14_inactives[pre14_inactives.duplicated(subset=[smi_col], keep=False)]\n","\n","print('Number of InChI duplicates in actives: ', len(final_actives_duplicates_InChI))\n","print('Number of InChI duplicates in inactives: ', len(final_inactives_duplicates_InChI))\n","print('Number of SMILES duplicates in actives: ', len(final_actives_duplicates_smi))\n","print('Number of SMILES duplicates in inactives: ', len(final_inactives_duplicates_smi))"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["if not os.path.exists(f'{data_folder}/before_finished/step_14'):\n","    os.makedirs(f'{data_folder}/before_finished/step_14')\n","\n","#write all the duplicates to a file:\n","#write duplicates to a txt file: \n","with open(f'{data_folder}/before_finished/step_14/duplicates.txt', 'w') as f:\n","    f.write('InChI duplicates in actives: \\n')\n","    f.write(final_actives_duplicates_InChI.to_string())\n","    f.write('\\n\\n')\n","    f.write('InChI duplicates in inactives: \\n')\n","    f.write(final_inactives_duplicates_InChI.to_string())\n","    f.write('\\n\\n')\n","    f.write('SMILES duplicates in actives: \\n')\n","    f.write(final_actives_duplicates_smi.to_string())\n","    f.write('\\n\\n')\n","    f.write('SMILES duplicates in inactives: \\n')\n","    f.write(final_inactives_duplicates_smi.to_string())"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["#remove these duplicates, keep the first one: \n","#by inchi:\n","final_actives = pre14_actives.drop_duplicates(subset=['InChI'], keep='first')\n","final_inactives = pre14_inactives.drop_duplicates(subset=['InChI'], keep='first')"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["No more duplicates in actives\n","No more duplicates in inactives\n"]}],"source":["if len(final_actives[final_actives.duplicated(subset=[smi_col], keep=False)]) == 0:\n","    print('No more duplicates in actives')\n","\n","if len(final_inactives[final_inactives.duplicated(subset=[smi_col], keep=False)]) == 0:\n","    print('No more duplicates in inactives')"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["# save: \n","if not os.path.exists(f'{data_folder}/finished'):\n","    os.makedirs(f'{data_folder}/finished')\n","final_actives.to_csv(f'{data_folder}/finished/final_actives.csv',sep=',', index=False)\n","final_inactives.to_csv(f'{data_folder}/finished/final_inactives.csv',sep=',', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Some additional modifications"]},{"cell_type":"markdown","metadata":{},"source":["## A. Adjust column names"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["final_actives = pd.read_csv(f'{data_folder}/finished/final_actives.csv', sep=',', header=0)\n","final_inactives = pd.read_csv(f'{data_folder}/finished/final_inactives.csv', sep=',', header=0)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# Add another column: \"activity_value\" with all empty NaN values for format consistency with regression datasets:\n","final_actives.loc[:, 'activity_value'] = np.nan \n","final_inactives.loc[:, 'activity_value'] = np.nan\n","\n","if 'small_organic_mol_from_mixture' not in final_actives.columns: # Sometimes, this column might be missing since no small org. mol was detected in mixtures.\n","    final_actives['small_organic_mol_from_mixture'] = np.nan\n","\n","# Rename the columns:\n","final_actives = final_actives.rename(columns={\n","    'PUBCHEM_CID': 'CID',\n","    'PUBCHEM_ACTIVITY_OUTCOME': 'activity_outcome',\n","    'PUBCHEM_EXT_DATASOURCE_SMILES': 'SMILES',\n","    'Mol removed from mixture': 'mol_removed_from_mixture',\n","    'Small inorganic molecule': 'small_inorganic_mol_from_mixture',\n","    'Small organic molecule': 'small_organic_mol_from_mixture'\n","})\n","final_inactives = final_inactives.rename(columns={\n","    'PUBCHEM_CID': 'CID',\n","    'PUBCHEM_ACTIVITY_OUTCOME': 'activity_outcome',\n","    'PUBCHEM_EXT_DATASOURCE_SMILES': 'SMILES',\n","    'Mol removed from mixture': 'mol_removed_from_mixture',\n","    'Small inorganic molecule': 'small_inorganic_mol_from_mixture',\n","    'Small organic molecule': 'small_organic_mol_from_mixture'\n","})\n","\n","#swap the positions of the columns InChI and activity_outcome:\n","final_actives = final_actives[['CID', 'SMILES', 'InChI', 'activity_outcome', 'activity_value', 'mol_removed_from_mixture', 'small_inorganic_mol_from_mixture', 'small_organic_mol_from_mixture']]\n","final_inactives = final_inactives[['CID', 'SMILES', 'InChI', 'activity_outcome', 'activity_value', 'mol_removed_from_mixture', 'small_inorganic_mol_from_mixture', 'small_organic_mol_from_mixture']]"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["#export:\n","final_actives.to_csv(f'{data_folder}/finished/final_actives.csv', sep=',', index=False)\n","final_inactives.to_csv(f'{data_folder}/finished/final_inactives.csv', sep=',', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["## B. Compile Control Data"]},{"cell_type":"markdown","metadata":{},"source":["This part of the notebook includes our complilation of the control data (poorly curated data without applying hierarchical curation, molecular processing, or filters). Data format should be similar to curated data for convenience."]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["for AID in AIDs:\n","    exec(f\"raw{AID} = pd.read_csv(f'{data_folder}/before_finished/step_1/AID{AID}.csv', sep=',', header=0)\")\n","\n","#import inchi:\n","for AID in AIDs:\n","    exec(f\"std_inchi{AID} = pd.read_csv(f'{data_folder}/before_finished/step_3/std_inchi_{AID}.txt', sep='\\t', header=None)\")\n","\n","#Update inchi\n","for AID in AIDs:\n","    exec(f\"\"\"\n","raw_inchi_dict{AID} = dict(zip(std_inchi{AID}[0], std_inchi{AID}[1]))\n","raw{AID}['InChI'] = raw{AID}['PUBCHEM_CID'].map(raw_inchi_dict{AID})\n","\"\"\")"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["raw_actives = raw2239[raw2239[activity_col] == 'Active']\n","raw_inactives = raw2239[raw2239[activity_col] == 'Inactive']"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["# Add some other columns to match the format of the curated data:\n","raw_actives.loc[:, 'activity_value'] = np.nan\n","raw_actives.loc[:, 'mol_removed_from_mixture'] = np.nan\n","raw_actives.loc[:, 'small_inorganic_mol_from_mixture'] = np.nan\n","raw_actives.loc[:, 'small_organic_mol_from_mixture'] = np.nan\n","\n","raw_inactives.loc[:, 'activity_value'] = np.nan\n","raw_inactives.loc[:, 'mol_removed_from_mixture'] = np.nan\n","raw_inactives.loc[:, 'small_inorganic_mol_from_mixture'] = np.nan\n","raw_inactives.loc[:, 'small_organic_mol_from_mixture'] = np.nan"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["# Rename the columns:\n","raw_actives = raw_actives.rename(columns={\n","    'PUBCHEM_CID': 'CID',\n","    'PUBCHEM_ACTIVITY_OUTCOME': 'activity_outcome',\n","    'PUBCHEM_EXT_DATASOURCE_SMILES': 'SMILES',\n","})\n","raw_inactives = raw_inactives.rename(columns={\n","    'PUBCHEM_CID': 'CID',\n","    'PUBCHEM_ACTIVITY_OUTCOME': 'activity_outcome',\n","    'PUBCHEM_EXT_DATASOURCE_SMILES': 'SMILES',\n","})\n","\n","#swap the positions of the columns InChI and activity_outcome:\n","raw_actives = raw_actives[['CID', 'SMILES', 'InChI', 'activity_outcome', 'activity_value', 'mol_removed_from_mixture', 'small_inorganic_mol_from_mixture', 'small_organic_mol_from_mixture']]\n","raw_inactives = raw_inactives[['CID', 'SMILES', 'InChI', 'activity_outcome', 'activity_value', 'mol_removed_from_mixture', 'small_inorganic_mol_from_mixture', 'small_organic_mol_from_mixture']]"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["if not os.path.exists(f'{data_folder}/finished/control_data'):\n","    os.makedirs(f'{data_folder}/finished/control_data')\n","\n","#save the hits and inactives\n","raw_actives.to_csv(f'{data_folder}/finished/control_data/raw_actives.csv', sep=',', index=False)\n","raw_inactives.to_csv(f'{data_folder}/finished/control_data/raw_inactives.csv', sep=',', index=False)\n","\n","#save as txt:\n","raw_actives.to_csv(f'{data_folder}/finished/control_data/raw_actives.txt', sep=';', index=False, header=False)\n","raw_inactives.to_csv(f'{data_folder}/finished/control_data/raw_inactives.txt', sep=';', index=False, header=False)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPfLlSKLjgs5ctgD2l5OOjz","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
