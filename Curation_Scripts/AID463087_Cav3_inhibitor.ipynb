{"cells":[{"cell_type":"markdown","metadata":{"id":"duVcJ3TEsH_c"},"source":["# 0. Initial Set-up"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LU7GZuQisH_f","outputId":"4b76486e-a60c-49c2-f73e-b62bb77d8f48"},"outputs":[{"name":"stderr","output_type":"stream","text":["[02:23:19] Initializing Normalizer\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import requests\n","import os\n","import json\n","import tqdm\n","\n","from rdkit import Chem\n","from tqdm import tqdm\n","from thermo import functional_groups\n","from Bio import Entrez\n","from chembl_structure_pipeline import checker\n","from rdkit.Chem import rdMolDescriptors, Descriptors, Lipinski, Crippen, inchi\n","from rdkit.Chem.FilterCatalog import FilterCatalog, FilterCatalogParams\n","from concurrent.futures import ThreadPoolExecutor, as_completed\n","\n","import utils\n","import filters\n","from data_gathering import download_and_save"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Save the path to your curation folder to \"curation_path\"\n","dataset_name = 'AID463087'\n","curation_path = 'S:/coding/WelQrate/'\n","data_folder = f'{curation_path}/data/{dataset_name}'\n","\n","# Columns to be extracted from the assays:\n","# Modify if your datasets have different format\n","smi_col = 'PUBCHEM_EXT_DATASOURCE_SMILES' # Column containing SMILES\n","cid_col = 'PUBCHEM_CID' # Column containing identifiers (e.g, CIDs)\n","activity_col = 'PUBCHEM_ACTIVITY_OUTCOME' # Column containing activity outcomes\n","col_list = [cid_col, smi_col, activity_col]"]},{"cell_type":"markdown","metadata":{"id":"YNaTZx5ysH_h"},"source":["# 1. Data gathering"]},{"cell_type":"markdown","metadata":{"id":"IEYwvXxusH_h"},"source":["Before importing data, need to identify which AIDs will be included. \n","\n","Data will be imported from https://pubchem.ncbi.nlm.nih.gov/assay/. For more information on PubChem's programmatic access, refer to: https://pubchem.ncbi.nlm.nih.gov/docs/bioassays. Some other programmatic access options available such as PUG-REST. However, these might not be optimal for bulk retrieval or handling of large dataset due to the limitation of request volume.\n","\n","Data for individual assays include 7 required columns (CIDs, isomeric SMILES, etc.) and optional test results. Refer to https://ftp.ncbi.nlm.nih.gov/pubchem/Bioassay/CSV/README for further details. For datasets intended for regression model, additional columns could be extracted accordingly."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Desired AIDs:\n","AIDs = [449739, 493021, 489005, 493022, 493023, 493041]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AH_exfp_sH_i","outputId":"730f47a3-4b83-481c-8489-7a87535ac1cd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of datasets retrieving:  6\n"]}],"source":["#Keep unique values in list AIDs (since there could be overlapping AIDs from different targets or project)\n","AIDs = list(set(AIDs))\n","AIDs = [str(AID) for AID in AIDs]\n","print('Number of datasets retrieving: ', len(AIDs))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VUvBge0XsH_i","outputId":"89718f2b-c8a1-4348-b4a0-0f4b394a3c8d"},"outputs":[{"name":"stdout","output_type":"stream","text":["1 out of 6 complete\n","2 out of 6 complete\n","3 out of 6 complete\n","4 out of 6 complete\n","5 out of 6 complete\n","6 out of 6 complete\n"]}],"source":["download_and_save(AIDs, data_folder, col_list, smi_col, cid_col, activity_col)"]},{"cell_type":"markdown","metadata":{"id":"ZjUdwM0dsH_j"},"source":["# 2. Isomeric SMILES"]},{"cell_type":"markdown","metadata":{"id":"dRh9GY9RsH_j"},"source":["For the purpose of our project, we would like to include isomeric form of SMILES representation in our final dataset. Although PubChem claimed that their datatable should include isomeric SMILES (https://pubchem.ncbi.nlm.nih.gov/docs/bioassays), some dataset might include non-isomeric SMILES. This step is to import isomeric SMILES based on CIDs.\n","\n","Several packages such as RDkit have modules to return isomeric SMILES from a given input SMILES. However, for consistency, we decided to use the PubChem Identifier Exchange Service, which take an input identifier (CIDs, SMILES, InChI, etc.)  and return the corresponding identifier (CIDs, isomeric SMILES, InChIs, etc.). Here, we export the list of CIDs for compounds in our dataset and use this server to retrieve their isomeric SMILES. For more information, refer to: https://pubchem.ncbi.nlm.nih.gov/docs/identifier-exchange-service"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iAn39HqJsH_j","outputId":"2d211ee1-2afa-4190-9d87-7cf5315878ce"},"outputs":[{"data":{"text/plain":["'\\nAfter this step, submit the lists of CIDs at https://pubchem.ncbi.nlm.nih.gov/idexchange/idexchange.cgi \\n    Operator type: \"same CID\" \\n    Output IDs \"SMILES\" (isomeric SMILES by default) \\n    Output method: \"Two column file showing each input output-correspondence\"\\n    Compression: \"No compression\"\\nRefer to https://pubchem.ncbi.nlm.nih.gov/docs/identifier-exchange-service for more details.\\nThe output files (converted isomeric SMILES) should be named as \"isomeric_smi_{AID}.txt\" and saved to the \"step_2\" folder.\\n'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["#Create a new step folder:\n","if not os.path.exists(f'{data_folder}/before_finished/step_2'):\n","    os.makedirs(f'{data_folder}/before_finished/step_2')\n","\n","#Export list of CIDs to csv with one column (without the column name):\n","for AID in AIDs:\n","    assay = pd.read_csv(f'{data_folder}/before_finished/step_1/AID{AID}.csv')\n","    cids = assay['PUBCHEM_CID'].astype(int)  # Ensure the CIDs are integers\n","    cids.to_csv(f'{data_folder}/before_finished/step_2/CID{AID}.csv', index=False, header=False)\n","\n","#After this step, we submit the list at https://pubchem.ncbi.nlm.nih.gov/idexchange/idexchange.cgi with operator type \"same CID\" and Output IDs \"SMILES\" (isomeric SMILES by default)\n","#https://pubchem.ncbi.nlm.nih.gov/docs/identifier-exchange-service for more details\n","#Here I named the output file as \"SMILES{AID}.txt\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QRvqY3-1sH_j"},"outputs":[],"source":["def check_isomeric_smiles(AIDs):\n","    \"\"\"\n","    Check if the SMILES in the assay are the same as the isomeric forms returned by pubchem idexchange.\n","    Input: AIDs (list of strings)\n","    Output: non_isomeric_smi_cids (dictionary with AID as key and list of CIDs as values for the datasets in AIDs\n","    \"\"\"\n","    non_isomeric_smi_cids = {}\n","    for AID in AIDs:    \n","        non_isomeric_smi_cids[AID] = []\n","        #import SMILES.txt file as a table:\n","        correct_isomeric_smiles = pd.read_csv(f'{data_folder}/before_finished/step_2/isomeric_smi_{AID}.txt', sep='\\t', header=None)\n","        assay = pd.read_csv(f'{data_folder}/before_finished/step_1/AID{AID}.csv')\n","\n","        #compare smiles in assay with smiles in correct_smiles:\n","        for cid in assay['PUBCHEM_CID']:\n","            if assay.loc[assay['PUBCHEM_CID'] == cid, 'PUBCHEM_EXT_DATASOURCE_SMILES'].values[0] != correct_isomeric_smiles.loc[correct_isomeric_smiles[0] == cid, 1].values[0]:\n","                non_isomeric_smi_cids[AID].append(cid)\n","\n","        if len(non_isomeric_smi_cids[AID]) == 0:\n","            print(f'All SMILES in AID {AID} are isomeric')\n","        else:\n","            print(f'There are some potential non-isomeric SMILES in AID {AID}:')\n","            print(non_isomeric_smi_cids[AID])\n","\n","    return non_isomeric_smi_cids\n","\n","def update_isomeric(AIDs, non_isomeric_smi_cids):\n","    \"\"\"\n","    Update the SMILES in the assay to isomeric SMILES.\n","    Input: AIDs (list of strings), non_isomeric_smi_cids (dictionary with AID as key and list of non-isomeric CIDs as values)\n","    \"\"\"\n","    with open(f'{data_folder}/before_finished/step_2/non_isomeric_smi_cids.txt', 'w') as f:\n","        # record the non-isomeric SMILES \n","        for AID in AIDs:\n","            assay = pd.read_csv(f'{data_folder}/before_finished/step_1/AID{AID}.csv')\n","            correct_isomeric_smiles = pd.read_csv(f'{data_folder}/before_finished/step_2/isomeric_smi_{AID}.txt', sep='\\t', header=None)\n","            f.write(f'AID {AID}: {non_isomeric_smi_cids[AID]}\\n')\n","\n","            for cid in non_isomeric_smi_cids[AID]:\n","                f.write(f'CID {cid}: {assay.loc[assay[\"PUBCHEM_CID\"] == cid, \"PUBCHEM_EXT_DATASOURCE_SMILES\"].values[0]} -> {correct_isomeric_smiles.loc[correct_isomeric_smiles[0] == cid, 1].values[0]}\\n')\n","                assay.loc[assay['PUBCHEM_CID'] == cid, 'PUBCHEM_EXT_DATASOURCE_SMILES'] = correct_isomeric_smiles.loc[correct_isomeric_smiles[0] == cid, 1].values[0]\n","\n","            f.write(f'===\\n')\n","            assay.to_csv(f'{data_folder}/before_finished/step_2/AID{AID}.csv', index=False)       "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bh4YuZIQsH_k","outputId":"da27dcab-e1bf-4f3e-ea07-16581fe6c517"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are some non-isomeric SMILES in AID 449739:\n","[2997662, 2997957, 2999888]\n","All SMILES in AID 489005 are isomeric\n","All SMILES in AID 493041 are isomeric\n","All SMILES in AID 493021 are isomeric\n","All SMILES in AID 493022 are isomeric\n","All SMILES in AID 493023 are isomeric\n"]}],"source":["non_isomeric_smi_cids = check_isomeric_smiles(AIDs)"]},{"cell_type":"markdown","metadata":{"id":"puAZ3wAdsH_k"},"source":["Note: Here they returned that three smiles in AID449739 might not be isomeric. This shows that the SMILES representation of some compounds in the given datasets might not be isomeric."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OVN0a5Z9sH_k"},"outputs":[],"source":["update_isomeric(AIDs, non_isomeric_smi_cids)"]},{"cell_type":"markdown","metadata":{"id":"ly-ZMzGQsH_k"},"source":["# 3. Import InChIs"]},{"cell_type":"markdown","metadata":{"id":"2S3JVqS9sH_k"},"source":["We would like to include standard InChI to diversify users' choice of which data they would like to use for their own benchmark."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Lp5dv34sH_k"},"outputs":[],"source":["# Create a new step folder:\n","if not os.path.exists(f'{data_folder}/before_finished/step_3'):\n","    os.makedirs(f'{data_folder}/before_finished/step_3')"]},{"cell_type":"markdown","metadata":{"id":"DN214Z1AsH_l"},"source":["Again, it is convenient to use the PubChem Identifier Exchange Service (https://pubchem.ncbi.nlm.nih.gov/idexchange/idexchange.cgi) with operator type \"same CID\" and Output IDs \"InChI\" to retrieve InChI from a given list of input CIDs. The same CID lists from STEP 2 could be used here. The resulted InChIs could be checked if being standard by indentifying the presence of 'InChI=1S' at the begining of each InChI string."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n4HMqLhasH_l"},"outputs":[],"source":["\"\"\"\n","CID lists (in \"step_2\" folder should be submitted to PubChem Identifier Exchange Service)\n","    Operator type: \"same CID\" \n","    Output IDs \"InChI\"\n","    Output method: \"Two column file showing each input output-correspondence\"\n","    Compression: \"No compression\"\n","InChI list should be saved into \"step_3\" folder, named as \"std_inchi_{AID}.txt\" \n","\"\"\"\n","# Import dataframes:\n","for AID in AIDs: \n","    exec(f'AID{AID} = pd.read_csv(\"{data_folder}/before_finished/step_2/AID{AID}.csv\")')\n","    exec(f'AID{AID}_InChI = pd.read_csv(\"{data_folder}/before_finished/step_3/std_inchi_{AID}.txt\", sep=\"\\\\t\", header=None)')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iPmmzLE4sH_l","outputId":"81f958c1-0639-4d57-d23c-270cc539d2ad"},"outputs":[{"name":"stdout","output_type":"stream","text":["All InChI in AID449739 are standard\n","All InChI in AID489005 are standard\n","All InChI in AID493041 are standard\n","All InChI in AID493021 are standard\n","All InChI in AID493022 are standard\n","All InChI in AID493023 are standard\n"]}],"source":["#Check if they are all standard InChI:\n","for AID in AIDs:\n","    check_inchi = f\"\"\"\n","non_standard_InChI = []\n","for i in range(len(AID{AID}_InChI[1])):\n","    if not AID{AID}_InChI[1][i].startswith('InChI=1S'):\n","        non_standard_InChI.append(AID{AID}_InChI[1][i])\n","if not non_standard_InChI:\n","    print('All InChI in AID{AID} are standard')\n","else:\n","    print('There are some non-standard InChI in AID{AID}')\n","    print(non_standard_InChI)\n","    print('===')\n","\"\"\"\n","    exec(check_inchi)"]},{"cell_type":"markdown","metadata":{"id":"YXA-E1ucsH_l"},"source":["Now we concatenate the InChIs in our tables:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HgfJwSMasH_l"},"outputs":[],"source":["# Update and save the files\n","for AID in AIDs: \n","    update_inchi = f\"\"\"\n","AID{AID}_InChI_dict = dict(zip(AID{AID}_InChI[0], AID{AID}_InChI[1]))\n","AID{AID}['InChI'] = AID{AID}[cid_col].map(AID{AID}_InChI_dict)\n","AID{AID}['InChI'] = AID{AID}['InChI'].astype(str)\n","AID{AID}[cid_col] = AID{AID}[cid_col].astype(int)\n","AID{AID}.to_csv(r\"{data_folder}/before_finished/step_3/AID{AID}.csv\", index=False)\n","\"\"\"\n","    exec(update_inchi)"]},{"cell_type":"markdown","metadata":{"id":"plVu7zlKsH_l"},"source":["# 4. Check duplicates"]},{"cell_type":"markdown","metadata":{"id":"QfAhRYQEsH_l"},"source":["When checking duplicates in the datasets, we would like to know if there are\n","1) Multiple identical molecules\n","2) Molecules with identical CID but different InChIs or SMILES\n","3) Molecules with identical InChI but with different CIDs or SMILES"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sRDopQJ7sH_m"},"outputs":[],"source":["#import:\n","for AID in AIDs:\n","    exec(f\"AID{AID} = pd.read_csv(r'{data_folder}/before_finished/step_3/AID{AID}.csv', sep=',', header=0)\")\n","\n","#Create a new step folder:\n","if not os.path.exists(f'{data_folder}/before_finished/step_4'):\n","    os.makedirs(f'{data_folder}/before_finished/step_4')"]},{"cell_type":"markdown","metadata":{"id":"F2a4frv5sH_m"},"source":["## 4.1. Checking identical molecules"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tAIV8v2isH_m","outputId":"0cdc8b4d-6fd0-42ca-b5f1-e9007aa597a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of AID449739 InChI duplicates:  40\n","Number of AID449739 SMILES duplicates:  28\n","Number of AID449739 CID duplicates:  28\n","Number of AID489005 InChI duplicates:  0\n","Number of AID489005 SMILES duplicates:  0\n","Number of AID489005 CID duplicates:  0\n","Number of AID493041 InChI duplicates:  0\n","Number of AID493041 SMILES duplicates:  0\n","Number of AID493041 CID duplicates:  0\n","Number of AID493021 InChI duplicates:  0\n","Number of AID493021 SMILES duplicates:  0\n","Number of AID493021 CID duplicates:  0\n","Number of AID493022 InChI duplicates:  0\n","Number of AID493022 SMILES duplicates:  0\n","Number of AID493022 CID duplicates:  0\n","Number of AID493023 InChI duplicates:  0\n","Number of AID493023 SMILES duplicates:  0\n","Number of AID493023 CID duplicates:  0\n"]}],"source":["#Return all duplicates by comparing InChI, SMILES, and CIDs:\n","for AID in AIDs:\n","    check_duplicate = f\"\"\"\n","AID{AID}_duplicates_InChI = AID{AID}[AID{AID}.duplicated(subset=['InChI'], keep=False)]\n","AID{AID}_duplicates_SMILES = AID{AID}[AID{AID}.duplicated(subset=[smi_col], keep=False)]\n","AID{AID}_duplicates_CIDs = AID{AID}[AID{AID}.duplicated(subset=[cid_col], keep=False)]\n","print('Number of AID{AID} InChI duplicates: ', len(AID{AID}_duplicates_InChI))\n","print('Number of AID{AID} SMILES duplicates: ', len(AID{AID}_duplicates_SMILES))\n","print('Number of AID{AID} CID duplicates: ', len(AID{AID}_duplicates_CIDs))\n","\"\"\"\n","    exec(check_duplicate)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eb6JmQjUsH_m"},"outputs":[],"source":["#write duplicates to a txt file: \n","with open(f'{data_folder}/before_finished/step_4/duplicates.txt', 'w') as f:\n","    for AID in AIDs: \n","        duplicates_InChI = eval(f'AID{AID}_duplicates_InChI')\n","        duplicates_SMILES = eval(f'AID{AID}_duplicates_SMILES')\n","        duplicates_CIDs = eval(f'AID{AID}_duplicates_CIDs')\n","        f.write(f'\\n\\nAID{AID} InChI duplicates:\\n')\n","        f.write(duplicates_InChI.to_string())\n","        f.write(f'\\nAID{AID} SMILES duplicates:\\n')\n","        f.write(duplicates_SMILES.to_string())\n","        f.write(f'\\nAID{AID} CID duplicates:\\n')\n","        f.write(duplicates_CIDs.to_string())"]},{"cell_type":"markdown","metadata":{"id":"qn5u-wi-sH_m"},"source":["## 4.2. Same CIDs but different chemical representations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QWkV4wvHsH_m"},"outputs":[],"source":["#reindex\n","for AID in AIDs:\n","    exec(f\"AID{AID}_duplicates_CIDs.reset_index(drop=True, inplace=True)\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B2TyloVlsH_m"},"outputs":[],"source":["with open(f'{data_folder}/before_finished/step_4/sameCID_different_others.txt', 'w') as f:\n","    for AID in AIDs: \n","        sameCID_differentInChI = []\n","        sameCID_differentSMILES = []\n","        duplicates_CIDs = eval(f'AID{AID}_duplicates_CIDs')\n","        for i in range(len(duplicates_CIDs[cid_col])):\n","            for j in range(i+1, len(duplicates_CIDs[cid_col])):\n","                if duplicates_CIDs[cid_col][i] == duplicates_CIDs[cid_col][j]:\n","                    if duplicates_CIDs['InChI'][i] != duplicates_CIDs['InChI'][j]:\n","                        sameCID_differentInChI.append((duplicates_CIDs[cid_col][i], duplicates_CIDs[cid_col][j]))\n","                    if duplicates_CIDs[smi_col][i] != duplicates_CIDs[smi_col][j]:\n","                        sameCID_differentSMILES.append((duplicates_CIDs[cid_col][i], duplicates_CIDs[cid_col][j]))\n","\n","        if sameCID_differentInChI == []:\n","            f.write(f'No duplicate CIDs with different InChIs in AID{AID}\\n')\n","        else:\n","            f.write('Found duplicate CIDs with different InChIs in AID{AID}:\\n')\n","            f.write('\\n'.join(str(item) for item in sameCID_differentInChI))\n","            f.write(\"\\n\")\n","        \n","        if sameCID_differentSMILES == []:\n","            f.write(f'No duplicate CIDs with different SMILES in AID{AID}\\n')\n","        else:\n","            f.write(f'Found duplicate CIDs with different SMILES in AID{AID}:\\n')\n","            f.write('\\n'.join(str(item) for item in sameCID_differentSMILES))\n","            f.write(\"\\n\")\n","        f.write(\"===\\n\")"]},{"cell_type":"markdown","metadata":{"id":"YXMZth-hsH_n"},"source":["## 4.3. Same InChI but with different CIDs or SMILES"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lSC66XjIsH_n"},"outputs":[],"source":["#reindex\n","for AID in AIDs:\n","    exec(f\"AID{AID}_duplicates_InChI.reset_index(drop=True, inplace=True)\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AWSsrIUxsH_n"},"outputs":[],"source":["with open(f'{data_folder}/before_finished/step_4/sameInChI_different_others.txt', 'w') as f:\n","    for AID in AIDs: \n","        sameInChI_differentCID = []\n","        sameInChI_differentSMILES = []\n","        duplicates_InChI = eval(f'AID{AID}_duplicates_InChI')\n","        for i in range(len(duplicates_InChI['InChI'])):\n","            for j in range(i+1, len(duplicates_InChI['InChI'])):\n","                if duplicates_InChI['InChI'][i] == duplicates_InChI['InChI'][j]:\n","                    if duplicates_InChI[cid_col][i] != duplicates_InChI[cid_col][j]:\n","                        sameInChI_differentCID.append((duplicates_InChI[cid_col][i], duplicates_InChI[cid_col][j]))\n","                    if duplicates_InChI[smi_col][i] != duplicates_InChI[smi_col][j]:\n","                        sameInChI_differentSMILES.append((duplicates_InChI[cid_col][i], duplicates_InChI[cid_col][j]))\n","        \n","        if sameInChI_differentCID == []:\n","            f.write(f'No duplicate InChIs with different CIDs in AID{AID}\\n')\n","        else:\n","            f.write('Found duplicate InChIs with different CIDs in AID{AID}:\\n')\n","            f.write('\\n'.join(str(item) for item in sameInChI_differentCID))\n","            f.write(\"\\n\")\n","        \n","        if sameInChI_differentSMILES == []:\n","            f.write(f'No duplicate InChIs with different SMILES in AID{AID}\\n')\n","        else:\n","            f.write(f'Found duplicate InChIs with different SMILES in AID{AID}:\\n')\n","            f.write('\\n'.join(str(item) for item in sameInChI_differentSMILES))\n","            f.write(\"\\n\")\n","        f.write(\"===\\n\")"]},{"cell_type":"markdown","metadata":{"id":"1tpQsjzesH_n"},"source":["## 4.4. Same SMILES but with different CIDs or SMILES"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ONqm-HNWsH_n"},"outputs":[],"source":["#reindex\n","for AID in AIDs:\n","    exec(f\"AID{AID}_duplicates_SMILES.reset_index(drop=True, inplace=True)\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zYPGOAlTsH_n"},"outputs":[],"source":["with open(f'{data_folder}/before_finished/step_4/sameSMILES_different_others.txt', 'w') as f:\n","    for AID in AIDs: \n","        sameSMILES_differentCID = []\n","        sameSMILES_differentInChI = []\n","        duplicates_SMILES = eval(f'AID{AID}_duplicates_SMILES')\n","        for i in range(len(duplicates_SMILES[smi_col])):\n","            for j in range(i+1, len(duplicates_SMILES[smi_col])):\n","                if duplicates_SMILES[smi_col][i] == duplicates_SMILES[smi_col][j]:\n","                    if duplicates_SMILES[cid_col][i] != duplicates_SMILES[cid_col][j]:\n","                        sameSMILES_differentCID.append((duplicates_SMILES[cid_col][i], duplicates_SMILES[cid_col][j]))\n","                    if duplicates_SMILES['InChI'][i] != duplicates_SMILES['InChI'][j]:\n","                        sameSMILES_differentInChI.append((duplicates_SMILES[cid_col][i], duplicates_SMILES[cid_col][j]))\n","        \n","        if sameSMILES_differentCID == []:\n","            f.write(f'No duplicate SMILES with different CIDs in AID{AID}\\n')\n","        else:\n","            f.write(f'Found duplicate SMILES with different CIDs in AID{AID}:\\n')\n","            f.write('\\n'.join(str(item) for item in sameSMILES_differentCID))\n","            f.write(\"\\n\")\n","        \n","        if sameSMILES_differentInChI == []:\n","            f.write(f'No duplicate SMILES with different InChIs in AID{AID}\\n')\n","        else:\n","            f.write(f'Found duplicate SMILES with different InChIs in AID{AID}:\\n')\n","            f.write('\\n'.join(str(item) for item in sameSMILES_differentInChI))\n","            f.write(\"\\n\")\n","        f.write(\"===\\n\")"]},{"cell_type":"markdown","metadata":{"id":"wIU2UFfRsH_n"},"source":["## 4.5. Drop duplicates"]},{"cell_type":"markdown","metadata":{"id":"4ldUTh9GsH_o"},"source":["When dropping duplicates, we will keep the first molecule in a pair or a group of duplicates. For example, here there are 12 duplicates (6 pairs) so we keep 6 of them."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9xnDatyKsH_o","outputId":"94359a38-73f7-469a-848d-3a71c0adb3db"},"outputs":[{"name":"stdout","output_type":"stream","text":["No more duplicate InChI in AID449739\n","No more duplicate InChI in AID489005\n","No more duplicate InChI in AID493041\n","No more duplicate InChI in AID493021\n","No more duplicate InChI in AID493022\n","No more duplicate InChI in AID493023\n"]}],"source":["# Keep only the first duplicate in the dataframes:\n","for AID in AIDs: \n","    exec(f\"AID{AID}.drop_duplicates(subset=['InChI'], keep='first', inplace=True)\")\n","\n","    last_check = f\"\"\"\n","if len(AID{AID}[AID{AID}.duplicated(subset=['InChI'], keep=False)]) == 0:\n","    print('No more duplicate InChI in AID{AID}')\n","else:\n","    print('There are still duplicate InChI in AID{AID}')   \n","    \"\"\"\n","    exec(last_check)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dlU--t_lsH_p","outputId":"dc0531f3-9c64-46e0-8f9a-b95fa0540200"},"outputs":[{"name":"stdout","output_type":"stream","text":["No more duplicate SMILES in AID449739\n","No more duplicate SMILES in AID489005\n","No more duplicate SMILES in AID493041\n","No more duplicate SMILES in AID493021\n","No more duplicate SMILES in AID493022\n","No more duplicate SMILES in AID493023\n"]}],"source":["for AID in AIDs: \n","    last_check = f\"\"\"\n","if len(AID{AID}[AID{AID}.duplicated(subset=[smi_col], keep=False)]) == 0:\n","    print('No more duplicate SMILES in AID{AID}')\n","else:\n","    print('There are still duplicate SMILES in AID{AID}')   \n","    \"\"\"\n","    exec(last_check)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"py7j6QBYsH_p","outputId":"3a77f2dc-f1a4-497f-ecde-403de1a3c5d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["No more duplicate CID in AID449739\n","No more duplicate CID in AID489005\n","No more duplicate CID in AID493041\n","No more duplicate CID in AID493021\n","No more duplicate CID in AID493022\n","No more duplicate CID in AID493023\n"]}],"source":["for AID in AIDs: \n","    last_check = f\"\"\"\n","if len(AID{AID}[AID{AID}.duplicated(subset=[cid_col], keep=False)]) == 0:\n","    print('No more duplicate CID in AID{AID}')\n","else:\n","    print('There are still duplicate CID in AID{AID}')   \n","    \"\"\"\n","    exec(last_check)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zZQo_ksZsH_p"},"outputs":[],"source":["# Save the dataframes to csv:\n","for AID in AIDs: \n","    exec(f\"AID{AID}.to_csv(r'{data_folder}/before_finished/step_4/AID{AID}.csv', index=False)\")"]},{"cell_type":"markdown","metadata":{"id":"c4E1T8hvsH_p"},"source":["# 5. Hierarchical Curation"]},{"cell_type":"markdown","metadata":{"id":"by5eHu8nsH_p"},"source":["For the hierarchical curation, there are some rules:\n","\n","(1) All assays used should be on the same or close species/cell lines. Optimally, they should also be from the same project/laboratory.\n","\n","(2) Primary actives (PrA) will have a large false-positive rate. Therefore, they should be tested in follow-up confirmatory screens (optimally dose-reponse).\n","\n","(3) Actives could be promiscuous. Therefore, it is optimal to have counter-screens on different targets to test specificity.\n","\n","(4) For some projects, compounds were tested in multiple rounds. Therefore, assays often have hierarchical relations. From a single primary screen (Pr), active compounds (Pr_A) could be tested in multiple rounds of confirmatory screens (Cf_1, Cf_2, ..., Cf_final) or counter screens (Ct_1, Ct_2, etc.). Actives from confirmatory screens (Cf_actives) have a higher possibility of being true active. If an active compound is tested active in counter screens (Cf_actives), it is likely to be a promiscuous compound and should not be included.\n","\n","(4) It is important to know the relationship between assays. Active sets from downstream screens always have a lower false-positive rate than active sets from upstream screens due to better assay technologies on a smaller set of compounds. Therefore, final hits should be taken from the intersection of the very last confirmatory assays, without tested active in any counter-screen:\n","Final hits = [Cf_final1_actives ∩ Cf_final2_actives ∩ ...] \\ [Ct_1_actives ∪ Ct_2_actives ∪ ...]\n","\n","However, if the confirmatory assays are unrelated (tested on different set of compounds), then we might have to take the union of their active sets instead of the intersections as in this formula.\n","\n","(5) The hierarchical relations should be inspected carefully to see if follow-up confirmatory screens include extra compounds (Ex) that were not tested in earlier screens or tested inactive in earlier screens. If exist, these compounds require manual inspection.\n","\n","(6) Final inactives should be taken from primary inactives (Pr_inactives) (not inconclusive, unspecified, or probes), plus extra compounds that were tested inactive in conformatory screens (Ex_inactives), if justified.\n","Final inactives = Pr_inactives ∪ Ex_inactives"]},{"cell_type":"markdown","metadata":{"id":"1zC182PMsH_q"},"source":["## 5.1. Classify groups of compounds in each assay by activities"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BYTe5r7-sH_q"},"outputs":[],"source":["path = f'{data_folder}/before_finished/step_4'\n","keynumbers = [449739, 493021, 489005, 493022, 493023, 493041] # specify the keynumbers you want to import\n","\n","for keynumber in keynumbers:\n","    filename = os.path.join(path, f'AID{keynumber}.csv')\n","    if os.path.exists(filename):\n","        df = pd.read_csv(filename, index_col=None, header=0)\n","        exec(f'AID{keynumber} = df')\n","        exec(f'AID{keynumber}_active = df[df[\"PUBCHEM_ACTIVITY_OUTCOME\"]==\"Active\"]')\n","        exec(f'AID{keynumber}_inactive = df[df[\"PUBCHEM_ACTIVITY_OUTCOME\"]==\"Inactive\"]')\n","        exec(f'AID{keynumber}_inconclusive = df[df[\"PUBCHEM_ACTIVITY_OUTCOME\"]==\"Inconclusive\"]')\n","        exec(f'AID{keynumber}_unspecified = df[df[\"PUBCHEM_ACTIVITY_OUTCOME\"]==\"Unspecified\"]')\n","        exec(f'AID{keynumber}_probe = df[df[\"PUBCHEM_ACTIVITY_OUTCOME\"]==\"Probe\"]')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XeV5wAXBsH_q","outputId":"d3b9a30e-75f1-400c-9e6c-985f1001deb0"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>AID</th>\n","      <th>Tested Compounds</th>\n","      <th>Active</th>\n","      <th>Inactive</th>\n","      <th>Inconclusive</th>\n","      <th>Unspecified</th>\n","      <th>Probe</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AID449739</td>\n","      <td>104722</td>\n","      <td>4230</td>\n","      <td>100492</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>AID493021</td>\n","      <td>17</td>\n","      <td>17</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>AID489005</td>\n","      <td>895</td>\n","      <td>703</td>\n","      <td>192</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>AID493022</td>\n","      <td>44</td>\n","      <td>41</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>AID493023</td>\n","      <td>29</td>\n","      <td>25</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>AID493041</td>\n","      <td>32</td>\n","      <td>24</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         AID  Tested Compounds  Active  Inactive  Inconclusive  Unspecified  \\\n","0  AID449739            104722    4230    100492             0            0   \n","1  AID493021                17      17         0             0            0   \n","2  AID489005               895     703       192             0            0   \n","3  AID493022                44      41         3             0            0   \n","4  AID493023                29      25         4             0            0   \n","5  AID493041                32      24         8             0            0   \n","\n","   Probe  \n","0      0  \n","1      0  \n","2      0  \n","3      0  \n","4      0  \n","5      0  "]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["#Create a df with first column the variables name, and the second column the number of rows:\n","df = pd.DataFrame(columns=['AID', 'Tested Compounds', 'Active', 'Inactive', 'Inconclusive', 'Unspecified', 'Probe'])\n","for keynumber in keynumbers:\n","    exec(f'df.loc[len(df)] = [\"AID{keynumber}\", len(AID{keynumber}), len(AID{keynumber}_active), len(AID{keynumber}_inactive), len(AID{keynumber}_inconclusive), len(AID{keynumber}_unspecified), len(AID{keynumber}_probe)]')\n","df"]},{"cell_type":"markdown","metadata":{"id":"Tl17HyJJsH_q"},"source":["## 5.2. Check the hierachical relations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RdU8PA3CsH_q"},"outputs":[],"source":["def check_is_in(downstream, upstream):\n","    downstream_in_upstream = downstream[downstream[cid_col].isin(upstream[cid_col])]\n","    downstream_notin_upstream = downstream[~downstream[cid_col].isin(upstream[cid_col])]\n","    return downstream_in_upstream, downstream_notin_upstream"]},{"cell_type":"markdown","metadata":{"id":"zn_9xMU7sH_r"},"source":["### Flow: AID449739 (Pr), AID493021 (Cf_1a), AID489005 (Cf_1b), AID493022 (Cf_2a), AID493023 (Cf_2b), AID493041 (Cf_2c)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CqZC_pywsH_r","outputId":"ede70456-9926-4a41-8f5c-c918c0523d96"},"outputs":[{"name":"stdout","output_type":"stream","text":["Among AID493021, 0 were tested inactive in AID449739. Among these, 0 became active\n","Among AID493021, 0 were not tested in the AID449739. Among these, 0 became active\n","Among AID489005, 0 were tested inactive in AID449739. Among these, 0 became active\n","Among AID489005, 0 were not tested in the AID449739. Among these, 0 became active\n"]}],"source":["# Check between AID493021 and AID449739\n","a1, a2 = check_is_in(AID493021, AID449739_inactive)\n","a3, a4 = check_is_in(a1, AID493021_active)\n","a5, a6 = check_is_in(AID493021, AID449739)\n","a7, a8 = check_is_in(a6, AID493021_active)\n","print(f'Among AID493021, {len(a1)} were tested inactive in AID449739. Among these, {len(a3)} became active')\n","print(f'Among AID493021, {len(a6)} were not tested in the AID449739. Among these, {len(a7)} became active')\n","\n","# Check between AID489005 and AID449739\n","b1, b2 = check_is_in(AID489005, AID449739_inactive)\n","b3, b4 = check_is_in(a1, AID489005_active)\n","b5, b6 = check_is_in(AID489005, AID449739)\n","b7, b8 = check_is_in(a6, AID489005_active)\n","print(f'Among AID489005, {len(b1)} were tested inactive in AID449739. Among these, {len(b3)} became active')\n","print(f'Among AID489005, {len(b6)} were not tested in the AID449739. Among these, {len(b7)} became active')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yUl-IJwFsH_r","outputId":"1803566f-7c08-486c-c768-e89931484167"},"outputs":[{"name":"stdout","output_type":"stream","text":["Among AID493022, 0 were tested inactive in AID449739. Among these, 0 became active\n","Among AID493022, 44 were not tested in the AID449739. Among these, 41 became active\n"]}],"source":["c1, c2 = check_is_in(AID493022, AID449739_inactive)\n","c3, c4 = check_is_in(c1, AID493022_active)\n","c5, c6 = check_is_in(AID493022, AID449739)\n","c7, c8 = check_is_in(c6, AID493022_active)\n","print(f'Among AID493022, {len(c1)} were tested inactive in AID449739. Among these, {len(c3)} became active')\n","print(f'Among AID493022, {len(c6)} were not tested in the AID449739. Among these, {len(c7)} became active')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1zgjPef6sH_r","outputId":"89d7af4f-6c06-4140-8b5b-d7eff30b8f6e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Among AID493023, 0 were tested inactive in AID449739. Among these, 0 became active\n","Among AID493023, 29 were not tested in the AID449739. Among these, 25 became active\n"]}],"source":["d1, d2 = check_is_in(AID493023, AID449739_inactive)\n","d3, d4 = check_is_in(d1, AID493023_active)\n","d5, d6 = check_is_in(AID493023, AID449739)\n","d7, d8 = check_is_in(d6, AID493023_active)\n","print(f'Among AID493023, {len(d1)} were tested inactive in AID449739. Among these, {len(d3)} became active')\n","print(f'Among AID493023, {len(d6)} were not tested in the AID449739. Among these, {len(d7)} became active')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zDi8iMCAsH_r","outputId":"7046df63-1cb9-400d-f31e-cebac72fc2de"},"outputs":[{"name":"stdout","output_type":"stream","text":["Among AID493041, 0 were tested inactive in AID449739. Among these, 0 became active\n","Among AID493041, 32 were not tested in the AID449739. Among these, 24 became active\n"]}],"source":["e1, e2 = check_is_in(AID493041, AID449739_inactive)\n","e3, e4 = check_is_in(e1, AID493041_active)\n","e5, e6 = check_is_in(AID493041, AID449739)\n","e7, e8 = check_is_in(e6, AID493041_active)\n","print(f'Among AID493041, {len(e1)} were tested inactive in AID449739. Among these, {len(e3)} became active')\n","print(f'Among AID493041, {len(e6)} were not tested in the AID449739. Among these, {len(e7)} became active')"]},{"cell_type":"markdown","metadata":{"id":"57PElJdVsH_r"},"source":["Here, the two large confirmatory datasets AID493021 and AID489005 have no problem. None of the compounds tested in the rest three confirmatory assays (AID493022, AID493023, and AID493041) were not even tested from primary screen. The assays protocol showed that these are newly synthesized molecules similar to confirmed actives to test as potential hits.\n","\n","The potential final hits therefore should be any compound that were active in all confirmatory screens: AID493021, AID489005, AID493022, AID493023, and AID493041. Inactives should be taken from the primary inactives, plus some extra newly synthesized compounds that were confirmed to be inactive in the three small confirmatory screens."]},{"cell_type":"markdown","metadata":{"id":"opzrC3bdsH_s"},"source":["## 5.3. Export the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n9gjBWydsH_s","outputId":"f672853d-8644-4f44-e918-9294a06930e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["We end up with 791 potential hits.\n"]}],"source":["# concatenate all the dataframes to confirmed hits:\n","confirmed_actives = pd.concat([AID493021_active, AID489005_active, AID493022_active, AID493023_active, AID493041_active])\n","confirmed_actives = confirmed_actives.drop_duplicates(subset=[cid_col], keep='first')\n","potential_actives = confirmed_actives\n","print(f'We end up with {len(confirmed_actives)} potential hits.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NeQXty4zsH_s","outputId":"303ca85e-7460-4f5d-a2da-c6914ba4d519"},"outputs":[{"name":"stdout","output_type":"stream","text":["We end up with 100507 potential inactives.\n"]}],"source":["potential_inactives = pd.concat([AID449739_inactive, c8, d8, e8])\n","potential_inactives = potential_inactives.drop_duplicates(subset=[cid_col], keep='first')\n","print(f'We end up with {len(potential_inactives)} potential inactives.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZQNfNeGksH_s"},"outputs":[],"source":["if not os.path.exists(f'{data_folder}/before_finished/step_5'):\n","    os.makedirs(f'{data_folder}/before_finished/step_5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rv3ZiISTsH_s"},"outputs":[],"source":["#export the potential hits and inactives to csv:\n","potential_actives.to_csv(f'{data_folder}/before_finished/step_5/potential_actives.csv', index=False)\n","potential_inactives.to_csv(f'{data_folder}/before_finished/step_5/potential_inactives.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"aGeGKZ-ssH_s"},"source":["# 6. RDkit Parse Check"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GKAXVmfUsH_t"},"outputs":[],"source":["potential_actives = pd.read_csv(f'{data_folder}/before_finished/step_5/potential_actives.csv', sep=',', header=0)\n","potential_inactives = pd.read_csv(f'{data_folder}/before_finished/step_5/potential_inactives.csv', sep=',', header=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hQeRfAU0sH_t","outputId":"16193d16-5a6e-4612-8014-50aea60074d6"},"outputs":[{"name":"stdout","output_type":"stream","text":["No problems detected\n","No problems detected\n"]}],"source":["problems_actives, cannot_parse_actives = filters.rdkit_parse(potential_actives, smi_col, cid_col)\n","problems_inactives, cannot_parse_inactives = filters.rdkit_parse(potential_inactives, smi_col, cid_col)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YcF8qrwZsH_t"},"outputs":[],"source":["#Create a new step folder:\n","if not os.path.exists(f'{data_folder}/before_finished/step_6'):\n","    os.makedirs(f'{data_folder}/before_finished/step_6')\n","\n","with open(f'{data_folder}/before_finished/step_6/problem_list_actives.txt', 'w') as f:\n","    f.write(\"Problems:\\n\")\n","    for item in problems_actives:\n","        f.write(\"%s\\n\" % item)\n","    f.write(\"Cannot parse:\\n\")\n","    for item in cannot_parse_actives:\n","        f.write(\"%s\\n\" % item)\n","\n","with open(f'{data_folder}/before_finished/step_6/problem_list_inactives.txt', 'w') as f:\n","    f.write(\"Problems:\\n\")\n","    for item in problems_inactives:\n","        f.write(\"%s\\n\" % item)\n","    f.write(\"Cannot parse:\\n\")\n","    for item in cannot_parse_inactives:\n","        f.write(\"%s\\n\" % item)"]},{"cell_type":"markdown","metadata":{"id":"Am1MHdvJsH_t"},"source":["Our dataset returned no problem or non-parsable molecule."]},{"cell_type":"markdown","metadata":{"id":"b2g7zRiBsH_t"},"source":["# 7. Inorganics Filter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5IUrDVV2sH_u"},"outputs":[],"source":["# Import data\n","potential_actives = pd.read_csv(f'{data_folder}/before_finished/step_5/potential_actives.csv', sep=',', header=0)\n","potential_inactives = pd.read_csv(f'{data_folder}/before_finished/step_5/potential_inactives.csv', sep=',', header=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UomKuiJcsH_u","outputId":"71764b6f-e297-447e-c922-a09dd1d3dbd4"},"outputs":[{"name":"stdout","output_type":"stream","text":["In hits, there are 791 organic molecules and 0 inorganic molecules\n","In inactives, there are 100507 organic molecules and 0 inorganic molecules\n"]}],"source":["inorganic_actives_cids, organic_actives_cids = filters.inorganic_filter(potential_actives, smi_col, cid_col, type='smiles')\n","print(f'In hits, there are {len(organic_actives_cids)} organic molecules and {len(inorganic_actives_cids)} inorganic molecules')\n","\n","inorganic_inactives_cids, organic_inactives_cids = filters.inorganic_filter(potential_inactives, smi_col, cid_col, type='smiles')\n","print(f'In inactives, there are {len(organic_inactives_cids)} organic molecules and {len(inorganic_inactives_cids)} inorganic molecules')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9fbDm3gcsH_u"},"outputs":[],"source":["#Create a new step folder:\n","if not os.path.exists(f'{data_folder}/before_finished/step_7'):\n","    os.makedirs(f'{data_folder}/before_finished/step_7')\n","\n","with open(f'{data_folder}/before_finished/step_7/inorganic.txt', 'w') as f:\n","    f.write(\"Actives:\\n\")\n","    for item in inorganic_actives_cids:\n","        f.write(\"%s\\n\" % item)\n","    f.write(\"\\n\\nInactives:\\n\")\n","    for item in inorganic_inactives_cids:\n","        f.write(\"%s\\n\" % item)\n","\n","# Drop inorganics: \n","potential_actives = potential_actives[~potential_actives[cid_col].isin(inorganic_actives_cids)]\n","potential_inactives = potential_inactives[~potential_inactives[cid_col].isin(inorganic_inactives_cids)]\n","\n","#save: \n","potential_actives.to_csv(f'{data_folder}/before_finished/step_7/organic_actives.csv', index=False)\n","potential_inactives.to_csv(f'{data_folder}/before_finished/step_7/organic_inactives.csv', index=False)\n","\n","print('Dropped inorganic and saved organic compounds into step_7 folder.')"]},{"cell_type":"markdown","metadata":{"id":"wrb9ysBXsH_v"},"source":["# 8. Mixture Handling"]},{"cell_type":"markdown","metadata":{"id":"d6NxyOdMsH_v"},"source":["## 8.1. Quick check"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XcqtwCDBsH_v"},"outputs":[],"source":["#import: \n","organic_actives = pd.read_csv(f'{data_folder}/before_finished/step_7/organic_actives.csv', sep=',', header=0)\n","organic_inactives = pd.read_csv(f'{data_folder}/before_finished/step_7/organic_inactives.csv', sep=',', header=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YtFtUMjAsH_v","outputId":"c4be49bd-9d97-4a5b-a48c-eb3c75d6020f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of mixtures in hits is 27\n","Total number of mixtures in inactives is 3659\n"]}],"source":["filters.quick_check_mixtures('hits', organic_actives[smi_col])\n","filters.quick_check_mixtures('inactives', organic_inactives[smi_col])"]},{"cell_type":"markdown","metadata":{"id":"DO9zQ5RvsH_w"},"source":["## 8.2. Handling mixture"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IyaxhCTbsH_w","outputId":"e4d1d43c-784a-443a-a893-42471f488b54"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cannot decide between ['CN(C)C1=NC2=CC=CC=C2C(=C1)N', 'C1=C(NC(=O)NC1=O)C(=O)O'] for CID 646688\n","Cannot decide between ['C1C2(CN3CN1CN(C2)C3)N', 'C1=CC(=CN=C1)C(=O)O'] for CID 648270\n","Cannot decide between ['CN(C)C1=NC2=C(CCC2)C(=C1)N', 'C1=C(C=NC=C1O)C(=O)O'] for CID 652177\n","Cannot decide between ['CC1=NC2=C(S1)C3=CC=CC=C3C=C2', 'C1=C(C=C(C(=C1[N+](=O)[O-])O)[N+](=O)[O-])[N+](=O)[O-]'] for CID 654127\n","Big organic molecule for CID 657180 does not pass Lipinski's rule of five\n","Cannot decide between ['C1CC1C(C2CC2)NC3=NCCO3', 'C(=C/C(=O)O)\\\\C(=O)O'] for CID 5388964\n","Cannot decide between ['CN1C(=O)C2=C(N=C(N2)Cl)N(C1=O)C(=O)[O-]', 'CN(C)CCOC(C1=CC=CC=C1)C2=CC=CC=C2'] for CID 657227\n","Cannot decide between ['CC[N+](C)(C)CC1=CC=CC=C1Br', 'CC1=CC=C(C=C1)S(=O)(=O)[O-]'] for CID 6100\n","Cannot decide between ['C1CN(CCN1CCOCCO)C(C2=CC=CC=C2)C3=CC=C(C=C3)Cl', 'C1=CC=C2C(=C1)C=C(C(=C2CC3=C(C(=CC4=CC=CC=C43)C(=O)O)O)O)C(=O)O'] for CID 25096\n","Big organic molecule for CID 5284439 does not pass Lipinski's rule of five\n","Cannot decide between ['CC1=NC2=C(O1)C3=CC=CC=C3C=C2', 'C1=C(C=C(C(=C1[N+](=O)[O-])O)[N+](=O)[O-])[N+](=O)[O-]'] for CID 3241713\n","Big organic molecule for CID 3244813 does not pass Lipinski's rule of five\n","Big organic molecule for CID 8566 does not pass Lipinski's rule of five\n","Big organic molecule for CID 227456 does not pass Lipinski's rule of five\n","Cannot decide between ['CNC[C@@H](C1=CC(=C(C=C1)O)O)O', 'C(C(C(=O)O)O)(C(=O)O)O'] for CID 6852374\n","Cannot decide between ['C1CCC(C(C1)N)N', 'Cl[Pt]Cl'] for CID 151689\n","Big organic molecule for CID 6420009 does not pass Lipinski's rule of five\n","Cannot decide between ['CCN(CC)C(=O)N1CCN(CC1)C', 'C(C(=O)O)C(CC(=O)O)(C(=O)O)O'] for CID 15432\n","Cannot decide between ['CC1=C(SC=C1)/C=C/C2=NCCCN2C', 'C(C(C(=O)O)O)(C(=O)O)O'] for CID 6419965\n","Big organic molecule for CID 62881 does not pass Lipinski's rule of five\n","Cannot decide between ['CC(C)NC[C@H](C1=CC(=C(C=C1)O)O)O', 'C(C(C(=O)O)O)(C(=O)O)O'] for CID 6852409\n","Cannot decide between ['C(CS)N', 'Cl'] for CID 9082\n","Big organic molecule for CID 9549148 does not pass Lipinski's rule of five\n","Cannot decide between ['CC1=NC(CC2=CC=CC=C12)(C)C', 'C1=CC=C(C(=C1)C(=O)O)O'] for CID 9549466\n","Big organic molecule for CID 9549634 does not pass Lipinski's rule of five\n","Big organic molecule for CID 9549642 does not pass Lipinski's rule of five\n","Cannot decide between ['CCCC1=NCCN2C1=CC=C2', 'C(=C/C(=O)O)\\\\C(=O)O'] for CID 5717182\n","Big organic molecule for CID 135512395 does not pass Lipinski's rule of five\n","Cannot decide between ['CSC1=NC=C(C(=N1)C(=O)[O-])Cl', 'C1=CC=C(C=C1)CC[NH3+]'] for CID 9552033\n","Big organic molecule for CID 11948864 does not pass Lipinski's rule of five\n","Big organic molecule for CID 135490316 does not pass Lipinski's rule of five\n","Big organic molecule for CID 5729990 does not pass Lipinski's rule of five\n","Big organic molecule for CID 135712454 does not pass Lipinski's rule of five\n","Big organic molecule for CID 16219228 does not pass Lipinski's rule of five\n","Big organic molecule for CID 9896684 does not pass Lipinski's rule of five\n","Big organic molecule for CID 23723054 does not pass Lipinski's rule of five\n","Big organic molecule for CID 23581804 does not pass Lipinski's rule of five\n","Big organic molecule for CID 3005572 does not pass Lipinski's rule of five\n","Big organic molecule for CID 9847786 does not pass Lipinski's rule of five\n","Big organic molecule for CID 23581803 does not pass Lipinski's rule of five\n"]}],"source":["processed_actives, removed_actives, small_organic_actives, small_inorganic_actives, not_lipinski_actives, cleaned_actives = filters.process_smi_mixtures(organic_actives, smi_col, cid_col)\n","processed_inactives, removed_inactives, small_organic_inactives, small_inorganic_inactives, not_lipinski_inactives, cleaned_inactives = filters.process_smi_mixtures(organic_inactives, smi_col, cid_col)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I9h8E1swsH_w"},"outputs":[],"source":["# Create a new step folder\n","if not os.path.exists(f'{data_folder}/before_finished/step_8'):\n","    os.makedirs(f'{data_folder}/before_finished/step_8')\n","\n","#Generate df with the smiles column in the cleaned_actives or cleaned_inactives dictionary:\n","cleaned_actives_df = pd.DataFrame(list(cleaned_actives.values()), columns=[smi_col])\n","cleaned_inactives_df = pd.DataFrame(list(cleaned_inactives.values()), columns=[smi_col])\n","\n","#Export the cleaned hits and inactives to csv:\n","cleaned_actives_df.to_csv(f'{data_folder}/before_finished/step_8/cleaned_mixtures_actives.csv', index=False, header=False)\n","cleaned_inactives_df.to_csv(f'{data_folder}/before_finished/step_8/cleaned_mixtures_inactives.csv', index=False, header=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L7cUY8HbsH_x","outputId":"6f1171a8-836d-4eab-d3b8-af1cd718156b"},"outputs":[],"source":["processed_hits_df = filters.process_mixture_df('actives_Cav3', organic_actives, processed_actives, removed_actives, small_organic_actives, small_inorganic_actives, smi_col, cid_col)\n","processed_inactives_df = filters.process_mixture_df('inactives_Cav3', organic_inactives, processed_inactives, removed_inactives, small_organic_inactives, small_inorganic_inactives, smi_col, cid_col)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SgKnjt62sH_x","outputId":"05ed7dfe-5b21-4bad-d9a4-2dba564278d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataframes saved successfully\n"]}],"source":["with open(f'{data_folder}/before_finished/step_8/mixture.txt', 'w') as f:\n","    f.write(f\"\"\"\n","Hits before processing: {len(organic_actives)}\n","Hits before processing: {len(organic_actives)}\n","Hits after processing: {len(processed_hits_df)}\n","Mixtures detected: {len(removed_actives)}\n","Mixtures with small inorganic molecules: {len(small_inorganic_actives)}\n","Mixtures with big organic molecules passing Lipinski: {len(small_organic_actives)}\n","Mixtures with big organic molecules not passing Lipinski: {len(not_lipinski_actives)}\n","\n","Inactives before processing: {len(organic_inactives)}\n","Inactives after processing: {len(processed_inactives_df)}\n","Mixtures detected: {len(removed_inactives)}\n","Mixtures with small inorganic molecules: {len(small_inorganic_inactives)}\n","Mixtures with big organic molecules passing Lipinski: {len(small_organic_inactives)}\n","Mixtures with big organic molecules not passing Lipinski: {len(not_lipinski_inactives)}\n","\"\"\")\n","\n","# Save the processed dataframes to csv\n","processed_hits_df.to_csv(f'{data_folder}/before_finished/step_8/post8_actives.csv', index=False)\n","processed_inactives_df.to_csv(f'{data_folder}/before_finished/step_8/post8_inactives.csv', index=False)\n","\n","print('Dataframes saved successfully')"]},{"cell_type":"markdown","metadata":{"id":"upLK5Zo1sH_x"},"source":["# 9. Neutralize & 10. Aromatize Molecules"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IYv1YHSXsH_x"},"outputs":[],"source":["# Create a new step folder:\n","if not os.path.exists(f'{data_folder}/before_finished/step_9_10'):\n","    os.makedirs(f'{data_folder}/before_finished/step_9_10')\n","\n","#import:\n","pre9_actives = pd.read_csv(f'{data_folder}/before_finished/step_8/post8_actives.csv', sep=',', header=0)\n","pre9_inactives = pd.read_csv(f'{data_folder}/before_finished/step_8/post8_inactives.csv', sep=',', header=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y-ECrJ98sH_y"},"outputs":[],"source":["updated_smi = []\n","\n","#Update dataset with neutralized, aromatic SMILES\n","for smi in pre9_actives[smi_col]: \n","    mol = Chem.MolFromSmiles(smi)\n","    mol_neu = utils.neutralize_atoms(mol)\n","    smi_arom = utils.aromatize_smile(mol_neu)\n","    updated_smi.append(smi_arom)\n","    \n","#update the smiles in this df\n","pre9_actives[smi_col] = updated_smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"92Lbq5CrsH_y"},"outputs":[],"source":["updated_smi = []\n","\n","#Update dataset with neutralized, aromatic SMILES\n","for smi in pre9_inactives[smi_col]: \n","    mol = Chem.MolFromSmiles(smi)\n","    mol_neu = utils.neutralize_atoms(mol)\n","    smi_arom = utils.aromatize_smile(mol_neu)\n","    updated_smi.append(smi_arom)\n","\n","#update the smiles in this df\n","pre9_inactives[smi_col] = updated_smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CcFJnqCPsH_y"},"outputs":[],"source":["#Save\n","pre9_actives.to_csv(f'{data_folder}/before_finished/step_9_10/post10_actives.csv', index=False)\n","pre9_inactives.to_csv(f'{data_folder}/before_finished/step_9_10/post10_inactives.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"-o4eOUafsH_y"},"source":["# Post 9+10: Update InChIs"]},{"cell_type":"markdown","metadata":{"id":"1MKyfU7xsH_y"},"source":["Is it important to now update InChI in our datasets, for 2 reasons:\n","\n","(1) Some mixture compounds have been modified (removal of small inorganic or organic molecules) in SMILES representation but not InChIs.\n","\n","(2) The SMILES representations have been neutralized and aromatized, but not InChIs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W6TMUL-VsH_y"},"outputs":[],"source":["#export the smiles columns to txt\n","pre9_actives[smi_col].to_csv(f'{data_folder}/before_finished/step_9_10/smiles_actives.txt', index=False, header=False)\n","pre9_inactives[smi_col].to_csv(f'{data_folder}/before_finished/step_9_10/smiles_inactives.txt', index=False, header=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dIZYDM7IsH_y"},"outputs":[],"source":["\"\"\"\n","Submit the smiles files to PubChem Identifier Exchange Service: \n","    Input IDs: \"SMILES\"\n","    Operator type: \"same CID\" \n","    Output IDs: \"InChI\"\n","    Output method: \"Two column file showing each input output-correspondence\"\n","    Compression: \"No compression\"\n","InChI list should be saved into \"step_9_10\" folder, named as \"inchi_actives.txt\" and \"inchi_inactives\" \n","\"\"\"\n","#Import the converted InChIs\n","cleaned_inchi_hits = pd.read_csv(f'{data_folder}/before_finished/step_9_10/inchi_actives.txt', sep='\\t', header=None)\n","cleaned_inchi_inactives = pd.read_csv(f'{data_folder}/before_finished/step_9_10/inchi_inactives.txt', sep='\\t', header=None)\n","\n","#a dictionary of smiles and corresponding inchi in cleaned_inchi_hits\n","hits_smi_inchi_dict = dict(zip(cleaned_inchi_hits[0], cleaned_inchi_hits[1]))\n","inactives_smi_inchi_dict = dict(zip(cleaned_inchi_inactives[0], cleaned_inchi_inactives[1]))\n","                             \n","#update the pre9_hits by matching the smiles with keys and replace inchi with values:\n","pre9_actives['InChI'] = pre9_actives[smi_col].map(hits_smi_inchi_dict) \n","pre9_inactives['InChI'] = pre9_inactives[smi_col].map(inactives_smi_inchi_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pp4U13ZksH_y"},"outputs":[],"source":["#export: \n","pre9_actives.to_csv(f'{data_folder}/before_finished/step_9_10/post10_actives.csv', index=False)\n","pre9_inactives.to_csv(f'{data_folder}/before_finished/step_9_10/post10_inactives.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"BrrAFp07sH_z"},"source":["# 11. PAIN Filters"]},{"cell_type":"markdown","metadata":{"id":"P_OHy2LvsH_z"},"source":["## 11.1. Frequency of Hits (FoH) Filter"]},{"cell_type":"markdown","metadata":{"id":"r10cicZ6sH_z"},"source":["Frequency of Hits is a complex concept that requires a merticulous approach. In general, the rule is if a compound was tested active in multiple assays, it is likely to be a promiscuous compound.\n","1. For each compounds, retrieve the information on its tested assays\n","2. For each of the assay tested, retrieve the sequence of the protein target.\n","3. Given all sequence of the protein tested, do a multiple sequence alignment to find the percentage Percent Identity (similarty) between these proteins. If an assay has high percentage to other targets, then these assays contribute less to promiscuousity of the compound.\n","4. Use the percentage identity as a weight:\n","w = 1 - %SI/100\n","Calculate the frequency of hits for each compound:\n","FoH = wACC/TAC\n","wACC is the weighed total number of assay tested where the compounds were identified acitives. TAC is the total number of assays tested."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fe5qcEUGsH_z"},"outputs":[],"source":["pre11_actives = pd.read_csv(f'{data_folder}/before_finished/step_9_10/post10_actives.csv', sep=',', header=0)\n","pre11_inactives = pd.read_csv(f'{data_folder}/before_finished/step_9_10/post10_inactives.csv', sep=',', header=0)\n","\n","# Create a new step folder:\n","if not os.path.exists(f'{data_folder}/before_finished/step_11/11_1'):\n","    os.makedirs(f'{data_folder}/before_finished/step_11/11_1')"]},{"cell_type":"markdown","metadata":{"id":"n8Hh99eMsH_z"},"source":["### 11.1.1. PubChem testing information for each compound"]},{"cell_type":"markdown","metadata":{"id":"0yD-NfC2sH_z"},"source":["This part illustrates how to retrieve the information of how each compound was tested from the PubChem database. Bulk data retrieval from the ftp server is used to get the information of every bioassay in PubChem:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qkyrwGowsH_z","outputId":"f63272bf-9277-4c8f-be5c-074341e35190"},"outputs":[],"source":["url = 'https://ftp.ncbi.nlm.nih.gov/pubchem/Bioassay/Extras/bioassays.tsv.gz' #this FTP file records the summary data of all available AIDs in PubChem\n","\n","local_save_dir = 'S:\\coding\\WelQrate\\pubchem_sum'\n","local_save_path = os.path.join(local_save_dir, 'bioassays.tsv.gz')\n","\n","if not os.path.exists(local_save_dir):\n","    os.makedirs(local_save_dir)\n","r = requests.get(url, stream=True)\n","\n","with open(local_save_path, 'wb') as f:\n","    for chunk in r.iter_content(chunk_size=8192):\n","        f.write(chunk)\n","print('Downloaded to %s' % local_save_path)\n","\n","path = 'pubchem_sum/bioassays.tsv.gz'\n","\n","# Read the TSV file\n","all_bioassay = pd.read_csv(path, delimiter='\\t')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xuguR0t5sH_0","outputId":"2a58a576-e8ce-49e1-ab5c-74a349d07c6c"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>AID</th>\n","      <th>BioAssay Name</th>\n","      <th>Deposit Date</th>\n","      <th>Modify Date</th>\n","      <th>Source Name</th>\n","      <th>Source ID</th>\n","      <th>Substance Type</th>\n","      <th>Outcome Type</th>\n","      <th>Project Category</th>\n","      <th>BioAssay Group</th>\n","      <th>BioAssay Types</th>\n","      <th>Protein Accessions</th>\n","      <th>UniProts IDs</th>\n","      <th>Gene IDs</th>\n","      <th>Target TaxIDs</th>\n","      <th>Taxonomy IDs</th>\n","      <th>Number of Tested SIDs</th>\n","      <th>Number of Active SIDs</th>\n","      <th>Number of Tested CIDs</th>\n","      <th>Number of Active CIDs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>20040815</td>\n","      <td>20240410</td>\n","      <td>DTP/NCI</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>small-molecule</td>\n","      <td>Confirmatory</td>\n","      <td>Other</td>\n","      <td>NCI-60_DOSERESP</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>55228</td>\n","      <td>3318</td>\n","      <td>53214</td>\n","      <td>3094</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>20040815</td>\n","      <td>20240410</td>\n","      <td>DTP/NCI</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>small-molecule</td>\n","      <td>Confirmatory</td>\n","      <td>Other</td>\n","      <td>NCI-60_DOSERESP</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>51435</td>\n","      <td>2615</td>\n","      <td>49564</td>\n","      <td>2467</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>20040815</td>\n","      <td>20240410</td>\n","      <td>DTP/NCI</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>small-molecule</td>\n","      <td>Confirmatory</td>\n","      <td>Other</td>\n","      <td>NCI-60_DOSERESP</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>54079</td>\n","      <td>2503</td>\n","      <td>52046</td>\n","      <td>2317</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>20040815</td>\n","      <td>20240410</td>\n","      <td>DTP/NCI</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>small-molecule</td>\n","      <td>Confirmatory</td>\n","      <td>Other</td>\n","      <td>NCI-60_DOSERESP</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>54062</td>\n","      <td>4335</td>\n","      <td>52033</td>\n","      <td>4098</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>20040815</td>\n","      <td>20240410</td>\n","      <td>DTP/NCI</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>small-molecule</td>\n","      <td>Confirmatory</td>\n","      <td>Other</td>\n","      <td>NCI-60_DOSERESP</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>53977</td>\n","      <td>3159</td>\n","      <td>52001</td>\n","      <td>2981</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   AID                                      BioAssay Name  Deposit Date  \\\n","0    1  NCI human tumor cell line growth inhibition as...      20040815   \n","1    3  NCI human tumor cell line growth inhibition as...      20040815   \n","2    5  NCI human tumor cell line growth inhibition as...      20040815   \n","3    7  NCI human tumor cell line growth inhibition as...      20040815   \n","4    9  NCI human tumor cell line growth inhibition as...      20040815   \n","\n","   Modify Date Source Name                                          Source ID  \\\n","0     20240410     DTP/NCI  NCI human tumor cell line growth inhibition as...   \n","1     20240410     DTP/NCI  NCI human tumor cell line growth inhibition as...   \n","2     20240410     DTP/NCI  NCI human tumor cell line growth inhibition as...   \n","3     20240410     DTP/NCI  NCI human tumor cell line growth inhibition as...   \n","4     20240410     DTP/NCI  NCI human tumor cell line growth inhibition as...   \n","\n","   Substance Type  Outcome Type Project Category   BioAssay Group  \\\n","0  small-molecule  Confirmatory            Other  NCI-60_DOSERESP   \n","1  small-molecule  Confirmatory            Other  NCI-60_DOSERESP   \n","2  small-molecule  Confirmatory            Other  NCI-60_DOSERESP   \n","3  small-molecule  Confirmatory            Other  NCI-60_DOSERESP   \n","4  small-molecule  Confirmatory            Other  NCI-60_DOSERESP   \n","\n","  BioAssay Types Protein Accessions UniProts IDs Gene IDs  Target TaxIDs  \\\n","0            NaN                NaN          NaN      NaN            NaN   \n","1            NaN                NaN          NaN      NaN            NaN   \n","2            NaN                NaN          NaN      NaN            NaN   \n","3            NaN                NaN          NaN      NaN            NaN   \n","4            NaN                NaN          NaN      NaN            NaN   \n","\n","  Taxonomy IDs  Number of Tested SIDs  Number of Active SIDs  \\\n","0          NaN                  55228                   3318   \n","1          NaN                  51435                   2615   \n","2          NaN                  54079                   2503   \n","3          NaN                  54062                   4335   \n","4          NaN                  53977                   3159   \n","\n","   Number of Tested CIDs  Number of Active CIDs  \n","0                  53214                   3094  \n","1                  49564                   2467  \n","2                  52046                   2317  \n","3                  52033                   4098  \n","4                  52001                   2981  "]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["all_bioassay.head()"]},{"cell_type":"markdown","metadata":{"id":"6rUtkppYsH_0"},"source":["### 11.1.2 Retrieving protein sequences for assays tested:"]},{"cell_type":"markdown","metadata":{"id":"_v-cVAPIsH_0"},"source":["Then, the testing information for each compound is retrieved from the PugREST API"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"afaTLUmKsH_0"},"outputs":[],"source":["# Cache to store the number of compounds tested per AID to avoid redundant call.\n","num_compounds_tested_cache = {}\n","\n","def get_num_compounds_tested(aid, all_bioassay=all_bioassay):\n","    \"\"\"\n","    This function retrieves the information of how many compounds were tested in a given assay (by AID).\n","    \"\"\"\n","    if aid in num_compounds_tested_cache:\n","        return num_compounds_tested_cache[aid]\n","    else:\n","        #return the 'Number of Tested CIDs' column value at the row where the 'AID' column is equal to aid in the all_bioassay dataframe\n","        num_compounds_tested = all_bioassay[all_bioassay['AID'] == aid]['Number of Tested CIDs'].values[0]\n","    return num_compounds_tested\n","\n","def get_assay_data(cid):\n","    \"\"\"\n","    Return a dictionary of all targets that a given compound (by CID) was tested on in PubChem\n","    and the activity values of the compound.\n","    \"\"\"\n","    url = f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/{cid}/assaysummary/JSON\" #PUG-REST compound summary by CID\n","    response = requests.get(url)\n","    data = response.json()\n","\n","    target_activity = {}\n","\n","    if 'Table' in data and 'Row' in data['Table']:\n","        for row in data['Table']['Row']:\n","            cells = row['Cell']\n","            aid = int(cells[0])  # Extracting the AID from the first cell\n","\n","            # Proceed only if the assay is a screening assay\n","            if cells[10] == 'Screening':\n","\n","                # Proceed only if more than 10,000 compounds were tested\n","                num_compounds_tested = get_num_compounds_tested(aid)\n","                if num_compounds_tested > 10000:\n","                    target_gi = cells[5] # Retrieve the protein target's GI\n","                    activity_outcome = cells[4].lower()\n","\n","                    if target_gi not in target_activity:\n","                        target_activity[target_gi] = activity_outcome == 'active'\n","                    elif activity_outcome == 'active':\n","                        target_activity[target_gi] = True # If a compound was tested multiple times on the same protein, priotize \"active\" outcome.\n","\n","            else:\n","                continue\n","\n","    return (cid, target_activity)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KhhTtTSpsH_0","outputId":"686710b3-fa6d-492b-ef54-215f770e1dd3"},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing CIDs:   0%|          | 0/791 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["Processing CIDs: 100%|██████████| 791/791 [07:28<00:00,  1.77it/s]\n"]}],"source":["import requests\n","from concurrent.futures import ThreadPoolExecutor, as_completed\n","from tqdm import tqdm\n","\n","cids_list = pre11_actives[cid_col].tolist()\n","\n","def execute_with_multiprocessing(cids_list):\n","    \"\"\"\n","    For a given list of CIDs, return a dictionary of dictionaries \n","    of protein targets these compounds were tested on and the activity outcomes\n","    Input: \n","        [list of CIDs]\n","    Output: \n","        Dictionary of testing information for all CIDs, such as:\n","        {CID1:{target1:activity1, target3:activity3, ...},{CID2:{target2:activity2, target4:activity4, ...}, ...}}\n","    \"\"\"\n","    results_dict = {}\n","    with ThreadPoolExecutor(max_workers=10) as executor:\n","        # Prepare futures for all CIDs\n","        futures = [executor.submit(get_assay_data, cid) for cid in cids_list]\n","        \n","        # Process futures as they complete\n","        for future in tqdm(as_completed(futures), total=len(cids_list), desc=\"Processing CIDs\"):\n","            try:\n","                cid, target_activity = future.result()\n","                results_dict[cid] = target_activity\n","            except Exception as e:\n","                print(f\"Error processing CID: {e}\")\n","    return results_dict\n","\n","results_dict = execute_with_multiprocessing(cids_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9BW1ToLhsH_0"},"outputs":[],"source":["#export results_dict\n","with open(f'{data_folder}/before_finished/step_11/11_1/results_dict.json', 'w') as f:\n","    json.dump(results_dict, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cldFtoXksH_1","outputId":"1fc729f0-afdc-44d9-84f5-a2d328059227"},"outputs":[{"name":"stdout","output_type":"stream","text":["['222080095', '62868213', '4758878', '2182777540', '67463989', '2578455', '13325293', '4505209', '56202836', '1655766739', '730163', '6755076', '4581413', '194068499', '6680530', '5016090', '4506113', '499328', '16130726', '4502003', '2507196', '262118306', '83627717', '68565218', '89348172', '38156699', '68565074', '9966877', '119607129', '1679362728', '223460826', '148378801', '27894344', '301171662', '38349113', '4503385', '130375', '5454102', '83699673', '118764400', '76496497', '27368096', '81899072', '257380', '83779224', '15675770', '4503779', '12381848', '134244587', '23505220', '147728', '59036749', '156104889', '154146191', '16128424', '14149746', '42741659', '351542238', '13699818', '34577122', '7381449', '55976631', '47123300', '1572493', '225543099', '46909587', '15610807', '5729858', '14389423', '7108463', '47496637', '195969650', '8574038', '41872631', '85666113', '56790945', '180352', '21489979', '12830367', '534286618', '22538455', '4503351', '21361340', '115496662', '15610601', '55960760', '155969707', '109633019', '38258652', '68989256', '27807367', '29788785', '378544807', '208342286', '116734717', '119579178', '15927174', '253722402', '28949057', '82503229', '4507593', '13399304', '55584151', '73745819', '38788193', '5032039', '2853980', '881546', '21618340', '735367775', '998701', '70832125', '160877737', '1575471', '30219', '487738', '1797100823', '14790033', '116907', '112822', '121945198', '48428097', '1782953264', '78486550', '41872583', '21327705', '1927', '219518789', '4758208', '780303193', '5174513', '312275222', '124486680', '56417702', '28373018', '1519312078', '10864009', '15929025', '23893668', '4757840', '1708272', '124513266', '75495260', '124263658', '190938', '4507681', '339641', '115430235', '9629363', '6912644', '1781172', '5730106', '49168602', '86990435', '4505447', '32479527', '120538355', '15645703', '90111653', '341916350', '4506243', '32425330', '4503219', '109637798', '6009644', '433552101', '42794767', '90421313', '398366139', '218931251', '4503907', '166209887', '7657508', '116076351', '62201602', '4504843', '7582271', '160333370', '119622516', '32307126', '19860819', '27753985', '4507791', '1730321', '11275980', '7108336', '148745659', '62526033', '15680217', '56786138', '2498404', '317373446', '13236497', '120997', '117940060', '16306916', '40254439', '4507615', '14719829', '302699239', '32307152', '119508433', '164058', '49574532', '994798', '31542303', '119603173', '119580345', '32400300', '54112388', '194306653', '27597073', '21361095', '6708281', '124487323', '2393947', '48255881', '2935630', '19923198', '134142337', '4758484', '71746704', '486173', '7669492', '47132585', '124376142', '11093520', '21359873', '115347926', '285814664', '160707929', '16130689', '20336315', '47132611', '124809506', '1237937630', '1762973', '1628587', '10567816', '510901', '86301151', '4507793', '21595776', '16130724', '493539358', '342179211', '32400299', '113121', '126698238', '20070193', '45269145', '153217451', '63477962', '23943882', '38174238', '6274552', '37589898', '597517618', '23110962', '89191863', '13272532', '31563518', '110611243', '83318444', '21264324', '4504343', '134304838', '216409728', '55956923', '37187860', '13177715', '62740231', '151101270', '291463269', '6679827', '14790119', '13128862', '168184763', '74356043', '6016094', '55958172', '20072248', '71987181', '7706645', '17391426', '23510348', '156416009', '6323930', '111034851', '216548193', '11141885', '270133071', '23893623', '4502495', '62203298', '119579215', '10835145', '6166485', '83758679', '224494019', '7706135', '46367787', '37622910', '285809906', '62362414', '21595511', '60391226', '10092597', '1654220559', '231632', '116077694', '126642418', '21464101', '187960042', '223468676', '48145933', '125541954', '1246761', '88501734', '21955158', '119607128', '20336229', '9955963', '68476498', '28373962', '12803275', '67463988', '73747889', '76364066', '21315078', '115529463', '4758204', '4506537', '224028257', '929524245', '55662034', '46577642', '2702319', '7657550', '4826834', '68474550', '118341367', '71774083', '613504304', '54112432', '31881630', '12644416', '4826706', '4502331', '223459640', '3183518', '139472804', '296080766', '597517265', '1166512', '22035600', '40807040', '74355113', '48146199', '16130723', '4503383', '116292172', '17507875', '578162', '10835013', '67191027', '139424501', '124809271', '4502169', '53832009', '528078313', '4506055', '63102437', '216548487', '38027923', '10190672', '25148072', '149631', '11528014', '536029', '88702791', '74315350', '15610945', '167013344', '148539876', '21392848', '15609874', '1709543', '166202459', '4757950', '6831552', '5453722', '1302091', '24119166', '15646160', '2501205', '218891639', '73586699', '78070770', '296434520', '6978787', '187952397', '15610402', '9937384', '16878311', '47678551', '1937369734', '13124881', '11094021', '13027636', '4505445', '15607504', '111305821', '90652859', '74752344', '9629361', '4885057', '2358024', '34330186', '171229', '6325022', '52426748', '74734243', '1111959238', '116516899', '4503155', '89993689']\n","Require multiple sequencing alignment for 427 proteins.\n"]}],"source":["#import results_dict:\n","with open(f'{data_folder}/before_finished/step_11/11_1/results_dict.json', 'r') as f:\n","    results_dict = json.load(f)\n","\n","#get the list of all keys of the values in the dictionary:\n","protein_ids = []\n","for value in results_dict.values():\n","    protein_ids.extend(value.keys())\n","\n","#clean the list\n","protein_ids = list(set(protein_ids))\n","protein_ids = [id for id in protein_ids if id != '']\n","\n","print(protein_ids)\n","print(f'Require multiple sequencing alignment for {len(protein_ids)} proteins.')"]},{"cell_type":"markdown","metadata":{"id":"3kJRCQmNsH_1"},"source":["Now we retrieve all the FASTA sequences of proteins tested for all of our compounds with Biopython API to Entrez of NCBI. The FASTA sequence is saved as \"sequences.fasta\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YV6CPY08sH_1"},"outputs":[],"source":["# Always tell NCBI who you are\n","Entrez.email = \"hdong26@amherst.edu\"\n","\n","# The filename where you want to save the sequences\n","output_filename = f'{data_folder}/before_finished/step_11/11_1/sequences.fasta'\n","\n","# Open a file to write the sequences\n","with open(output_filename, \"w\") as output_file:\n","    for id in protein_ids:\n","        try:\n","            # Fetch the sequence from NCBI\n","            handle = Entrez.efetch(db=\"protein\", id=id, rettype=\"fasta\", retmode=\"text\")\n","            sequence_data = handle.read()\n","            handle.close()\n","\n","            # Write the sequence data to the file\n","            output_file.write(sequence_data)\n","        except Exception as e:\n","            print(f\"An error occurred while fetching {id}: {e}\")"]},{"cell_type":"markdown","metadata":{"id":"CZKcmPPvsH_1"},"source":["From the FASTA sequence, we also need to retrieve the list of protein names, since these are different from the protein GIs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UqR_gQ3_sH_1"},"outputs":[],"source":["def extract_protein_names(file_path):\n","    protein_names = []\n","    with open(file_path, 'r') as file:\n","        for line in file:\n","            if line.startswith('>'):\n","                # Split the line at spaces and take the first item\n","                parts = line.split(' ')\n","                protein_name = parts[0]\n","                # Remove the leading '>' character\n","                protein_name = protein_name[1:]\n","                protein_names.append(protein_name)\n","    return protein_names\n","\n","file_path = f'{data_folder}/before_finished/step_11/11_1/sequences.fasta'\n","protein_names = extract_protein_names(file_path)\n","\n","# Create a dictionary to map protein IDs to protein names by index \n","protein_id_to_name = {protein_ids[i]: protein_names[i] for i in range(len(protein_ids))}"]},{"cell_type":"markdown","metadata":{"id":"9EIhxM8DsH_2"},"source":["### 11.1.3 Percent Sequence Identity by Multiple Sequence Alignment"]},{"cell_type":"markdown","metadata":{"id":"HxJxDsI4sH_2"},"source":["The sequences.fasta file is submitted to https://www.ebi.ac.uk/jdispatcher/msa/clustalo for multiple sequencing alignment. The resulted table of percent sequence identity matrix is saved and imported for the calculation of FoH"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pbhlvsrIsH_2"},"outputs":[],"source":["\"\"\"\n","Submit sequences.fasta to https://www.ebi.ac.uk/jdispatcher/msa/clustalo\n","    Input sequence type: Protein\n","    Output format: ClustalW with character counts\n","Download the resulted Percent Identity Matrix file file and save as \"percent_identity_matrix.txt\"\n","\"\"\"\n","\n","#import the identity matrix:\n","protein_si = pd.read_csv(\n","    f'{data_folder}/before_finished/step_11/11_1/percent_identity_matrix.txt',\n","    delimiter='\\s+',\n","    header=None,\n","    skiprows=6\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TE9y0y0lsH_2"},"outputs":[],"source":["#remove the first column:\n","protein_si = protein_si.drop(protein_si.columns[0], axis=1)\n","\n","name = protein_si[1].tolist()\n","name = ['protein name'] + name\n","protein_si.columns = name"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ln-xvLQ0sH_3","outputId":"05c6fdc1-6f5f-45f9-a47f-0a4105868874"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>protein name</th>\n","      <th>AAH65243.1</th>\n","      <th>NP_937802.1</th>\n","      <th>NP_001341533.1</th>\n","      <th>AAG29340.1</th>\n","      <th>NP_057685.1</th>\n","      <th>NP_000469.3</th>\n","      <th>NP_001074551.1</th>\n","      <th>AAI32679.1</th>\n","      <th>NP_776412.2</th>\n","      <th>...</th>\n","      <th>pdb|1VRU|A</th>\n","      <th>sp|Q9HAT2.1|SIAE_HUMAN</th>\n","      <th>EAN77629.1</th>\n","      <th>NP_644805.1</th>\n","      <th>NP_009330.1</th>\n","      <th>NP_269944.1</th>\n","      <th>NP_003896.1</th>\n","      <th>AAH10859.1</th>\n","      <th>NP_004070.3</th>\n","      <th>AAA25265.1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AAH65243.1</td>\n","      <td>100.00</td>\n","      <td>97.34</td>\n","      <td>97.37</td>\n","      <td>13.42</td>\n","      <td>13.01</td>\n","      <td>10.14</td>\n","      <td>14.69</td>\n","      <td>17.48</td>\n","      <td>16.78</td>\n","      <td>...</td>\n","      <td>11.61</td>\n","      <td>11.21</td>\n","      <td>5.21</td>\n","      <td>9.09</td>\n","      <td>8.33</td>\n","      <td>14.08</td>\n","      <td>6.10</td>\n","      <td>9.86</td>\n","      <td>12.00</td>\n","      <td>15.19</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NP_937802.1</td>\n","      <td>97.34</td>\n","      <td>100.00</td>\n","      <td>100.00</td>\n","      <td>14.10</td>\n","      <td>13.73</td>\n","      <td>9.74</td>\n","      <td>14.09</td>\n","      <td>16.78</td>\n","      <td>16.11</td>\n","      <td>...</td>\n","      <td>11.30</td>\n","      <td>10.34</td>\n","      <td>4.00</td>\n","      <td>9.50</td>\n","      <td>10.17</td>\n","      <td>14.77</td>\n","      <td>6.73</td>\n","      <td>8.42</td>\n","      <td>11.11</td>\n","      <td>14.74</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NP_001341533.1</td>\n","      <td>97.37</td>\n","      <td>100.00</td>\n","      <td>100.00</td>\n","      <td>14.20</td>\n","      <td>13.84</td>\n","      <td>9.74</td>\n","      <td>14.09</td>\n","      <td>16.78</td>\n","      <td>16.11</td>\n","      <td>...</td>\n","      <td>11.30</td>\n","      <td>10.74</td>\n","      <td>4.76</td>\n","      <td>9.44</td>\n","      <td>10.11</td>\n","      <td>14.77</td>\n","      <td>6.73</td>\n","      <td>8.42</td>\n","      <td>11.11</td>\n","      <td>14.74</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>AAG29340.1</td>\n","      <td>13.42</td>\n","      <td>14.10</td>\n","      <td>14.20</td>\n","      <td>100.00</td>\n","      <td>61.76</td>\n","      <td>13.04</td>\n","      <td>18.39</td>\n","      <td>17.24</td>\n","      <td>14.94</td>\n","      <td>...</td>\n","      <td>9.43</td>\n","      <td>9.57</td>\n","      <td>8.65</td>\n","      <td>7.46</td>\n","      <td>5.30</td>\n","      <td>11.32</td>\n","      <td>7.76</td>\n","      <td>6.12</td>\n","      <td>5.62</td>\n","      <td>10.20</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NP_057685.1</td>\n","      <td>13.01</td>\n","      <td>13.73</td>\n","      <td>13.84</td>\n","      <td>61.76</td>\n","      <td>100.00</td>\n","      <td>13.79</td>\n","      <td>19.51</td>\n","      <td>15.85</td>\n","      <td>14.63</td>\n","      <td>...</td>\n","      <td>9.43</td>\n","      <td>9.26</td>\n","      <td>7.84</td>\n","      <td>8.00</td>\n","      <td>6.40</td>\n","      <td>13.46</td>\n","      <td>8.26</td>\n","      <td>5.38</td>\n","      <td>8.86</td>\n","      <td>10.59</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>422</th>\n","      <td>NP_269944.1</td>\n","      <td>14.08</td>\n","      <td>14.77</td>\n","      <td>14.77</td>\n","      <td>11.32</td>\n","      <td>13.46</td>\n","      <td>7.25</td>\n","      <td>7.35</td>\n","      <td>4.41</td>\n","      <td>8.82</td>\n","      <td>...</td>\n","      <td>13.27</td>\n","      <td>11.36</td>\n","      <td>14.84</td>\n","      <td>13.97</td>\n","      <td>13.64</td>\n","      <td>100.00</td>\n","      <td>15.43</td>\n","      <td>19.66</td>\n","      <td>11.34</td>\n","      <td>18.97</td>\n","    </tr>\n","    <tr>\n","      <th>423</th>\n","      <td>NP_003896.1</td>\n","      <td>6.10</td>\n","      <td>6.73</td>\n","      <td>6.73</td>\n","      <td>7.76</td>\n","      <td>8.26</td>\n","      <td>10.81</td>\n","      <td>9.17</td>\n","      <td>11.93</td>\n","      <td>10.09</td>\n","      <td>...</td>\n","      <td>11.37</td>\n","      <td>14.23</td>\n","      <td>15.27</td>\n","      <td>16.28</td>\n","      <td>13.84</td>\n","      <td>15.43</td>\n","      <td>100.00</td>\n","      <td>13.93</td>\n","      <td>13.51</td>\n","      <td>15.76</td>\n","    </tr>\n","    <tr>\n","      <th>424</th>\n","      <td>AAH10859.1</td>\n","      <td>9.86</td>\n","      <td>8.42</td>\n","      <td>8.42</td>\n","      <td>6.12</td>\n","      <td>5.38</td>\n","      <td>8.64</td>\n","      <td>8.97</td>\n","      <td>8.97</td>\n","      <td>6.41</td>\n","      <td>...</td>\n","      <td>10.38</td>\n","      <td>7.52</td>\n","      <td>11.90</td>\n","      <td>15.36</td>\n","      <td>12.77</td>\n","      <td>19.66</td>\n","      <td>13.93</td>\n","      <td>100.00</td>\n","      <td>17.21</td>\n","      <td>18.56</td>\n","    </tr>\n","    <tr>\n","      <th>425</th>\n","      <td>NP_004070.3</td>\n","      <td>12.00</td>\n","      <td>11.11</td>\n","      <td>11.11</td>\n","      <td>5.62</td>\n","      <td>8.86</td>\n","      <td>17.39</td>\n","      <td>17.58</td>\n","      <td>14.29</td>\n","      <td>18.68</td>\n","      <td>...</td>\n","      <td>10.23</td>\n","      <td>13.04</td>\n","      <td>13.75</td>\n","      <td>14.04</td>\n","      <td>13.72</td>\n","      <td>11.34</td>\n","      <td>13.51</td>\n","      <td>17.21</td>\n","      <td>100.00</td>\n","      <td>20.07</td>\n","    </tr>\n","    <tr>\n","      <th>426</th>\n","      <td>AAA25265.1</td>\n","      <td>15.19</td>\n","      <td>14.74</td>\n","      <td>14.74</td>\n","      <td>10.20</td>\n","      <td>10.59</td>\n","      <td>13.73</td>\n","      <td>10.00</td>\n","      <td>11.00</td>\n","      <td>11.00</td>\n","      <td>...</td>\n","      <td>13.23</td>\n","      <td>14.03</td>\n","      <td>16.84</td>\n","      <td>12.88</td>\n","      <td>14.52</td>\n","      <td>18.97</td>\n","      <td>15.76</td>\n","      <td>18.56</td>\n","      <td>20.07</td>\n","      <td>100.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>427 rows × 428 columns</p>\n","</div>"],"text/plain":["       protein name  AAH65243.1  NP_937802.1  NP_001341533.1  AAG29340.1  \\\n","0        AAH65243.1      100.00        97.34           97.37       13.42   \n","1       NP_937802.1       97.34       100.00          100.00       14.10   \n","2    NP_001341533.1       97.37       100.00          100.00       14.20   \n","3        AAG29340.1       13.42        14.10           14.20      100.00   \n","4       NP_057685.1       13.01        13.73           13.84       61.76   \n","..              ...         ...          ...             ...         ...   \n","422     NP_269944.1       14.08        14.77           14.77       11.32   \n","423     NP_003896.1        6.10         6.73            6.73        7.76   \n","424      AAH10859.1        9.86         8.42            8.42        6.12   \n","425     NP_004070.3       12.00        11.11           11.11        5.62   \n","426      AAA25265.1       15.19        14.74           14.74       10.20   \n","\n","     NP_057685.1  NP_000469.3  NP_001074551.1  AAI32679.1  NP_776412.2  ...  \\\n","0          13.01        10.14           14.69       17.48        16.78  ...   \n","1          13.73         9.74           14.09       16.78        16.11  ...   \n","2          13.84         9.74           14.09       16.78        16.11  ...   \n","3          61.76        13.04           18.39       17.24        14.94  ...   \n","4         100.00        13.79           19.51       15.85        14.63  ...   \n","..           ...          ...             ...         ...          ...  ...   \n","422        13.46         7.25            7.35        4.41         8.82  ...   \n","423         8.26        10.81            9.17       11.93        10.09  ...   \n","424         5.38         8.64            8.97        8.97         6.41  ...   \n","425         8.86        17.39           17.58       14.29        18.68  ...   \n","426        10.59        13.73           10.00       11.00        11.00  ...   \n","\n","     pdb|1VRU|A  sp|Q9HAT2.1|SIAE_HUMAN  EAN77629.1  NP_644805.1  NP_009330.1  \\\n","0         11.61                   11.21        5.21         9.09         8.33   \n","1         11.30                   10.34        4.00         9.50        10.17   \n","2         11.30                   10.74        4.76         9.44        10.11   \n","3          9.43                    9.57        8.65         7.46         5.30   \n","4          9.43                    9.26        7.84         8.00         6.40   \n","..          ...                     ...         ...          ...          ...   \n","422       13.27                   11.36       14.84        13.97        13.64   \n","423       11.37                   14.23       15.27        16.28        13.84   \n","424       10.38                    7.52       11.90        15.36        12.77   \n","425       10.23                   13.04       13.75        14.04        13.72   \n","426       13.23                   14.03       16.84        12.88        14.52   \n","\n","     NP_269944.1  NP_003896.1  AAH10859.1  NP_004070.3  AAA25265.1  \n","0          14.08         6.10        9.86        12.00       15.19  \n","1          14.77         6.73        8.42        11.11       14.74  \n","2          14.77         6.73        8.42        11.11       14.74  \n","3          11.32         7.76        6.12         5.62       10.20  \n","4          13.46         8.26        5.38         8.86       10.59  \n","..           ...          ...         ...          ...         ...  \n","422       100.00        15.43       19.66        11.34       18.97  \n","423        15.43       100.00       13.93        13.51       15.76  \n","424        19.66        13.93      100.00        17.21       18.56  \n","425        11.34        13.51       17.21       100.00       20.07  \n","426        18.97        15.76       18.56        20.07      100.00  \n","\n","[427 rows x 428 columns]"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["protein_si"]},{"cell_type":"markdown","metadata":{"id":"53axxwr7sH_3"},"source":["### 11.1.4 Calculation of FoHs:"]},{"cell_type":"markdown","metadata":{"id":"9gBbbOoxsH_3"},"source":["Until now, we have a dictionary of (cid: assays tested); (assay_tested:protein name), and percentage identity matrix with first columns as protein names.\n","For each compound, we retrieve the list of all protein names tested on that compounds by matching between the two first dictionary. From this list, we retrieve the corresponding matrix of percentages identitiy of these proteins corresponding to these compounds and calculate the FoH"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rf93abvIsH_3"},"outputs":[],"source":["protein_si_dict = {}\n","for name in protein_si['protein name']:\n","    for other_name in protein_si['protein name']:\n","        if other_name != name:\n","            protein_si_dict[(name, other_name)] = protein_si.loc[protein_si['protein name'] == name, other_name].values[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9K4swtASsH_3","outputId":"658ddb21-f8cc-4088-e8a4-e33684086fe1"},"outputs":[{"name":"stderr","output_type":"stream","text":["  1%|          | 5/791 [00:00<00:32, 23.89it/s]"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 791/791 [02:02<00:00,  6.44it/s]\n"]}],"source":["foh_dict = {}\n","\n","for cid, targets in tqdm.tqdm(results_dict.items()):\n","    active_weight_list = []\n","    total_weight_list = []\n","\n","    for target_id, result in targets.items():\n","        if target_id == '':\n","            continue\n","\n","        protein_name = protein_id_to_name[target_id]\n","        max_weight = 0\n","\n","        for other_id, other_result in targets.items():\n","            if other_id != target_id and other_id != '':\n","                other_protein_name = protein_id_to_name[other_id]\n","                value = protein_si_dict[(protein_name, other_protein_name)]\n","                max_weight = max(max_weight, value)\n","\n","        target_weight = 1 - max_weight / 100\n","\n","        if result:\n","            active_weight_list.append(target_weight)\n","        total_weight_list.append(target_weight)\n","\n","    if total_weight_list:\n","        foh_score = sum(active_weight_list) / sum(total_weight_list)\n","        foh_dict[cid] = foh_score\n","    else: \n","        foh_dict[cid] = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"96N2ULZYsH_3"},"outputs":[],"source":["#export foh_dict\n","with open(f'{data_folder}/before_finished/step_11/11_1/foh_dict.json', 'w') as f:\n","    json.dump(foh_dict, f)"]},{"cell_type":"markdown","metadata":{"id":"4aQtFqHHsH_4"},"source":["For compounds with FoH larger than 0.26, we remove them"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5FMSlX3_sH_4","outputId":"3456a534-d4f3-4dfc-d1c1-e18037e4c489"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dropped 0 compounds with FoH larger than 0.26\n"]}],"source":["to_drop = []\n","for cid, foh_score in foh_dict.items():\n","    if foh_score > 0.26: \n","        to_drop.append(cid)\n","\n","post_FoH_actives = pre11_actives[~pre11_actives[cid_col].isin(to_drop)]\n","print(f'Dropped {(len(to_drop))} compounds with FoH larger than 0.26')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uHyADmMXsH_4"},"outputs":[],"source":["post_FoH_actives.to_csv(f'{data_folder}/before_finished/step_11/11_1/post_FoH_actives.csv', index=False)\n","pre11_inactives.to_csv(f'{data_folder}/before_finished/step_11/11_1/post_FoH_inactives.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"tkGn-9EosH_4"},"source":["## 11.2 Autofluoresence Filter"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["post_FoH_actives = pd.read_csv(f'{data_folder}/before_finished/step_11/11_1/post_FoH_actives.csv', sep=',', header=0)\n","post_FoH_inactives = pd.read_csv(f'{data_folder}/before_finished/step_11/11_1/post_FoH_inactives.csv', sep=',', header=0)"]},{"cell_type":"markdown","metadata":{"id":"9pbyJovgsH_5"},"source":["When finding false positive due to autofluorescence and luceferase inhibition, it is important to check if the particular assays use one of these technologies. Here, all three assays (AID626, AID1488, and AID1741) use fluorescence technologies, so it is optimal to remove compounds that are active in AIDs: 587, 588, 590, 591, 592, 593, 594"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ucjw6tZPsH_5"},"outputs":[],"source":["autofluorescence_cids = filters.load_autofluorescence_cids(data_folder)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n7E0-zKnsH_5","outputId":"6cdbd19b-b189-4392-a87d-b1aa90974cd7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dropped 0 autofluorescence compounds\n"]}],"source":["to_drop_actives = []\n","for cid in post_FoH_actives: \n","    if cid in autofluorescence_cids:\n","        to_drop.append(cid)\n","post_autofluorescence_actives = post_FoH_actives[~post_FoH_actives['PUBCHEM_CID'].isin(to_drop_actives)]\n","print(f'Dropped {(len(to_drop_actives))} autofluorescence compounds')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NGzS4EDcsH_5"},"outputs":[],"source":["if not os.path.exists(f'{data_folder}/before_finished/step_11/11_2'):\n","    os.makedirs(f'{data_folder}/before_finished/step_11/11_2')\n","\n","#save: \n","post_autofluorescence_actives.to_csv(f'{data_folder}/before_finished/step_11/11_2/post_autofluorescence_actives.csv', index=False)\n","pre11_inactives.to_csv(f'{data_folder}/before_finished/step_11/11_2/post_autofluorescence_inactives.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"3wYez9w1sH_6"},"source":["## 11.3 RDKit PAIN filter"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["post_autofluorescence_actives = pd.read_csv(f'{data_folder}/before_finished/step_11/11_2/post_autofluorescence_actives.csv', sep=',', header=0)\n","post_autofluorescence_inactives = pd.read_csv(f'{data_folder}/before_finished/step_11/11_2/post_autofluorescence_inactives.csv', sep=',', header=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rf47Xc7asH_6","outputId":"a2603ec3-6559-4310-f3ba-2512fe762d1e"},"outputs":[{"name":"stdout","output_type":"stream","text":["1 pains detected\n","2 pains detected\n","3 pains detected\n","4 pains detected\n","5 pains detected\n","6 pains detected\n","7 pains detected\n","8 pains detected\n","9 pains detected\n","10 pains detected\n","11 pains detected\n","12 pains detected\n","13 pains detected\n","14 pains detected\n","15 pains detected\n","16 pains detected\n","17 pains detected\n","18 pains detected\n","19 pains detected\n","20 pains detected\n","21 pains detected\n","22 pains detected\n","23 pains detected\n","24 pains detected\n","25 pains detected\n","26 pains detected\n","27 pains detected\n","28 pains detected\n"]}],"source":["pains_actives = filters.detect_pains(post_autofluorescence_actives, smi_col, cid_col)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bzi-1ovWsH_6"},"outputs":[],"source":["post_pains_actives = post_autofluorescence_actives[~post_autofluorescence_actives['PUBCHEM_CID'].isin(pains_actives)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yEi4hgLisH_6"},"outputs":[],"source":["if not os.path.exists(f'{data_folder}/before_finished/step_11/11_3'):\n","    os.makedirs(f'{data_folder}/before_finished/step_11/11_3')\n","\n","post_pains_actives.to_csv(f'{data_folder}/before_finished/step_11/11_3/post_pains_actives.csv', index=False)\n","post_autofluorescence_inactives.to_csv(f'{data_folder}/before_finished/step_11/11_3/post_pains_inactives.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"vQBMJd_-sH_6"},"source":["# 12. Drug-likeness Filter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DzwzkU_xsH_7"},"outputs":[],"source":["pre12_actives = pd.read_csv(f'{data_folder}/before_finished/step_11/11_3/post_pains_actives.csv', sep=',', header=0)\n","pre12_inactives = pd.read_csv(f'{data_folder}/before_finished/step_11/11_3/post_pains_inactives.csv', sep=',', header=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f0bN6UtNsH_7","outputId":"743635f0-c5dd-436e-f226-ef06798c315b"},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing SMILES: 100%|██████████| 763/763 [00:00<00:00, 1226150.94it/s]\n"]}],"source":["not_drug_actives = filters.drug_likeness_filter_multiprocessing(pre12_actives, smi_col, cid_col)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VxjJ0iePsH_7","outputId":"b19c3a9e-d35b-4925-9e05-281c3e06399f"},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing SMILES: 100%|██████████| 100467/100467 [00:14<00:00, 7136.16it/s] \n"]}],"source":["not_drug_inactives = filters.drug_likeness_filter_multiprocessing(pre12_inactives, smi_col, cid_col)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BOIE5oFqsH_7","outputId":"a08b5ed3-8d9b-45bc-d193-922f77da4935"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dropped 111 hit compounds that do not pass the drug likeness filter\n","Dropped 5423 inactive compounds that do not pass the drug likeness filter\n"]}],"source":["post12_actives = pre12_actives[~pre12_actives['PUBCHEM_CID'].isin(not_drug_actives)]\n","post12_inactives = pre12_inactives[~pre12_inactives['PUBCHEM_CID'].isin(not_drug_inactives)]\n","\n","print(f'Dropped {(len(not_drug_actives))} hit compounds that do not pass the drug likeness filter')\n","print(f'Dropped {(len(not_drug_inactives))} inactive compounds that do not pass the drug likeness filter')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7cPU1W1dsH_7"},"outputs":[],"source":["if not os.path.exists(f'{data_folder}/before_finished/step_12'):\n","    os.makedirs(f'{data_folder}/before_finished/step_12')\n","\n","#Export not_drug_actives and inactives:\n","with open(f'{data_folder}/before_finished/step_12/not_drug_actives.json', 'w') as f:\n","    json.dump(not_drug_actives, f)\n","with open(f'{data_folder}/before_finished/step_12/not_drug_inactives.json', 'w') as f:\n","    json.dump(not_drug_inactives, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mYHd9DmxsH_7"},"outputs":[],"source":["# save: \n","post12_actives.to_csv(f'{data_folder}/before_finished/step_12/post12_actives.csv', index=False)\n","post12_inactives.to_csv(f'{data_folder}/before_finished/step_12/post12_inactives.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"GP2GaUb6sH_8"},"source":["# 13. ChemBL Curation Pipeline"]},{"cell_type":"markdown","metadata":{},"source":["Besides PubChem, the ChEMBL database is one of several public databases containing bioactivity data on small molecule compounds curated from various sources. Incoming compounds are typically not standardized according to consistent rules. To maintain the quality of the final database and to facilitate the comparison and integration of data on the same compound from different sources, it is essential to appropriately standardize the chemical structures in the database. This chemical curation pipeline has been developed by Bento, A.P, et al., using the open-source toolkit RDKit, including a Checker module that tests the validity of chemical structures and flags any serious errors. For ChEMBL, a penalty score of 7 is considered a fatal error, and the molfile is not loaded into the database.\n","\n","In our dataset, we passed all compounds through this Checker module to evaluate the validity of the included chemical structures. For compounds that returned a penalty score of 7, we will check them manually.\n","\n","Reference:\n","Bento, A.P., Hersey, A., Félix, E. et al. An open source chemical structure curation pipeline using RDKit. J Cheminform 12, 51 (2020). https://doi.org/10.1186/s13321-020-00456-1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MYDGv0vcsH_8"},"outputs":[],"source":["pre13_actives = pd.read_csv(f'{data_folder}/before_finished/step_12/post12_actives.csv', sep=',', header=0)\n","pre13_inactives = pd.read_csv(f'{data_folder}/before_finished/step_12/post12_inactives.csv', sep=',', header=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IOuDdyBssH_8","outputId":"6d8f795a-1179-4416-de54-549a6afa9f45"},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing SMILES: 100%|██████████| 652/652 [00:01<00:00, 457.96it/s]\n","[17:32:55] Conflicting single bond directions around double bond at index 7.\n","[17:32:55]   BondStereo set to STEREONONE and single bond directions set to NONE.\n","[17:33:17] Conflicting single bond directions around double bond at index 4.\n","[17:33:17]   BondStereo set to STEREONONE and single bond directions set to NONE.\n","Processing SMILES: 100%|██████████| 95044/95044 [00:29<00:00, 3178.91it/s]  \n"]}],"source":["# Apply the ChemBL Curation Pipeline Checker module:\n","score_actives = utils.checker_multiprocessing(pre13_actives, smi_col, cid_col)\n","score_inactives = utils.checker_multiprocessing(pre13_inactives, smi_col, cid_col)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H8-pP8PEsH_8","outputId":"cbfe4d8c-0d75-4adc-f4b8-4c6edf4d2be1"},"outputs":[{"name":"stdout","output_type":"stream","text":["{0, 2}\n","{0, 2, 5, 6}\n"]}],"source":["#print all unique values in the dictionary:\n","print(set(score_actives.values()))\n","print(set(score_inactives.values()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fw0Wr4JusH_9"},"outputs":[],"source":["# Create a new step folder\n","if not os.path.exists(f'{data_folder}/before_finished/step_13'):\n","    os.makedirs(f'{data_folder}/before_finished/step_13')\n","\n","# save the scores:\n","with open(f'{data_folder}/before_finished/step_13/score_actives.json', 'w') as f:\n","    json.dump(score_actives, f)\n","with open(f'{data_folder}/before_finished/step_13/score_inactives.json', 'w') as f:\n","    json.dump(score_inactives, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n30e6pKfsH_9"},"outputs":[],"source":["#drop all compounds with a penalty score of 7:\n","to_drop_actives = []\n","to_drop_inactives = []\n","for cid, penalty_score in score_actives.items():\n","    if penalty_score == 7:\n","        to_drop_actives.append(cid)\n","for cid, penalty_score in score_inactives.items():\n","    if penalty_score == 7:\n","        to_drop_inactives.append(cid)\n","\n","post13_actives = pre13_actives[~pre13_actives[cid_col].isin(to_drop_actives)]\n","post13_inactives = pre13_inactives[~pre13_inactives[cid_col].isin(to_drop_inactives)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nws-joZwsH_9"},"outputs":[],"source":["#save final_hits and inactives:\n","post13_actives.to_csv(f'{data_folder}/before_finished/step_13/post13_actives.csv', index=False)\n","post13_inactives.to_csv(f'{data_folder}/before_finished/step_13/post13_inactives.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"H7hvIAh9sH_9"},"source":["# 14. Final handling of chemical representation"]},{"cell_type":"markdown","metadata":{"id":"NU6cwJz4sH_9"},"source":["Any kind of molecular processing should come with a special attention to post-processing adjustment. This is because during molecular processing, changes in data representation and format could lead to inconsistency or redundancy in the datasets. Below are the two adjustments performed on our datasets. \n","\n","(1) Some of the InChIs in our datasets should be updated. This is because some of the InChI will be missing, since the PubChem Identifier Exchange service might not able to find the corresponding InChI for the aromatized, neutralized SMILES.\n","\n","(2) Presence of some additional duplicates resulted from molecular processing: While handling mixtures, there might be some mixtures whose component molecules are identical. For example, mixtures of organic and inorganic molecules (molX-ionA and molX-ionB) after removed the ions (ionA and ionB) will result in duplicates (molX). Moreover, since the original mixtures are different, their activities could be different. Therefore, we also need to check their activities while handling these duplicates.\n","- If all duplicates share the same results (active/inactive), we keep one of them, since it is likely that the organic molecule kept contributed more significantly to the activity of the mixture. \n","- If duplicates of the same molecules returned different activity, it is safer to remove both of them."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_M-0STPRsH_9"},"outputs":[],"source":["#import: \n","pre14_actives = pd.read_csv(f'{data_folder}/before_finished/step_13/post13_actives.csv', sep=',', header=0)\n","pre14_inactives = pd.read_csv(f'{data_folder}/before_finished/step_13/post13_inactives.csv', sep=',', header=0)"]},{"cell_type":"markdown","metadata":{"id":"cghV2gMvsH_9"},"source":["## 14.1 Update InChI"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nSBynlrLsH_-"},"outputs":[],"source":["def smi_to_inchi(smi):\n","    mol = Chem.MolFromSmiles(smi)\n","    inchi = Chem.inchi.MolToInchi(mol)\n","    return inchi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4kgShO7UsH_-","outputId":"9638b077-d9ea-4413-e030-c6357693ac24"},"outputs":[{"name":"stdout","output_type":"stream","text":["Updated 0 InChI values in pre14_hits\n"]},{"name":"stderr","output_type":"stream","text":["[17:42:18] WARNING: Omitted undefined stereo\n","\n","[17:42:19] WARNING: Charges were rearranged\n","\n","[17:42:19] WARNING: Omitted undefined stereo\n","\n","[17:42:19] WARNING: Omitted undefined stereo\n","\n","[17:42:19] WARNING: Omitted undefined stereo\n","\n","[17:42:19] WARNING: Omitted undefined stereo\n","\n","[17:42:19] WARNING: Omitted undefined stereo\n","\n","[17:42:19] WARNING: Omitted undefined stereo\n","\n","[17:42:20] WARNING: Omitted undefined stereo\n","\n","[17:42:20] WARNING: Omitted undefined stereo\n","\n"]},{"name":"stdout","output_type":"stream","text":["Updated 27 InChI values in pre14_inactives\n"]}],"source":["count = 0 \n","for index, row in pre14_actives.iterrows():\n","    if row['InChI'] != row['InChI']:\n","        pre14_actives.at[index, 'InChI'] = smi_to_inchi(row[smi_col])\n","        count += 1\n","print(f'Updated {count} InChI values in pre14_actives')\n","\n","count = 0\n","for index, row in pre14_inactives.iterrows():\n","    if row['InChI'] != row['InChI']:\n","        pre14_inactives.at[index, 'InChI'] = smi_to_inchi(row[smi_col])\n","        count += 1\n","print(f'Updated {count} InChI values in pre14_inactives')"]},{"cell_type":"markdown","metadata":{"id":"n2uY0jkPsH_-"},"source":["## 14.2 Handle duplicates"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ivCwPo4dsH_-","outputId":"439e9576-a780-4418-99d0-5ff9c0344152"},"outputs":[{"name":"stdout","output_type":"stream","text":["CC(C)(C)CCN1CCC[C@H](NC(=O)COc2ccc(F)c(Cl)c2)C1 SMILES appeared in both hit and inactive sets\n","InChI=1S/C19H28ClFN2O2/c1-19(2,3)8-10-23-9-4-5-14(12-23)22-18(24)13-25-15-6-7-17(21)16(20)11-15/h6-7,11,14H,4-5,8-10,12-13H2,1-3H3,(H,22,24)/t14-/m0/s1 InChI appeared in both hit and inactive sets\n","Number of InChI duplicates in hits:  0\n","Number of InChI duplicates in inactives:  91\n","Number of SMILES duplicates in hits:  0\n","Number of SMILES duplicates in inactives:  91\n"]}],"source":["#Check if a mol in active set appeared in inactive set:\n","for i in pre14_actives[smi_col]:\n","    if i in list(pre14_inactives[smi_col]):\n","        print(f'{i} SMILES appeared in both active and inactive sets')\n","for i in pre14_actives['InChI']:\n","    if i in list(pre14_inactives['InChI']):\n","        print(f'{i} InChI appeared in both active and inactive sets')\n","\n","#Return all duplicates by comparing InChI:\n","final_actives_duplicates_InChI = pre14_actives[pre14_actives.duplicated(subset=['InChI'], keep=False)]\n","final_inactives_duplicates_InChI = pre14_inactives[pre14_inactives.duplicated(subset=['InChI'], keep=False)]\n","final_actives_duplicates_smi = pre14_actives[pre14_actives.duplicated(subset=[smi_col], keep=False)]\n","final_inactives_duplicates_smi = pre14_inactives[pre14_inactives.duplicated(subset=[smi_col], keep=False)]\n","\n","print('Number of InChI duplicates in actives: ', len(final_actives_duplicates_InChI))\n","print('Number of InChI duplicates in inactives: ', len(final_inactives_duplicates_InChI))\n","print('Number of SMILES duplicates in actives: ', len(final_actives_duplicates_smi))\n","print('Number of SMILES duplicates in inactives: ', len(final_inactives_duplicates_smi))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aYk60AZbsH_-"},"outputs":[],"source":["if not os.path.exists(f'{data_folder}/before_finished/step_14'):\n","    os.makedirs(f'{data_folder}/before_finished/step_14')\n","\n","#write all the duplicates to a file:\n","#write duplicates to a txt file: \n","with open(f'{data_folder}/before_finished/step_14/duplicates.txt', 'w') as f:\n","    f.write('InChI duplicates in actives: \\n')\n","    f.write(final_actives_duplicates_InChI.to_string())\n","    f.write('\\n\\n')\n","    f.write('InChI duplicates in inactives: \\n')\n","    f.write(final_inactives_duplicates_InChI.to_string())\n","    f.write('\\n\\n')\n","    f.write('SMILES duplicates in actives: \\n')\n","    f.write(final_actives_duplicates_smi.to_string())\n","    f.write('\\n\\n')\n","    f.write('SMILES duplicates in inactives: \\n')\n","    f.write(final_inactives_duplicates_smi.to_string())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b7posfY1sH__"},"outputs":[],"source":["#remove these duplicates, keep the first one: \n","#by inchi:\n","final_actives = pre14_actives.drop_duplicates(subset=['InChI'], keep='first')\n","final_inactives = pre14_inactives.drop_duplicates(subset=['InChI'], keep='first')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ni_M7pL4sH__","outputId":"65db8b7e-3d51-492b-b91f-a8ced9effd88"},"outputs":[{"name":"stdout","output_type":"stream","text":["No more duplicates in hits\n","No more duplicates in inactives\n"]}],"source":["if len(final_actives[final_actives.duplicated(subset=[smi_col], keep=False)]) == 0:\n","    print('No more duplicates in hits')\n","\n","if len(final_inactives[final_inactives.duplicated(subset=[smi_col], keep=False)]) == 0:\n","    print('No more duplicates in inactives')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LKfoG99usH__"},"outputs":[],"source":["# save: \n","if not os.path.exists(f'{data_folder}/finished'):\n","    os.makedirs(f'{data_folder}/finished')\n","final_actives.to_csv(f'{data_folder}/finished/final_actives.csv',sep=',', index=False)\n","final_inactives.to_csv(f'{data_folder}/finished/final_inactives.csv',sep=',', index=False)"]},{"cell_type":"markdown","metadata":{"id":"-EfnGTM8s3KV"},"source":["# Some additional modifications"]},{"cell_type":"markdown","metadata":{"id":"mzDc6ODksH__"},"source":["## A. Adjust column names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yTG6eIWosH__"},"outputs":[],"source":["final_actives = pd.read_csv(f'{data_folder}/finished/final_actives.csv', sep=',', header=0)\n","final_inactives = pd.read_csv(f'{data_folder}/finished/final_inactives.csv', sep=',', header=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QXmiKUHksH__"},"outputs":[],"source":["# Add another column: \"activity_value\" with all empty NaN values for format consistency with regression datasets:\n","final_actives.loc[:, 'activity_value'] = np.nan \n","final_inactives.loc[:, 'activity_value'] = np.nan\n","\n","if 'small_organic_mol_from_mixture' not in final_actives.columns: # Sometimes, this column might be missing since no small org. mol was detected in mixtures.\n","    final_actives['small_organic_mol_from_mixture'] = np.nan\n","\n","# Rename the columns:\n","final_actives = final_actives.rename(columns={\n","    'PUBCHEM_CID': 'CID',\n","    'PUBCHEM_ACTIVITY_OUTCOME': 'activity_outcome',\n","    'PUBCHEM_EXT_DATASOURCE_SMILES': 'SMILES',\n","    'Mol removed from mixture': 'mol_removed_from_mixture',\n","    'Small inorganic molecule': 'small_inorganic_mol_from_mixture',\n","    'Small organic molecule': 'small_organic_mol_from_mixture'\n","})\n","final_inactives = final_inactives.rename(columns={\n","    'PUBCHEM_CID': 'CID',\n","    'PUBCHEM_ACTIVITY_OUTCOME': 'activity_outcome',\n","    'PUBCHEM_EXT_DATASOURCE_SMILES': 'SMILES',\n","    'Mol removed from mixture': 'mol_removed_from_mixture',\n","    'Small inorganic molecule': 'small_inorganic_mol_from_mixture',\n","    'Small organic molecule': 'small_organic_mol_from_mixture'\n","})\n","\n","#swap the positions of the columns InChI and activity_outcome:\n","final_actives = final_actives[['CID', 'SMILES', 'InChI', 'activity_outcome', 'activity_value', 'mol_removed_from_mixture', 'small_inorganic_mol_from_mixture', 'small_organic_mol_from_mixture']]\n","final_inactives = final_inactives[['CID', 'SMILES', 'InChI', 'activity_outcome', 'activity_value', 'mol_removed_from_mixture', 'small_inorganic_mol_from_mixture', 'small_organic_mol_from_mixture']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0RBOb9kFsIAA"},"outputs":[],"source":["#export:\n","final_actives.to_csv(f'{data_folder}/finished/final_actives.csv', sep=',', index=False)\n","final_inactives.to_csv(f'{data_folder}/finished/final_inactives.csv', sep=',', index=False)"]},{"cell_type":"markdown","metadata":{"id":"FPAYTZkisIAA"},"source":["## B. Compile Control Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y2NVlOWfsIAA"},"outputs":[],"source":["for AID in AIDs:\n","    exec(f\"raw{AID} = pd.read_csv(f'{data_folder}/before_finished/step_1/AID{AID}.csv', sep=',', header=0)\")\n","\n","#import inchi:\n","for AID in AIDs:\n","    exec(f\"std_inchi{AID} = pd.read_csv(f'{data_folder}/before_finished/step_3/std_inchi_{AID}.txt', sep='\\t', header=None)\")\n","\n","#Update inchi\n","for AID in AIDs:\n","    exec(f\"\"\"\n","raw_inchi_dict{AID} = dict(zip(std_inchi{AID}[0], std_inchi{AID}[1]))\n","raw{AID}['InChI'] = raw{AID}['PUBCHEM_CID'].map(raw_inchi_dict{AID})\n","\"\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o4mBRcLasIAA"},"outputs":[],"source":["raw_hits = raw449739[raw449739['PUBCHEM_ACTIVITY_OUTCOME'] == 'Active']\n","raw_inactives = raw449739[raw449739['PUBCHEM_ACTIVITY_OUTCOME'] == 'Inactive']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X9LGILXDsIAA"},"outputs":[],"source":["# Add some other columns to match the format of the curated data:\n","raw_hits.loc[:, 'activity_value'] = np.nan\n","raw_hits.loc[:, 'mol_removed_from_mixture'] = np.nan\n","raw_hits.loc[:, 'small_inorganic_mol_from_mixture'] = np.nan\n","raw_hits.loc[:, 'small_organic_mol_from_mixture'] = np.nan\n","\n","raw_inactives.loc[:, 'activity_value'] = np.nan\n","raw_inactives.loc[:, 'mol_removed_from_mixture'] = np.nan\n","raw_inactives.loc[:, 'small_inorganic_mol_from_mixture'] = np.nan\n","raw_inactives.loc[:, 'small_organic_mol_from_mixture'] = np.nan"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BCJQc7k5sIAA"},"outputs":[],"source":["# Rename the columns:\n","raw_hits = raw_hits.rename(columns={\n","    'PUBCHEM_CID': 'CID',\n","    'PUBCHEM_ACTIVITY_OUTCOME': 'activity_outcome',\n","    'PUBCHEM_EXT_DATASOURCE_SMILES': 'SMILES',\n","})\n","raw_inactives = raw_inactives.rename(columns={\n","    'PUBCHEM_CID': 'CID',\n","    'PUBCHEM_ACTIVITY_OUTCOME': 'activity_outcome',\n","    'PUBCHEM_EXT_DATASOURCE_SMILES': 'SMILES',\n","})\n","\n","#swap the positions of the columns InChI and activity_outcome:\n","raw_hits = raw_hits[['CID', 'SMILES', 'InChI', 'activity_outcome', 'activity_value', 'mol_removed_from_mixture', 'small_inorganic_mol_from_mixture', 'small_organic_mol_from_mixture']]\n","raw_inactives = raw_inactives[['CID', 'SMILES', 'InChI', 'activity_outcome', 'activity_value', 'mol_removed_from_mixture', 'small_inorganic_mol_from_mixture', 'small_organic_mol_from_mixture']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LsuoGRuCsIAA"},"outputs":[],"source":["if not os.path.exists(f'{data_folder}/finished/control_data'):\n","    os.makedirs(f'{data_folder}/finished/control_data')\n","\n","#save the hits and inactives\n","raw_hits.to_csv(f'{data_folder}/finished/control_data/raw_hits.csv', sep=',', index=False)\n","raw_inactives.to_csv(f'{data_folder}/finished/control_data/raw_inactives.csv', sep=',', index=False)\n","\n","#save as txt:\n","raw_hits.to_csv(f'{data_folder}/finished/control_data/raw_hits.txt', sep=';', index=False, header=False)\n","raw_inactives.to_csv(f'{data_folder}/finished/control_data/raw_inactives.txt', sep=';', index=False, header=False)"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
