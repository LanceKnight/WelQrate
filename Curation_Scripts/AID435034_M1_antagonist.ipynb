{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[06:33:37] Initializing Normalizer\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import tqdm\n",
    "\n",
    "from rdkit import Chem\n",
    "from tqdm import tqdm\n",
    "from thermo import functional_groups\n",
    "from Bio import Entrez\n",
    "from chembl_structure_pipeline import checker\n",
    "\n",
    "from rdkit.Chem import rdMolDescriptors, Descriptors, Lipinski, Crippen, inchi\n",
    "from rdkit.Chem.FilterCatalog import FilterCatalog, FilterCatalogParams\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/AID435034' # Name your data folder\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before importing data, need to identify which AIDs will be included. Data will be imported from https://pubchem.ncbi.nlm.nih.gov/assay/pcget. For more information on PubChem's programmatic access, refer to: https://pubchem.ncbi.nlm.nih.gov/docs/bioassays. Some other programmatic access options available such as PUG-REST. However, these might not be optimal for bulk retrieval or handling of large dataset due to the limitation of request volume. \n",
    "\n",
    "Data for individual assays include 7 required columns (CIDs, isomeric SMILES, etc.) and optional test results. Refer to https://ftp.ncbi.nlm.nih.gov/pubchem/Bioassay/CSV/README for further details. For datasets intended for regression model, additional columns could be extracted accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets retrieving:  4\n"
     ]
    }
   ],
   "source": [
    "# Desired AIDs:\n",
    "AIDs = [628, 677, 859, 860]\n",
    "\n",
    "#Keep unique values in list AIDs (since there could be overlapping AIDs from different targets or project)\n",
    "AIDs = list(set(AIDs))\n",
    "AIDs = [str(AID) for AID in AIDs]\n",
    "print('Number of datasets retrieving: ', len(AIDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 4 complete\n",
      "2 out of 4 complete\n",
      "3 out of 4 complete\n",
      "4 out of 4 complete\n"
     ]
    }
   ],
   "source": [
    "#Data to be extracted from the assay:\n",
    "col_list = ['PUBCHEM_CID','PUBCHEM_EXT_DATASOURCE_SMILES', 'PUBCHEM_ACTIVITY_OUTCOME']\n",
    "\n",
    "count = 0\n",
    "for AID in AIDs:\n",
    "    url = f'https://pubchem.ncbi.nlm.nih.gov/assay/pcget.cgi?query=download&record_type=datatable&actvty=all&response_type=save&aid={AID}'\n",
    "    assay = pd.read_csv(url, usecols=col_list)\n",
    "\n",
    "    #convert SMILES to string\n",
    "    assay['PUBCHEM_EXT_DATASOURCE_SMILES'] = assay['PUBCHEM_EXT_DATASOURCE_SMILES'].astype(str)\n",
    "\n",
    "    #delete rows with nan values\n",
    "    assay = assay.dropna(subset=['PUBCHEM_EXT_DATASOURCE_SMILES', 'PUBCHEM_ACTIVITY_OUTCOME', 'PUBCHEM_CID'])\n",
    "\n",
    "    #convert cids to int: \n",
    "    assay['PUBCHEM_CID'] = assay['PUBCHEM_CID'].astype(int)\n",
    "\n",
    "    #reindex assay dataframe from 0:\n",
    "    assay.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    #Create a new folder to save the data (with relative path):\n",
    "    if not os.path.exists(f'{data_folder}/before_finished/step_1'):\n",
    "        os.makedirs(f'{data_folder}/before_finished/step_1')\n",
    "    assay.to_csv(f'{data_folder}/before_finished/step_1/AID{AID}.csv', index=False)\n",
    "    count += 1\n",
    "    print(f'{count} out of {len(AIDs)} complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Isomeric SMILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of our project, we would like to include isomeric form of SMILES representation in our final dataset. Although PubChem claimed that their datatable should include isomeric SMILES (https://pubchem.ncbi.nlm.nih.gov/docs/bioassays), some dataset might include non-isomeric SMILES. This step is to import isomeric SMILES based on CIDs. \n",
    "\n",
    "Several packages such as RDkit have modules to return isomeric SMILES from a given input SMILES. However, for consistency, we decided to use the PubChem Identifier Exchange Service, which take an input identifier (CIDs, SMILES, InChI, etc.)  and return the corresponding identifier (CIDs, isomeric SMILES, InChIs, etc.). Here, we export the list of CIDs for compounds in our dataset and use this server to retrieve their isomeric SMILES. For more information, refer to: https://pubchem.ncbi.nlm.nih.gov/docs/identifier-exchange-service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new step folder:\n",
    "if not os.path.exists(f'{data_folder}/before_finished/step_2'):\n",
    "    os.makedirs(f'{data_folder}/before_finished/step_2')\n",
    "\n",
    "#Export list of CIDs to csv with one column without the column name:\n",
    "for AID in AIDs:\n",
    "    assay = pd.read_csv(f'{data_folder}/before_finished/step_1/AID{AID}.csv')\n",
    "    assay['PUBCHEM_CID'].to_csv(f'{data_folder}/before_finished/step_2/CID{AID}.csv', index=False, header=False)\n",
    "\"\"\"\n",
    "After this step, submit the lists of CIDs at https://pubchem.ncbi.nlm.nih.gov/idexchange/idexchange.cgi \n",
    "    Operator type: \"same CID\" \n",
    "    Output IDs \"SMILES\" (isomeric SMILES by default) \n",
    "    Output method: \"Two column file showing each input output-correspondence\"\n",
    "    Compression: \"No compression\"\n",
    "Refer to https://pubchem.ncbi.nlm.nih.gov/docs/identifier-exchange-service for more details.\n",
    "The output files (converted isomeric SMILES) should be named as \"isomeric_smi_{AID}.txt\" and saved to the \"step_2\" folder.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_isomeric_smiles(AIDs):\n",
    "    \"\"\"\n",
    "    Check if the SMILES in the assay are isomeric or not.\n",
    "    Input: AIDs (list of strings)\n",
    "    Output: non_isomeric_smi_cids (dictionary with AID as key and list of non-isomeric CIDs as values for the datasets in AIDs\n",
    "    \"\"\"\n",
    "    non_isomeric_smi_cids = {}\n",
    "    for AID in AIDs:    \n",
    "        non_isomeric_smi_cids[AID] = []\n",
    "        #import SMILES.txt file as a table:\n",
    "        correct_isomeric_smiles = pd.read_csv(f'{data_folder}/before_finished/step_2/isomeric_smi_{AID}.txt', sep='\\t', header=None)\n",
    "        assay = pd.read_csv(f'{data_folder}/before_finished/step_1/AID{AID}.csv')\n",
    "\n",
    "        #compare smiles in assay with smiles in correct_smiles:\n",
    "        for cid in assay['PUBCHEM_CID']:\n",
    "            if assay.loc[assay['PUBCHEM_CID'] == cid, 'PUBCHEM_EXT_DATASOURCE_SMILES'].values[0] != correct_isomeric_smiles.loc[correct_isomeric_smiles[0] == cid, 1].values[0]:\n",
    "                non_isomeric_smi_cids[AID].append(cid)\n",
    "\n",
    "        if len(non_isomeric_smi_cids[AID]) == 0:\n",
    "            print(f'All SMILES in AID {AID} are isomeric')\n",
    "        else:\n",
    "            print(f'There are some non-isomeric SMILES in AID {AID}:')\n",
    "            print(non_isomeric_smi_cids[AID])\n",
    "\n",
    "    return non_isomeric_smi_cids\n",
    "\n",
    "def update_isomeric(AIDs, non_isomeric_smi_cids):\n",
    "    \"\"\"\n",
    "    Update the SMILES in the assay to isomeric SMILES.\n",
    "    Input: AIDs (list of strings), non_isomeric_smi_cids (dictionary with AID as key and list of non-isomeric CIDs as values)\n",
    "    \"\"\"\n",
    "    with open(f'{data_folder}/before_finished/step_2/non_isomeric_smi_cids.txt', 'w') as f:\n",
    "        # record the non-isomeric SMILES \n",
    "        for AID in AIDs:\n",
    "            assay = pd.read_csv(f'{data_folder}/before_finished/step_1/AID{AID}.csv')\n",
    "            correct_isomeric_smiles = pd.read_csv(f'{data_folder}/before_finished/step_2/isomeric_smi_{AID}.txt', sep='\\t', header=None)\n",
    "            f.write(f'AID {AID}: {non_isomeric_smi_cids[AID]}\\n')\n",
    "\n",
    "            for cid in non_isomeric_smi_cids[AID]:\n",
    "                f.write(f'CID {cid}: {assay.loc[assay[\"PUBCHEM_CID\"] == cid, \"PUBCHEM_EXT_DATASOURCE_SMILES\"].values[0]} -> {correct_isomeric_smiles.loc[correct_isomeric_smiles[0] == cid, 1].values[0]}\\n')\n",
    "                assay.loc[assay['PUBCHEM_CID'] == cid, 'PUBCHEM_EXT_DATASOURCE_SMILES'] = correct_isomeric_smiles.loc[correct_isomeric_smiles[0] == cid, 1].values[0]\n",
    "\n",
    "            f.write(f'===\\n')\n",
    "            assay.to_csv(f'{data_folder}/before_finished/step_2/AID{AID}.csv', index=False)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All SMILES in AID 859 are isomeric\n",
      "There are some non-isomeric SMILES in AID 628:\n",
      "[2997662, 2997957, 2999888]\n",
      "All SMILES in AID 677 are isomeric\n",
      "All SMILES in AID 860 are isomeric\n"
     ]
    }
   ],
   "source": [
    "non_isomeric_smi_cids = check_isomeric_smiles(AIDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Here they returned that three smiles in AID628 were not isomeric. This shows that the SMILES representation of some compounds in the given datasets might not be isomeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_isomeric(AIDs, non_isomeric_smi_cids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. InChI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to include standard InChI to diversify users' choice of which data they would like to use for their own benchmark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new step folder:\n",
    "if not os.path.exists(f'{data_folder}/before_finished/step_3'):\n",
    "    os.makedirs(f'{data_folder}/before_finished/step_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, it is convenient to use the PubChem Identifier Exchange Service (https://pubchem.ncbi.nlm.nih.gov/idexchange/idexchange.cgi) with operator type \"same CID\" and Output IDs \"InChI\" to retrieve InChI from a given list of input CIDs. The same CID lists from STEP 2 could be used here. The resulted InChIs could be checked if being standard by indentifying the presence of 'InChI=1S' at the begining of each InChI string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CID lists (in \"step_2\" folder should be submitted to PubChem Identifier Exchange Service)\n",
    "    Operator type: \"same CID\" \n",
    "    Output IDs \"InChI\"\n",
    "    Output method: \"Two column file showing each input output-correspondence\"\n",
    "    Compression: \"No compression\"\n",
    "InChI list should be saved into \"step_3\" folder, named as \"std_inchi{AID}.txt\" \n",
    "\"\"\"\n",
    "# Import dataframes:\n",
    "for AID in AIDs: \n",
    "    exec(f'AID{AID} = pd.read_csv(\"{data_folder}/before_finished/step_2/AID{AID}.csv\")')\n",
    "    exec(f'AID{AID}_InChI = pd.read_csv(\"{data_folder}/before_finished/step_3/std_inchi_{AID}.txt\", sep=\"\\\\t\", header=None)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All InChI in AID859 are standard\n",
      "All InChI in AID628 are standard\n",
      "All InChI in AID677 are standard\n",
      "All InChI in AID860 are standard\n"
     ]
    }
   ],
   "source": [
    "#Check if they are all standard InChI:\n",
    "for AID in AIDs:\n",
    "    check_inchi = f\"\"\"\n",
    "non_standard_InChI = []\n",
    "for i in range(len(AID{AID}_InChI[1])):\n",
    "    if not AID{AID}_InChI[1][i].startswith('InChI=1S'):\n",
    "        non_standard_InChI.append(AID{AID}_InChI[1][i])\n",
    "if not non_standard_InChI:\n",
    "    print('All InChI in AID{AID} are standard')\n",
    "else:\n",
    "    print('There are some non-standard InChI in AID{AID}')\n",
    "    print(non_standard_InChI)\n",
    "    print('===')\n",
    "\"\"\"\n",
    "    exec(check_inchi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we concatenate the InChIs in our tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert AID626_InChI to a dictionary and save the files\n",
    "for AID in AIDs: \n",
    "    update_inchi = f\"\"\"\n",
    "AID{AID}_InChI_dict = dict(zip(AID{AID}_InChI[0], AID{AID}_InChI[1]))\n",
    "AID{AID}['InChI'] = AID{AID}['PUBCHEM_CID'].map(AID{AID}_InChI_dict)\n",
    "AID{AID}['InChI'] = AID{AID}['InChI'].astype(str)\n",
    "AID{AID}.to_csv(r\"{data_folder}/before_finished/step_3/AID{AID}.csv\", index=False)\n",
    "\"\"\"\n",
    "    exec(update_inchi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Check duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When checking duplicates in the datasets, we would like to know if there are\n",
    "1) Multiple identical molecules\n",
    "2) Molecules with identical CID but different InChIs or SMILES\n",
    "3) Molecules with identical InChI but with different CIDs or SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import:\n",
    "for AID in AIDs:\n",
    "    exec(f\"AID{AID} = pd.read_csv(r'{data_folder}/before_finished/step_3/AID{AID}.csv', sep=',', header=0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new step folder:\n",
    "if not os.path.exists(f'{data_folder}/before_finished/step_4'):\n",
    "    os.makedirs(f'{data_folder}/before_finished/step_4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Checking identical molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of AID859 InChI duplicates:  0\n",
      "Number of AID859 SMILES duplicates:  0\n",
      "Number of AID859 CID duplicates:  0\n",
      "Number of AID628 InChI duplicates:  12\n",
      "Number of AID628 SMILES duplicates:  12\n",
      "Number of AID628 CID duplicates:  12\n",
      "Number of AID677 InChI duplicates:  0\n",
      "Number of AID677 SMILES duplicates:  0\n",
      "Number of AID677 CID duplicates:  0\n",
      "Number of AID860 InChI duplicates:  0\n",
      "Number of AID860 SMILES duplicates:  0\n",
      "Number of AID860 CID duplicates:  0\n"
     ]
    }
   ],
   "source": [
    "#Return all duplicates by comparing InChI, SMILES, and CIDs:\n",
    "for AID in AIDs:\n",
    "    check_duplicate = f\"\"\"\n",
    "AID{AID}_duplicates_InChI = AID{AID}[AID{AID}.duplicated(subset=['InChI'], keep=False)]\n",
    "AID{AID}_duplicates_SMILES = AID{AID}[AID{AID}.duplicated(subset=['PUBCHEM_EXT_DATASOURCE_SMILES'], keep=False)]\n",
    "AID{AID}_duplicates_CIDs = AID{AID}[AID{AID}.duplicated(subset=['PUBCHEM_CID'], keep=False)]\n",
    "print('Number of AID{AID} InChI duplicates: ', len(AID{AID}_duplicates_InChI))\n",
    "print('Number of AID{AID} SMILES duplicates: ', len(AID{AID}_duplicates_SMILES))\n",
    "print('Number of AID{AID} CID duplicates: ', len(AID{AID}_duplicates_CIDs))\n",
    "\"\"\"\n",
    "    exec(check_duplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write duplicates to a txt file: \n",
    "with open(f'{data_folder}/before_finished/step_4/duplicates.txt', 'w') as f:\n",
    "    for AID in AIDs: \n",
    "        duplicates_InChI = eval(f'AID{AID}_duplicates_InChI')\n",
    "        duplicates_SMILES = eval(f'AID{AID}_duplicates_SMILES')\n",
    "        duplicates_CIDs = eval(f'AID{AID}_duplicates_CIDs')\n",
    "        f.write(f'\\n\\nAID{AID} InChI duplicates:\\n')\n",
    "        f.write(duplicates_InChI.to_string())\n",
    "        f.write(f'\\nAID{AID} SMILES duplicates:\\n')\n",
    "        f.write(duplicates_SMILES.to_string())\n",
    "        f.write(f'\\nAID{AID} CID duplicates:\\n')\n",
    "        f.write(duplicates_CIDs.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Same CIDs but different chemical representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reindex\n",
    "for AID in AIDs: \n",
    "    exec(f\"AID{AID}_duplicates_CIDs.reset_index(drop=True, inplace=True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_folder}/before_finished/step_4/sameCID_different_others.txt', 'w') as f:\n",
    "    for AID in AIDs: \n",
    "        sameCID_differentInChI = []\n",
    "        sameCID_differentSMILES = []\n",
    "        duplicates_CIDs = eval(f'AID{AID}_duplicates_CIDs')\n",
    "        for i in range(len(duplicates_CIDs['PUBCHEM_CID'])):\n",
    "            for j in range(i+1, len(duplicates_CIDs['PUBCHEM_CID'])):\n",
    "                if duplicates_CIDs['PUBCHEM_CID'][i] == duplicates_CIDs['PUBCHEM_CID'][j]:\n",
    "                    if duplicates_CIDs['InChI'][i] != duplicates_CIDs['InChI'][j]:\n",
    "                        sameCID_differentInChI.append((duplicates_CIDs['PUBCHEM_CID'][i], duplicates_CIDs['PUBCHEM_CID'][j]))\n",
    "                    if duplicates_CIDs['PUBCHEM_EXT_DATASOURCE_SMILES'][i] != duplicates_CIDs['PUBCHEM_EXT_DATASOURCE_SMILES'][j]:\n",
    "                        sameCID_differentSMILES.append((duplicates_CIDs['PUBCHEM_CID'][i], duplicates_CIDs['PUBCHEM_CID'][j]))\n",
    "\n",
    "        if sameCID_differentInChI == []:\n",
    "            f.write(f'No duplicate CIDs with different InChIs in AID{AID}\\n')\n",
    "        else:\n",
    "            f.write('Found duplicate CIDs with different InChIs in AID{AID}:\\n')\n",
    "            f.write('\\n'.join(str(item) for item in sameCID_differentInChI))\n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        if sameCID_differentSMILES == []:\n",
    "            f.write(f'No duplicate CIDs with different SMILES in AID{AID}\\n')\n",
    "        else:\n",
    "            f.write(f'Found duplicate CIDs with different SMILES in AID{AID}:\\n')\n",
    "            f.write('\\n'.join(str(item) for item in sameCID_differentSMILES))\n",
    "            f.write(\"\\n\")\n",
    "        f.write(\"===\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Same InChI but with different CIDs or SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reindex\n",
    "for AID in AIDs: \n",
    "    exec(f\"AID{AID}_duplicates_InChI.reset_index(drop=True, inplace=True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_folder}/before_finished/step_4/sameInChI_different_others.txt', 'w') as f:\n",
    "    for AID in AIDs: \n",
    "        sameInChI_differentCID = []\n",
    "        sameInChI_differentSMILES = []\n",
    "        duplicates_InChI = eval(f'AID{AID}_duplicates_InChI')\n",
    "        for i in range(len(duplicates_InChI['InChI'])):\n",
    "            for j in range(i+1, len(duplicates_InChI['InChI'])):\n",
    "                if duplicates_InChI['InChI'][i] == duplicates_InChI['InChI'][j]:\n",
    "                    if duplicates_InChI['PUBCHEM_CID'][i] != duplicates_InChI['PUBCHEM_CID'][j]:\n",
    "                        sameInChI_differentCID.append((duplicates_InChI['PUBCHEM_CID'][i], duplicates_InChI['PUBCHEM_CID'][j]))\n",
    "                    if duplicates_InChI['PUBCHEM_EXT_DATASOURCE_SMILES'][i] != duplicates_InChI['PUBCHEM_EXT_DATASOURCE_SMILES'][j]:\n",
    "                        sameInChI_differentSMILES.append((duplicates_InChI['PUBCHEM_CID'][i], duplicates_InChI['PUBCHEM_CID'][j]))\n",
    "        \n",
    "        if sameInChI_differentCID == []:\n",
    "            f.write(f'No duplicate InChIs with different CIDs in AID{AID}\\n')\n",
    "        else:\n",
    "            f.write('Found duplicate InChIs with different CIDs in AID{AID}:\\n')\n",
    "            f.write('\\n'.join(str(item) for item in sameInChI_differentCID))\n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        if sameInChI_differentSMILES == []:\n",
    "            f.write(f'No duplicate InChIs with different SMILES in AID{AID}\\n')\n",
    "        else:\n",
    "            f.write(f'Found duplicate InChIs with different SMILES in AID{AID}:\\n')\n",
    "            f.write('\\n'.join(str(item) for item in sameInChI_differentSMILES))\n",
    "            f.write(\"\\n\")\n",
    "        f.write(\"===\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Same SMILES but with different CIDs or SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reindex\n",
    "for AID in AIDs: \n",
    "    exec(f\"AID{AID}_duplicates_SMILES.reset_index(drop=True, inplace=True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_folder}/before_finished/step_4/sameSMILES_different_others.txt', 'w') as f:\n",
    "    for AID in AIDs: \n",
    "        sameSMILES_differentCID = []\n",
    "        sameSMILES_differentInChI = []\n",
    "        duplicates_SMILES = eval(f'AID{AID}_duplicates_SMILES')\n",
    "        for i in range(len(duplicates_SMILES['PUBCHEM_EXT_DATASOURCE_SMILES'])):\n",
    "            for j in range(i+1, len(duplicates_SMILES['PUBCHEM_EXT_DATASOURCE_SMILES'])):\n",
    "                if duplicates_SMILES['PUBCHEM_EXT_DATASOURCE_SMILES'][i] == duplicates_SMILES['PUBCHEM_EXT_DATASOURCE_SMILES'][j]:\n",
    "                    if duplicates_SMILES['PUBCHEM_CID'][i] != duplicates_SMILES['PUBCHEM_CID'][j]:\n",
    "                        sameSMILES_differentCID.append((duplicates_SMILES['PUBCHEM_CID'][i], duplicates_SMILES['PUBCHEM_CID'][j]))\n",
    "                    if duplicates_SMILES['InChI'][i] != duplicates_SMILES['InChI'][j]:\n",
    "                        sameSMILES_differentInChI.append((duplicates_SMILES['PUBCHEM_CID'][i], duplicates_SMILES['PUBCHEM_CID'][j]))\n",
    "        \n",
    "        if sameSMILES_differentCID == []:\n",
    "            f.write(f'No duplicate SMILES with different CIDs in AID{AID}\\n')\n",
    "        else:\n",
    "            f.write(f'Found duplicate SMILES with different CIDs in AID{AID}:\\n')\n",
    "            f.write('\\n'.join(str(item) for item in sameSMILES_differentCID))\n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        if sameSMILES_differentInChI == []:\n",
    "            f.write(f'No duplicate SMILES with different InChIs in AID{AID}\\n')\n",
    "        else:\n",
    "            f.write(f'Found duplicate SMILES with different InChIs in AID{AID}:\\n')\n",
    "            f.write('\\n'.join(str(item) for item in sameSMILES_differentInChI))\n",
    "            f.write(\"\\n\")\n",
    "        f.write(\"===\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Drop duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dropping duplicates, we will keep the first molecule in a pair or a group of duplicates. For example, here there are 12 duplicates (6 pairs) so we keep 6 of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more duplicate InChI in AID859\n",
      "No more duplicate InChI in AID628\n",
      "No more duplicate InChI in AID677\n",
      "No more duplicate InChI in AID860\n"
     ]
    }
   ],
   "source": [
    "# Keep only the first duplicate in the dataframes:\n",
    "for AID in AIDs: \n",
    "    exec(f\"AID{AID}.drop_duplicates(subset=['InChI'], keep='first', inplace=True)\")\n",
    "\n",
    "    last_check = f\"\"\"\n",
    "if len(AID{AID}[AID{AID}.duplicated(subset=['InChI'], keep=False)]) == 0:\n",
    "    print('No more duplicate InChI in AID{AID}')\n",
    "else:\n",
    "    print('There are still duplicate InChI in AID{AID}')   \n",
    "    \"\"\"\n",
    "    exec(last_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframes to csv:\n",
    "for AID in AIDs: \n",
    "    exec(f\"AID{AID}.to_csv(r'{data_folder}/before_finished/step_4/AID{AID}.csv', index=False)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Hierarchical Curation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the hierarchical curation, there are some rules: \n",
    "\n",
    "(1) All assays used should be on the same or close species/cell lines. Optimally, they should also be from the same project/laboratory.\n",
    "\n",
    "(2) Primary actives (PrA) will have a large false-positive rate. Therefore, they should be tested in follow-up confirmatory screens (optimally dose-reponse). \n",
    "\n",
    "(3) Actives could be promiscuous. Therefore, it is optimal to have counter-screens on different targets to test specificity.\n",
    "\n",
    "(4) For some projects, compounds were tested in multiple rounds. Therefore, assays often have hierarchical relations. From a single primary screen (Pr), active compounds (Pr_A) could be tested in multiple rounds of confirmatory screens (Cf_1, Cf_2, ..., Cf_final) or counter screens (Ct_1, Ct_2, etc.). Actives from confirmatory screens (Cf_A) have a higher possibility of being true active. If an active compound is tested active in counter screens (Ct_A), it is likely to be a promiscuous compound and should not be included. \n",
    "\n",
    "(4) It is important to know the relationship between assays. Active sets from downstream screens always have a lower false-positive rate than active sets from upstream screens due to better assay technologies on a smaller set of compounds. Therefore, final hits should be taken from the intersection of the very last confirmatory assays, without tested active in any counter-screens: \n",
    "Final hits = [Cf_final1_A ∩ Cf_final2_A ∩ ...] \\ [Ct_1_A ∪ Ct_2_A ∪ ...]\n",
    "\n",
    "However, if the confirmatory assays are unrelated (tested on different set of compounds), then we might have to take the union of their active sets instead of the intersections as in this formula.\n",
    "\n",
    "(5) The hierarchical relations should be inspected carefully to see if follow-up confirmatory screens include extra compounds (Ex) that were not tested in earlier screens or tested inactive in earlier screens. If exist, these compounds require manual inspection. \n",
    "\n",
    "(6) Final inactives should be taken from primary inactives (Pr_I) (not inconclusive, unspecified, or probes), plus extra compounds that were tested inactive in conformatory screens (Ex_I), if justified.\n",
    "Final inactives = PrI ∪ Ex_I\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Classify groups of compounds in each assay by activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'{data_folder}/before_finished/step_4' \n",
    "keynumbers = [628, 677, 859, 860] # specify the keynumbers you want to import\n",
    "\n",
    "for keynumber in keynumbers:\n",
    "    filename = os.path.join(path, f'AID{keynumber}.csv')\n",
    "    if os.path.exists(filename):\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        exec(f'AID{keynumber} = df')\n",
    "        exec(f'AID{keynumber}_active = df[df[\"PUBCHEM_ACTIVITY_OUTCOME\"]==\"Active\"]')\n",
    "        exec(f'AID{keynumber}_inactive = df[df[\"PUBCHEM_ACTIVITY_OUTCOME\"]==\"Inactive\"]')\n",
    "        exec(f'AID{keynumber}_inconclusive = df[df[\"PUBCHEM_ACTIVITY_OUTCOME\"]==\"Inconclusive\"]')\n",
    "        exec(f'AID{keynumber}_unspecified = df[df[\"PUBCHEM_ACTIVITY_OUTCOME\"]==\"Unspecified\"]')\n",
    "        exec(f'AID{keynumber}_probe = df[df[\"PUBCHEM_ACTIVITY_OUTCOME\"]==\"Probe\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AID</th>\n",
       "      <th>Tested Compounds</th>\n",
       "      <th>Active</th>\n",
       "      <th>Inactive</th>\n",
       "      <th>Inconclusive</th>\n",
       "      <th>Unspecified</th>\n",
       "      <th>Probe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AID628</td>\n",
       "      <td>63656</td>\n",
       "      <td>2179</td>\n",
       "      <td>61477</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AID677</td>\n",
       "      <td>1665</td>\n",
       "      <td>723</td>\n",
       "      <td>942</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AID859</td>\n",
       "      <td>591</td>\n",
       "      <td>231</td>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AID860</td>\n",
       "      <td>719</td>\n",
       "      <td>272</td>\n",
       "      <td>447</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AID  Tested Compounds  Active  Inactive  Inconclusive  Unspecified  \\\n",
       "0  AID628             63656    2179     61477             0            0   \n",
       "1  AID677              1665     723       942             0            0   \n",
       "2  AID859               591     231       360             0            0   \n",
       "3  AID860               719     272       447             0            0   \n",
       "\n",
       "   Probe  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a df with first column the variables name, and the second column the number of rows:\n",
    "df = pd.DataFrame(columns=['AID', 'Tested Compounds', 'Active', 'Inactive', 'Inconclusive', 'Unspecified', 'Probe'])\n",
    "for keynumber in keynumbers:\n",
    "    exec(f'df.loc[len(df)] = [\"AID{keynumber}\", len(AID{keynumber}), len(AID{keynumber}_active), len(AID{keynumber}_inactive), len(AID{keynumber}_inconclusive), len(AID{keynumber}_unspecified), len(AID{keynumber}_probe)]')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Check the hierachical relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_is_in(downstream, upstream): \n",
    "    downstream_in_upstream = downstream[downstream['PUBCHEM_CID'].isin(upstream['PUBCHEM_CID'])]\n",
    "    downstream_notin_upstream = downstream[~downstream['PUBCHEM_CID'].isin(upstream['PUBCHEM_CID'])]\n",
    "    return downstream_in_upstream, downstream_notin_upstream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow: AID628 (Pr), AID677 (Cf_1), AID860 (Ct_1), and AID859 (Cf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among AID859, 0 were tested inactive in AID677. Among these, 0 became active\n",
      "Among AID859, 0 were tested inactive in AID628. Among these, 0 became active\n",
      "Among AID859, 0 were not tested in the AID628. Among these, 0 became active\n",
      "Among AID859, 219 were tested active in the counter AID860. Among these, 144 became active\n"
     ]
    }
   ],
   "source": [
    "a1, a2 = check_is_in(AID859, AID677_inactive)\n",
    "a3, a4 = check_is_in(a1, AID859_active)\n",
    "print(f'Among AID859, {len(a1)} were tested inactive in AID677. Among these, {len(a3)} became active')\n",
    "\n",
    "b1, b2 = check_is_in(AID859, AID628_inactive)\n",
    "b3, b4 = check_is_in(b1, AID859_active)\n",
    "b5, b6 = check_is_in(AID859, AID628)\n",
    "b7, b8 = check_is_in(b6, AID859_active)\n",
    "print(f'Among AID859, {len(b1)} were tested inactive in AID628. Among these, {len(b3)} became active')\n",
    "print(f'Among AID859, {len(b6)} were not tested in the AID628. Among these, {len(b7)} became active')\n",
    "\n",
    "c1, c2 = check_is_in(AID859, AID860_active)\n",
    "c3, c4 = check_is_in(c1, AID859_active)\n",
    "print(f'Among AID859, {len(c1)} were tested active in the counter AID860. Among these, {len(c3)} became active')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, no extra compounds were found. The potential final hits therefore should be the confirmed actives from AID859, subtracted by compounds that were active in the counter screens. Inactives should be taken from the primary inactives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Export the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_hits = AID859_active[~AID859_active['PUBCHEM_CID'].isin(AID860_active['PUBCHEM_CID'])]\n",
    "potential_inactives = AID628_inactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f'{data_folder}/before_finished/step_5'):\n",
    "    os.makedirs(f'{data_folder}/before_finished/step_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the potential hits and inactives to csv:\n",
    "potential_hits.to_csv(f'{data_folder}/before_finished/step_5/potential_hits.csv', index=False)\n",
    "potential_inactives.to_csv(f'{data_folder}/before_finished/step_5/potential_inactives.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. RDkit check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_hits = pd.read_csv(f'{data_folder}/before_finished/step_5/potential_hits.csv', sep=',', header=0)\n",
    "potential_inactives = pd.read_csv(f'{data_folder}/before_finished/step_5/potential_inactives.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_smiles(df):\n",
    "    \"\"\"\n",
    "    This function check if the SMILES strings from a given dataset could be parsed by RDKit or if they returns any problems detected by RDkit\n",
    "    Input: \n",
    "        Pandas dataframe\n",
    "    Output: \n",
    "        mol_list: dictionary with CID as key and RDKit molecule object as value\n",
    "        problem_list: list of problems detected by RDKit\n",
    "        cannot_parse: list of CIDs that could not be parsed by RDKit\n",
    "    \"\"\"\n",
    "    mol_list = {}\n",
    "    problem_list = []\n",
    "    cannot_parse = []\n",
    "\n",
    "    for i in df['PUBCHEM_CID']:\n",
    "\n",
    "        #convert each SMILES to molecule:\n",
    "        m = Chem.MolFromSmiles(df[df['PUBCHEM_CID'] == i]['PUBCHEM_EXT_DATASOURCE_SMILES'].values[0], sanitize=False)\n",
    "        mol_list[i] = m\n",
    "\n",
    "        if m is None:\n",
    "            cannot_parse.append(i) #save if molecule is non-parsable\n",
    "            \n",
    "        elif m is not None:\n",
    "            problems = Chem.DetectChemistryProblems(m) #identify and capture error messages when creating mol objects.\n",
    "        if problems != ():\n",
    "            problem_list.append(problems)\n",
    "            \n",
    "    if len(problem_list) > 0: \n",
    "        print(problem_list)\n",
    "    else:\n",
    "        print(\"No problems detected\")\n",
    "    return mol_list, problem_list, cannot_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No problems detected\n",
      "No problems detected\n"
     ]
    }
   ],
   "source": [
    "mol_hits, problem_list_hits, cannot_parse_hits = process_smiles(potential_hits)\n",
    "mol_inactives, problem_list_inactives, cannot_parse_inactives = process_smiles(potential_inactives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new step folder:\n",
    "if not os.path.exists(f'{data_folder}/before_finished/step_6'):\n",
    "    os.makedirs(f'{data_folder}/before_finished/step_6')\n",
    "\n",
    "with open(f'{data_folder}/before_finished/step_6/problem_list_hits.txt', 'w') as f:\n",
    "    f.write(\"Problems:\\n\")\n",
    "    for item in problem_list_hits:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "    f.write(\"Cannot parse:\\n\")\n",
    "    for item in cannot_parse_hits:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n",
    "with open(f'{data_folder}/before_finished/step_6/problem_list_inactives.txt', 'w') as f:\n",
    "    f.write(\"Problems:\\n\")\n",
    "    for item in problem_list_inactives:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "    f.write(\"Cannot parse:\\n\")\n",
    "    for item in cannot_parse_inactives:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset returned no problem or non-parsable molecule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Inorganics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "potential_hits = pd.read_csv(f'{data_folder}/before_finished/step_5/potential_hits.csv', sep=',', header=0)\n",
    "potential_inactives = pd.read_csv(f'{data_folder}/before_finished/step_5/potential_inactives.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "organic_hits = []\n",
    "inorganic_hits = []\n",
    "\n",
    "for index, row in potential_hits.iterrows():\n",
    "    cid = row['PUBCHEM_CID']\n",
    "    smi = row['PUBCHEM_EXT_DATASOURCE_SMILES']\n",
    "    mol = Chem.MolFromSmiles(smi, sanitize=True)\n",
    "    if functional_groups.is_inorganic(mol):\n",
    "        inorganic_hits.append(cid)\n",
    "    else:\n",
    "        organic_hits.append(cid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "organic_inactives = []\n",
    "inorganic_inactives = []\n",
    "\n",
    "for index, row in potential_inactives.iterrows():\n",
    "    cid = row['PUBCHEM_CID']\n",
    "    smi = row['PUBCHEM_EXT_DATASOURCE_SMILES']\n",
    "    mol = Chem.MolFromSmiles(smi, sanitize=True)\n",
    "    if functional_groups.is_inorganic(mol):\n",
    "        inorganic_inactives.append(cid)\n",
    "    else: \n",
    "        organic_inactives.append(cid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In hits, there are 87 organic molecules and 0 inorganic molecules\n",
      "In inactives, there are 61477 organic molecules and 0 inorganic molecules\n"
     ]
    }
   ],
   "source": [
    "print(f'In hits, there are {len(organic_hits)} organic molecules and {len(inorganic_hits)} inorganic molecules')\n",
    "print(f'In inactives, there are {len(organic_inactives)} organic molecules and {len(inorganic_inactives)} inorganic molecules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new step folder:\n",
    "if not os.path.exists(f'{data_folder}/before_finished/step_7'):\n",
    "    os.makedirs(f'{data_folder}/before_finished/step_7')\n",
    "\n",
    "with open(f'{data_folder}/before_finished/step_7/inorganic.txt', 'w') as f:\n",
    "    f.write(\"Hits:\\n\")\n",
    "    for item in inorganic_hits:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "    f.write(\"\\n\\nInactives:\\n\")\n",
    "    for item in inorganic_inactives:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop inorganics: \n",
    "potential_hits = potential_hits[~potential_hits['PUBCHEM_CID'].isin(inorganic_hits)]\n",
    "potential_inactives = potential_inactives[~potential_inactives['PUBCHEM_CID'].isin(inorganic_inactives)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save: \n",
    "potential_hits.to_csv(f'{data_folder}/before_finished/step_7/organic_hits.csv', index=False)\n",
    "potential_inactives.to_csv(f'{data_folder}/before_finished/step_7/organic_inactives.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Mixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1. Quick check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import: \n",
    "organic_hits = pd.read_csv(f'{data_folder}/before_finished/step_7/organic_hits.csv', sep=',', header=0)\n",
    "organic_inactives = pd.read_csv(f'{data_folder}/before_finished/step_7/organic_inactives.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of mixtures in hits is 21\n",
      "Total number of mixtures in inactives is 1741\n"
     ]
    }
   ],
   "source": [
    "def quick_check_mixtures(name, smiles_list):\n",
    "    count=0\n",
    "    for smiles in smiles_list:\n",
    "        if '.' in smiles:\n",
    "            count+=1\n",
    "    print(f\"Total number of mixtures in {name} is {count}\")\n",
    "\n",
    "quick_check_mixtures('hits', organic_hits['PUBCHEM_EXT_DATASOURCE_SMILES'])\n",
    "quick_check_mixtures('inactives', organic_inactives['PUBCHEM_EXT_DATASOURCE_SMILES'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. Handling mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_smiles_dataframe(df):\n",
    "    \"\"\"\n",
    "    From a given dataframe, detect and handle mixtures based on SMILES representation.\n",
    "    Input: \n",
    "        Pandas dataframe\n",
    "    Output: \n",
    "        (dictionary: CID -> SMILES)\n",
    "            processed: non-mixture forms of every SMILES in the given dataset\n",
    "            removed: mixture components or mixtures removed from the original mixture SMILES\n",
    "            small_organic: small organic molecules that are removed from a size-imbalanced mixtures of organic molecules\n",
    "            small_inorganic: small inorganic molecules that are removed from a mixture of both organic and inorganic molecules\n",
    "            big_organic_not_lipinski: large organic molecules that are not kept due to not passing the lipinski criteria\n",
    "            cleaned_from_mixtures: non-mixture forms after handling of the orignal mixtures\n",
    "    \"\"\"\n",
    "    processed = {}\n",
    "    removed = {}\n",
    "    small_inorganic = {}\n",
    "    small_organic = {}\n",
    "    big_organic_not_lipinski = {}\n",
    "    cleaned_from_mixtures = {}\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        cid = row['PUBCHEM_CID']\n",
    "        smiles = row['PUBCHEM_EXT_DATASOURCE_SMILES']\n",
    "        \n",
    "        if '.' in smiles: # Check for mixtures\n",
    "            molecules = smiles.split('.')\n",
    "            mols = [Chem.MolFromSmiles(mol) for mol in molecules]\n",
    "            num_atoms = [mol.GetNumAtoms() for mol in mols if mol is not None]\n",
    "            \n",
    "            if all(x == num_atoms[0] for x in num_atoms): # Check if all molecules have the same number of atoms. If yes, keep one of them\n",
    "                processed[cid] = molecules[0]\n",
    "                cleaned_from_mixtures[cid] = molecules[0]\n",
    "                removed[cid] = '.'.join(molecules[1:])\n",
    "            else:\n",
    "                if max(num_atoms) - min(num_atoms) <= 5:\n",
    "                    removed[cid] = smiles # Remove the mixture if the difference in number of atoms is less than 5\n",
    "                    print(f\"Cannot decide between {molecules} for CID {cid}\")\n",
    "                else:\n",
    "                    max_index = num_atoms.index(max(num_atoms))\n",
    "                    min_index = num_atoms.index(min(num_atoms))\n",
    "                    if functional_groups.is_inorganic(mols[min_index]) == True:\n",
    "                        processed[cid] = molecules[max_index]\n",
    "                        cleaned_from_mixtures[cid] = molecules[max_index]\n",
    "                        removed[cid] = molecules[min_index] # Keep the organic molecule and remove the inorganic one\n",
    "                        small_inorganic[cid] = molecules[min_index]\n",
    "                    else:\n",
    "                        big_molecule = mols[max_index]\n",
    "                        \n",
    "                        # Calculate properties for Lipinski's rule of five\n",
    "                        mw = Descriptors.MolWt(big_molecule)\n",
    "                        hbd = rdMolDescriptors.CalcNumHBD(big_molecule)\n",
    "                        hba = rdMolDescriptors.CalcNumHBA(big_molecule)\n",
    "                        logp = Crippen.MolLogP(big_molecule)\n",
    "\n",
    "                        # Check Lipinski's criteria\n",
    "                        if mw <= 500 and hbd <= 5 and hba <= 10 and logp <= 5:\n",
    "                            processed[cid] = molecules[max_index] # Keep the big organic molecule if it passes Lipinski's rule of five\n",
    "                            cleaned_from_mixtures[cid] = molecules[max_index]\n",
    "                            removed[cid] = '.'.join([molecules[i] for i in range(len(molecules)) if i != max_index])\n",
    "                            small_organic[cid] = molecules[min_index]\n",
    "                        else:\n",
    "                            removed[cid] = smiles # Remove the mixture if the big organic molecule does not pass Lipinski's rule of five\n",
    "                            big_organic_not_lipinski[cid] = molecules[max_index]\n",
    "                            print(f\"Big organic molecule for CID {cid} does not pass Lipinski's rule of five\")\n",
    "\n",
    "        else:\n",
    "            processed[cid] = smiles\n",
    "            \n",
    "    return processed, removed, small_organic, small_inorganic, big_organic_not_lipinski, cleaned_from_mixtures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot decide between ['CC1=NC2=C(O1)C3=CC=CC=C3C=C2', 'C1=C(C=C(C(=C1[N+](=O)[O-])O)[N+](=O)[O-])[N+](=O)[O-]'] for CID 3241713\n",
      "Big organic molecule for CID 3244813 does not pass Lipinski's rule of five\n",
      "Cannot decide between ['CN(C)C1=NC2=CC=CC=C2C(=C1)N', 'C1=C(NC(=O)NC1=O)C(=O)O'] for CID 646688\n",
      "Cannot decide between ['C1C2(CN3CN1CN(C2)C3)N', 'C1=CC(=CN=C1)C(=O)O'] for CID 648270\n",
      "Cannot decide between ['CN(C)C1=NC2=C(CCC2)C(=C1)N', 'C1=C(C=NC=C1O)C(=O)O'] for CID 652177\n",
      "Cannot decide between ['CC1=NC2=C(S1)C3=CC=CC=C3C=C2', 'C1=C(C=C(C(=C1[N+](=O)[O-])O)[N+](=O)[O-])[N+](=O)[O-]'] for CID 654127\n",
      "Cannot decide between ['C1CC1C(C2CC2)NC3=NCCO3', 'C(=C/C(=O)O)\\\\C(=O)O'] for CID 5388964\n",
      "Cannot decide between ['CN1C(=O)C2=C(N=C(N2)Cl)N(C1=O)C(=O)[O-]', 'CN(C)CCOC(C1=CC=CC=C1)C2=CC=CC=C2'] for CID 657227\n",
      "Cannot decide between ['CC[N+](C)(C)CC1=CC=CC=C1Br', 'CC1=CC=C(C=C1)S(=O)(=O)[O-]'] for CID 6100\n",
      "Cannot decide between ['C1CN(CCN1CCOCCO)C(C2=CC=CC=C2)C3=CC=C(C=C3)Cl', 'C1=CC=C2C(=C1)C=C(C(=C2CC3=C(C(=CC4=CC=CC=C43)C(=O)O)O)O)C(=O)O'] for CID 25096\n",
      "Big organic molecule for CID 5284352 does not pass Lipinski's rule of five\n",
      "Big organic molecule for CID 444034 does not pass Lipinski's rule of five\n",
      "Big organic molecule for CID 5284439 does not pass Lipinski's rule of five\n"
     ]
    }
   ],
   "source": [
    "processed_hits, removed_hits, small_organic_hits, small_inorganic_hits, not_lipinski_hits, cleaned_hits = process_smiles_dataframe(organic_hits)\n",
    "processed_inactives, removed_inactives, small_organic_inactives, small_inorganic_inactives, not_lipinski_inactives, cleaned_inactives = process_smiles_dataframe(organic_inactives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new step folder\n",
    "if not os.path.exists(f'{data_folder}/before_finished/step_8'):\n",
    "    os.makedirs(f'{data_folder}/before_finished/step_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate df with the smiles column in the cleaned_hits or cleaned_inactives dictionary:\n",
    "cleaned_hits_df = pd.DataFrame(list(cleaned_hits.values()), columns=['PUBCHEM_EXT_DATASOURCE_SMILES'])\n",
    "cleaned_inactives_df = pd.DataFrame(list(cleaned_inactives.values()), columns=['PUBCHEM_EXT_DATASOURCE_SMILES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the cleaned hits and inactives to csv:\n",
    "cleaned_hits_df.to_csv(f'{data_folder}/before_finished/step_8/cleaned_mixtures_hits.csv', index=False, header=False)\n",
    "cleaned_inactives_df.to_csv(f'{data_folder}/before_finished/step_8/cleaned_mixtures_inactives.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3241713 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n",
      "3244813 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n",
      "646688 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n",
      "648270 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n",
      "652177 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n",
      "654127 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n",
      "5388964 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n",
      "657227 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n",
      "6100 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n",
      "25096 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n",
      "5284352 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n",
      "444034 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n",
      "5284439 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n"
     ]
    }
   ],
   "source": [
    "def process_mixture_df(name, df, processed, removed, small_organic, small_inorganic):\n",
    "    \"\"\"\n",
    "    Update a given dataframe with information on mixture handling\n",
    "    \"\"\"\n",
    "    indices_to_drop = []  # List to keep track of row indices that should be dropped\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        cid = row['PUBCHEM_CID']\n",
    "        if cid in processed:\n",
    "            df.loc[index, 'PUBCHEM_EXT_DATASOURCE_SMILES'] = processed[cid]\n",
    "            if cid in removed:\n",
    "                df.loc[index, 'Mol removed from mixture'] = removed[cid]\n",
    "            if cid in small_organic:\n",
    "                df.loc[index, 'Small organic molecule'] = small_organic[cid]\n",
    "            if cid in small_inorganic:\n",
    "                df.loc[index, 'Small inorganic molecule'] = small_inorganic[cid]\n",
    "        else:\n",
    "            indices_to_drop.append(index)\n",
    "            print(f\"{cid} has been removed from {name} because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\")\n",
    "    \n",
    "    # Drop rows outside the loop and reset index if needed\n",
    "    new_df = df.drop(indices_to_drop).reset_index(drop=True)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "processed_hits_df = process_mixture_df('hits_M1_antagonist', organic_hits, processed_hits, removed_hits, small_organic_hits, small_inorganic_hits)\n",
    "processed_inactives_df = process_mixture_df('inactives_M1_antagonist', organic_inactives, processed_inactives, removed_inactives, small_organic_inactives, small_inorganic_inactives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframes saved successfully\n"
     ]
    }
   ],
   "source": [
    "with open(f'{data_folder}/before_finished/step_8/mixture.txt', 'w') as f:\n",
    "    f.write(f\"\"\"\n",
    "Hits before processing: {len(organic_hits)}\n",
    "Hits before processing: {len(organic_hits)}\n",
    "Hits after processing: {len(processed_hits_df)}\n",
    "Mixtures detected: {len(removed_hits)}\n",
    "Mixtures with small inorganic molecules: {len(small_inorganic_hits)}\n",
    "Mixtures with big organic molecules passing Lipinski: {len(small_organic_hits)}\n",
    "Mixtures with big organic molecules not passing Lipinski: {len(not_lipinski_hits)}\n",
    "\n",
    "Inactives before processing: {len(organic_inactives)}\n",
    "Inactives after processing: {len(processed_inactives_df)}\n",
    "Mixtures detected: {len(removed_inactives)}\n",
    "Mixtures with small inorganic molecules: {len(small_inorganic_inactives)}\n",
    "Mixtures with big organic molecules passing Lipinski: {len(small_organic_inactives)}\n",
    "Mixtures with big organic molecules not passing Lipinski: {len(not_lipinski_inactives)}\n",
    "\"\"\")\n",
    "\n",
    "# Save the processed dataframes to csv\n",
    "processed_hits_df.to_csv(f'{data_folder}/before_finished/step_8/post8_hits.csv', index=False)\n",
    "processed_inactives_df.to_csv(f'{data_folder}/before_finished/step_8/post8_inactives.csv', index=False)\n",
    "\n",
    "print('Dataframes saved successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Neutralize & 10. Aromatize molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new step folder:\n",
    "if not os.path.exists(f'{data_folder}/before_finished/step_9_10'):\n",
    "    os.makedirs(f'{data_folder}/before_finished/step_9_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import:\n",
    "pre9_hits = pd.read_csv(f'{data_folder}/before_finished/step_8/post8_hits.csv', sep=',', header=0)\n",
    "pre9_inactives = pd.read_csv(f'{data_folder}/before_finished/step_8/post8_inactives.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neutralize_atoms(mol):\n",
    "    \"\"\"\n",
    "    Code adapted from https://www.rdkit.org/docs/Cookbook.html. \n",
    "    Source: https://baoilleach.blogspot.com/2019/12/no-charge-simple-approach-to.html\n",
    "    (Noel O’Boyle, 2019)\n",
    "\n",
    "    This function return a neutralized molecules for a given input Mol object. \n",
    "    Additional handling was added for molecules with tetracoordinated boron. \n",
    "    \"\"\"\n",
    "    pattern = Chem.MolFromSmarts(\"[+1!h0!$([*]~[-1,-2,-3,-4]),-1!$([*]~[+1,+2,+3,+4])]\")\n",
    "    at_matches = mol.GetSubstructMatches(pattern)\n",
    "    at_matches_list = [y[0] for y in at_matches]\n",
    "    if len(at_matches_list) > 0:\n",
    "        for at_idx in at_matches_list:\n",
    "            atom = mol.GetAtomWithIdx(at_idx)\n",
    "            chg = atom.GetFormalCharge()\n",
    "            hcount = atom.GetTotalNumHs()\n",
    "            \n",
    "            #Skip adjustment for tetracoordinated boron\n",
    "            if atom.GetAtomicNum() == 5 and atom.GetDegree() == 4: #ADD COMMENT\n",
    "                continue  # Just bypass the problematic atom\n",
    "\n",
    "            atom.SetFormalCharge(0)\n",
    "            atom.SetNumExplicitHs(hcount - chg)\n",
    "            atom.UpdatePropertyCache()\n",
    "    return mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aromatize_smile(mol):\n",
    "    \"\"\"\n",
    "    This function dekekulize an input Mol object and return the aromatic form of isomeric SMILES. \n",
    "    \"\"\"\n",
    "    Chem.Kekulize(mol)\n",
    "    Chem.SanitizeMol(mol, Chem.SanitizeFlags.SANITIZE_ALL)\n",
    "    aromatic_smiles = Chem.MolToSmiles(mol, isomericSmiles = True)\n",
    "    return aromatic_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_smi = []\n",
    "\n",
    "#Update dataset with neutralized, aromatic SMILES\n",
    "for smi in pre9_hits['PUBCHEM_EXT_DATASOURCE_SMILES']: \n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    mol_neu = neutralize_atoms(mol)\n",
    "    smi_arom = aromatize_smile(mol_neu)\n",
    "    updated_smi.append(smi_arom)\n",
    "    \n",
    "#update the smiles in this df\n",
    "pre9_hits['PUBCHEM_EXT_DATASOURCE_SMILES'] = updated_smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_smi = []\n",
    "\n",
    "#Update dataset with neutralized, aromatic SMILES\n",
    "for smi in pre9_inactives['PUBCHEM_EXT_DATASOURCE_SMILES']: \n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    mol_neu = neutralize_atoms(mol)\n",
    "    smi_arom = aromatize_smile(mol_neu)\n",
    "    updated_smi.append(smi_arom)\n",
    "\n",
    "#update the smiles in this df\n",
    "pre9_inactives['PUBCHEM_EXT_DATASOURCE_SMILES'] = updated_smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save\n",
    "pre9_hits.to_csv(f'{data_folder}/before_finished/step_9_10/post10_hits.csv', index=False)\n",
    "pre9_inactives.to_csv(f'{data_folder}/before_finished/step_9_10/post10_inactives.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post 9+10: Update InChI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it important to now update InChI in our datasets, for 2 reasons:\n",
    "\n",
    "(1) Some mixture compounds have been modified (removal of small inorganic or organic molecules) in SMILES representation but not InChIs.\n",
    "\n",
    "(2) The SMILES representations have been neutralized and aromatized, but not InChIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the smiles columns to txt\n",
    "pre9_hits['PUBCHEM_EXT_DATASOURCE_SMILES'].to_csv(f'{data_folder}/before_finished/step_9_10/smiles_hits.txt', index=False, header=False)\n",
    "pre9_inactives['PUBCHEM_EXT_DATASOURCE_SMILES'].to_csv(f'{data_folder}/before_finished/step_9_10/smiles_inactives.txt', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Submit the smiles files to PubChem Identifier Exchange Service: \n",
    "    Input IDs: \"SMILES\"\n",
    "    Operator type: \"same CID\" \n",
    "    Output IDs: \"InChI\"\n",
    "    Output method: \"Two column file showing each input output-correspondence\"\n",
    "    Compression: \"No compression\"\n",
    "InChI list should be saved into \"step_9_10\" folder, named as \"inchi_hits.txt\" and \"inchi_inactives\" \n",
    "\"\"\"\n",
    "#Import the converted InChIs\n",
    "cleaned_inchi_hits = pd.read_csv(f'{data_folder}/before_finished/step_9_10/inchi_hits.txt', sep='\\t', header=None)\n",
    "cleaned_inchi_inactives = pd.read_csv(f'{data_folder}/before_finished/step_9_10/inchi_inactives.txt', sep='\\t', header=None)\n",
    "\n",
    "#a dictionary of smiles and corresponding inchi in cleaned_inchi_hits\n",
    "hits_smi_inchi_dict = dict(zip(cleaned_inchi_hits[0], cleaned_inchi_hits[1]))\n",
    "inactives_smi_inchi_dict = dict(zip(cleaned_inchi_inactives[0], cleaned_inchi_inactives[1]))\n",
    "                             \n",
    "#update the pre9_hits by matching the smiles with keys and replace inchi with values:\n",
    "pre9_hits['InChI'] = pre9_hits['PUBCHEM_EXT_DATASOURCE_SMILES'].map(hits_smi_inchi_dict) \n",
    "pre9_inactives['InChI'] = pre9_inactives['PUBCHEM_EXT_DATASOURCE_SMILES'].map(inactives_smi_inchi_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export: \n",
    "pre9_hits.to_csv(f'{data_folder}/before_finished/step_9_10/post10_hits.csv', index=False)\n",
    "pre9_inactives.to_csv(f'{data_folder}/before_finished/step_9_10/post10_inactives.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. PAIN filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1. Frequency of hits (FoH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency of Hits is a complex concept that requires a merticulous approach. In general, the rule is if a compound was tested active in multiple assays, it is likely to be a promiscuous compound. \n",
    "1. For each compounds, retrieve the information on its tested assays\n",
    "2. For each of the assay tested, retrieve the sequence of the protein target. \n",
    "3. Given all sequence of the protein tested, do a multiple sequence alignment to find the percentage Percent Identity (similarty) between these proteins. If an assay has high percentage to other targets, then these assays contribute less to promiscuousity of the compound. \n",
    "4. Use the percentage identity as a weight: \n",
    "w = 1 - %SI/100\n",
    "Calculate the frequency of hits for each compound:\n",
    "FoH = wACC/TAC\n",
    "wACC is the weighed total number of assay tested where the compounds were identified acitives. TAC is the total number of assays tested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre11_hits = pd.read_csv(f'{data_folder}/before_finished/step_9_10/post10_hits.csv', sep=',', header=0)\n",
    "pre11_inactives = pd.read_csv(f'{data_folder}/before_finished/step_9_10/post10_inactives.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new step folder:\n",
    "if not os.path.exists(f'{data_folder}/before_finished/step_11/11_1'):\n",
    "    os.makedirs(f'{data_folder}/before_finished/step_11/11_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.1. PubChem testing information for each compound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part illustrates how to retrieve the information of how each compound was tested from the PubChem database. Bulk data retrieval from the ftp server is used to get the information of every bioassay in PubChem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://ftp.ncbi.nlm.nih.gov/pubchem/Bioassay/Extras/bioassays.tsv.gz' #this FTP file records the summary data of all available AIDs in PubChem\n",
    "\n",
    "local_save_dir = 'H:\\coding\\HiChem\\curation\\pubchem_sum'\n",
    "local_save_path = os.path.join(local_save_dir, 'bioassays.tsv.gz')\n",
    "\n",
    "if not os.path.exists(local_save_dir):\n",
    "    os.makedirs(local_save_dir)\n",
    "r = requests.get(url, stream=True)\n",
    "\n",
    "with open(local_save_path, 'wb') as f:\n",
    "    for chunk in r.iter_content(chunk_size=8192):\n",
    "        f.write(chunk)\n",
    "print('Downloaded to %s' % local_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'pubchem_sum/bioassays.tsv.gz'\n",
    "\n",
    "# Read the TSV file\n",
    "all_bioassay = pd.read_csv(path, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AID</th>\n",
       "      <th>BioAssay Name</th>\n",
       "      <th>Deposit Date</th>\n",
       "      <th>Modify Date</th>\n",
       "      <th>Source Name</th>\n",
       "      <th>Source ID</th>\n",
       "      <th>Substance Type</th>\n",
       "      <th>Outcome Type</th>\n",
       "      <th>Project Category</th>\n",
       "      <th>BioAssay Group</th>\n",
       "      <th>BioAssay Types</th>\n",
       "      <th>Protein Accessions</th>\n",
       "      <th>UniProts IDs</th>\n",
       "      <th>Gene IDs</th>\n",
       "      <th>Target TaxIDs</th>\n",
       "      <th>Taxonomy IDs</th>\n",
       "      <th>Number of Tested SIDs</th>\n",
       "      <th>Number of Active SIDs</th>\n",
       "      <th>Number of Tested CIDs</th>\n",
       "      <th>Number of Active CIDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NCI human tumor cell line growth inhibition as...</td>\n",
       "      <td>20040815</td>\n",
       "      <td>20231014</td>\n",
       "      <td>DTP/NCI</td>\n",
       "      <td>NCI human tumor cell line growth inhibition as...</td>\n",
       "      <td>small-molecule</td>\n",
       "      <td>Confirmatory</td>\n",
       "      <td>Other</td>\n",
       "      <td>NCI-60_DOSERESP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55004</td>\n",
       "      <td>3280</td>\n",
       "      <td>52994</td>\n",
       "      <td>3057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>NCI human tumor cell line growth inhibition as...</td>\n",
       "      <td>20040815</td>\n",
       "      <td>20231014</td>\n",
       "      <td>DTP/NCI</td>\n",
       "      <td>NCI human tumor cell line growth inhibition as...</td>\n",
       "      <td>small-molecule</td>\n",
       "      <td>Confirmatory</td>\n",
       "      <td>Other</td>\n",
       "      <td>NCI-60_DOSERESP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51204</td>\n",
       "      <td>2596</td>\n",
       "      <td>49337</td>\n",
       "      <td>2449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NCI human tumor cell line growth inhibition as...</td>\n",
       "      <td>20040815</td>\n",
       "      <td>20231014</td>\n",
       "      <td>DTP/NCI</td>\n",
       "      <td>NCI human tumor cell line growth inhibition as...</td>\n",
       "      <td>small-molecule</td>\n",
       "      <td>Confirmatory</td>\n",
       "      <td>Other</td>\n",
       "      <td>NCI-60_DOSERESP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53832</td>\n",
       "      <td>2486</td>\n",
       "      <td>51804</td>\n",
       "      <td>2301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>NCI human tumor cell line growth inhibition as...</td>\n",
       "      <td>20040815</td>\n",
       "      <td>20231014</td>\n",
       "      <td>DTP/NCI</td>\n",
       "      <td>NCI human tumor cell line growth inhibition as...</td>\n",
       "      <td>small-molecule</td>\n",
       "      <td>Confirmatory</td>\n",
       "      <td>Other</td>\n",
       "      <td>NCI-60_DOSERESP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53828</td>\n",
       "      <td>4275</td>\n",
       "      <td>51804</td>\n",
       "      <td>4041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>NCI human tumor cell line growth inhibition as...</td>\n",
       "      <td>20040815</td>\n",
       "      <td>20231014</td>\n",
       "      <td>DTP/NCI</td>\n",
       "      <td>NCI human tumor cell line growth inhibition as...</td>\n",
       "      <td>small-molecule</td>\n",
       "      <td>Confirmatory</td>\n",
       "      <td>Other</td>\n",
       "      <td>NCI-60_DOSERESP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53744</td>\n",
       "      <td>3125</td>\n",
       "      <td>51771</td>\n",
       "      <td>2948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AID                                      BioAssay Name  Deposit Date  \\\n",
       "0    1  NCI human tumor cell line growth inhibition as...      20040815   \n",
       "1    3  NCI human tumor cell line growth inhibition as...      20040815   \n",
       "2    5  NCI human tumor cell line growth inhibition as...      20040815   \n",
       "3    7  NCI human tumor cell line growth inhibition as...      20040815   \n",
       "4    9  NCI human tumor cell line growth inhibition as...      20040815   \n",
       "\n",
       "   Modify Date Source Name                                          Source ID  \\\n",
       "0     20231014     DTP/NCI  NCI human tumor cell line growth inhibition as...   \n",
       "1     20231014     DTP/NCI  NCI human tumor cell line growth inhibition as...   \n",
       "2     20231014     DTP/NCI  NCI human tumor cell line growth inhibition as...   \n",
       "3     20231014     DTP/NCI  NCI human tumor cell line growth inhibition as...   \n",
       "4     20231014     DTP/NCI  NCI human tumor cell line growth inhibition as...   \n",
       "\n",
       "   Substance Type  Outcome Type Project Category   BioAssay Group  \\\n",
       "0  small-molecule  Confirmatory            Other  NCI-60_DOSERESP   \n",
       "1  small-molecule  Confirmatory            Other  NCI-60_DOSERESP   \n",
       "2  small-molecule  Confirmatory            Other  NCI-60_DOSERESP   \n",
       "3  small-molecule  Confirmatory            Other  NCI-60_DOSERESP   \n",
       "4  small-molecule  Confirmatory            Other  NCI-60_DOSERESP   \n",
       "\n",
       "  BioAssay Types Protein Accessions UniProts IDs Gene IDs  Target TaxIDs  \\\n",
       "0            NaN                NaN          NaN      NaN            NaN   \n",
       "1            NaN                NaN          NaN      NaN            NaN   \n",
       "2            NaN                NaN          NaN      NaN            NaN   \n",
       "3            NaN                NaN          NaN      NaN            NaN   \n",
       "4            NaN                NaN          NaN      NaN            NaN   \n",
       "\n",
       "  Taxonomy IDs  Number of Tested SIDs  Number of Active SIDs  \\\n",
       "0          NaN                  55004                   3280   \n",
       "1          NaN                  51204                   2596   \n",
       "2          NaN                  53832                   2486   \n",
       "3          NaN                  53828                   4275   \n",
       "4          NaN                  53744                   3125   \n",
       "\n",
       "   Number of Tested CIDs  Number of Active CIDs  \n",
       "0                  52994                   3057  \n",
       "1                  49337                   2449  \n",
       "2                  51804                   2301  \n",
       "3                  51804                   4041  \n",
       "4                  51771                   2948  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bioassay.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.2 Retrieving protein sequences for assays tested:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the testing information for each compound is retrieved from the PugREST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache to store the number of compounds tested per AID to avoid redundant call. \n",
    "num_compounds_tested_cache = {}\n",
    "\n",
    "def get_num_compounds_tested(aid, all_bioassay=all_bioassay):\n",
    "    \"\"\"\n",
    "    This function retrieves the information of how many compounds were tested in a given assay (by AID).\n",
    "    \"\"\"\n",
    "    if aid in num_compounds_tested_cache:\n",
    "        return num_compounds_tested_cache[aid]\n",
    "    else: \n",
    "        #return the 'Number of Tested CIDs' column value at the row where the 'AID' column is equal to aid in the all_bioassay dataframe\n",
    "        num_compounds_tested = all_bioassay[all_bioassay['AID'] == aid]['Number of Tested CIDs'].values[0]\n",
    "    return num_compounds_tested\n",
    "\n",
    "def get_assay_data(cid):\n",
    "    \"\"\"\n",
    "    Return a dictionary of all targets that a given compound (by CID) was tested on in PubChem \n",
    "    and the activity values of the compound. \n",
    "    \"\"\"\n",
    "    url = f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/{cid}/assaysummary/JSON\" #PUG-REST compound summary by CID\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    target_activity = {}\n",
    "\n",
    "    if 'Table' in data and 'Row' in data['Table']:\n",
    "        for row in data['Table']['Row']:\n",
    "            cells = row['Cell']\n",
    "            aid = int(cells[0])  # Extracting the AID from the first cell\n",
    "\n",
    "            # Proceed only if the assay is a screening assay\n",
    "            if cells[10] == 'Screening':\n",
    "\n",
    "                # Proceed only if more than 10,000 compounds were tested\n",
    "                num_compounds_tested = get_num_compounds_tested(aid)\n",
    "                if num_compounds_tested > 10000:\n",
    "                    target_gi = cells[5] # Retrieve the protein target's GI\n",
    "                    activity_outcome = cells[4].lower()\n",
    "\n",
    "                    if target_gi not in target_activity:\n",
    "                        target_activity[target_gi] = activity_outcome == 'active'\n",
    "                    elif activity_outcome == 'active':\n",
    "                        target_activity[target_gi] = True # If a compound was tested multiple times on the same protein, priotize \"active\" outcome.\n",
    "            \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    return (cid, target_activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing CIDs: 100%|██████████| 87/87 [00:27<00:00,  3.19it/s]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "cids_list = pre11_hits['PUBCHEM_CID'].tolist()\n",
    "\n",
    "def execute_with_multiprocessing(cids_list):\n",
    "    \"\"\"\n",
    "    For a given list of CIDs, return a dictionary of dictionaries \n",
    "    of protein targets these compounds were tested on and the activity outcomes\n",
    "    Input: \n",
    "        [list of CIDs]\n",
    "    Output: \n",
    "        Dictionary of testing information for all CIDs, such as:\n",
    "        {CID1:{target1:activity1, target3:activity3, ...},{CID2:{target2:activity2, target4:activity4, ...}, ...}}\n",
    "    \"\"\"\n",
    "    results_dict = {}\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        # Prepare futures for all CIDs\n",
    "        futures = [executor.submit(get_assay_data, cid) for cid in cids_list]\n",
    "        \n",
    "        # Process futures as they complete\n",
    "        for future in tqdm(as_completed(futures), total=len(cids_list), desc=\"Processing CIDs\"):\n",
    "            try:\n",
    "                cid, target_activity = future.result()\n",
    "                results_dict[cid] = target_activity\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing CID: {e}\")\n",
    "    return results_dict\n",
    "\n",
    "results_dict = execute_with_multiprocessing(cids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export results_dict\n",
    "with open(f'{data_folder}/before_finished/step_11/11_1/results_dict.json', 'w') as f:\n",
    "    json.dump(results_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import results_dict:\n",
    "with open(f'{data_folder}/before_finished/step_11/11_1/results_dict.json', 'r') as f:\n",
    "    results_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the list of all keys of the values in the dictionary:\n",
    "protein_ids = []\n",
    "for value in results_dict.values():\n",
    "    protein_ids.extend(value.keys())\n",
    "\n",
    "#clean the list\n",
    "protein_ids = list(set(protein_ids))\n",
    "protein_ids = [id for id in protein_ids if id != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['90111653', '291463269', '13699818', '30219', '47496637', '2853980', '4505445', '998701', '15646160', '124486680', '4503155', '118341367', '2358024', '21264324', '38349113', '116907', '23505220', '119579215', '134244587', '119580345', '4503385', '115529463', '10835013', '70832125', '46577642', '74315350', '14790033', '63102437', '5174513', '119603173', '2501205', '28373962', '262118306', '190938', '6016094', '4885057', '56417702', '21955158', '40254439', '111305821', '6274552', '7657550', '15645703', '32425330', '223468676', '4507793', '21361095', '115347926', '730163', '16878311', '156416009', '4826706', '32307126', '231632', '257380', '56202836', '155969707', '6912644', '23893623', '12830367', '171229', '47132585', '89348172', '56790945', '62868213', '78486550', '5454102', '216548193', '13325293', '4758204', '73586699', '73745819', '90652859', '52426748', '4502331', '166202459', '124487323', '89993689', '67463988', '15929025', '6680530', '4758878', '341916350', '13236497', '499328', '5730106', '15610402', '20070193', '4758484', '378544807', '134304838', '218891639', '881546', '510901', '5453722', '994798', '1302091', '48146199', '224494019', '167013344', '62203298', '10092597', '9955963', '1927', '22538455', '6166485', '27753985', '4502495', '16130723', '2507196', '7669492', '19860819', '2578455', '148378801', '47132611', '83779224', '86301151', '15610601', '7108463', '7706135', '28373018', '2702319', '4505209', '1246761', '10567816', '7706645', '433552101', '7381449', '1519312078', '168184763', '119607129', '54112388', '5032039', '216409728', '4507615', '4502003', '19923198', '109637798', '125541954', '47678551', '48145933', '4506113', '14389423', '4504843', '493539358', '48255881', '4505447', '224028257', '398366139', '312275222', '1111959238', '6978787', '45269145', '55976631', '20072248', '21595511', '1572493', '89191863', '42741659', '13177715', '1781172', '1762973', '9937384', '5016090', '487738', '113121', '48428097', '17391426', '68476498', '23943882', '4503351', '23110962', '55662034', '4507681', '83318444', '4757950', '116292172', '27807367', '21595776', '38027923', '285809906', '6679827', '54112432', '351542238', '74752344', '4506537', '124376142', '55960760', '124263658', '1628587', '115430235', '40807040', '32479527', '11094021', '31563518', '27368096', '81899072', '780303193', '68989256', '11093520', '147728', '7582271', '63477962', '76364066', '339641', '154146191', '1709543', '37589898', '301171662', '11528014', '270133071', '68565074', '285814664', '4503907', '59036749', '29788785', '76496497', '15675770', '4506243', '15610945', '4506055', '16130726', '1679362728', '31542303', '62740231', '55958172', '10190672', '10864009', '21359873', '42794767', '14149746', '15680217', '88501734', '225543099', '32400299', '216548487', '55584151', '195969650', '1937369734', '223459640', '160877737', '187952397', '187960042', '118764400', '112822', '38174238', '613504304', '119607128', '68474550', '9629363', '8574038', '2935630', '130375', '1237937630', '486173', '6831552', '166209887', '62362414', '34330186', '116734717', '71987181', '41872583', '83627717', '49574532', '4581413', '31881630', '597517618', '4826834', '1708272', '119622516', '37622910', '2393947', '148539876', '34577122', '20336315', '16306916', '56786138', '296080766', '74355113', '24119166', '15609874', '160707929', '929524245', '1655766739', '4503383', '6009644', '10835145', '4507593', '126642418', '46909587', '2498404', '119579178', '6708281', '4504343', '1782953264', '126698238', '46367787', '121945198', '6755076', '60391226', '1166512', '75495260', '7108336', '139472804', '15607504', '194068499', '218931251', '12803275', '296434520', '6325022', '28949057', '342179211', '21361340', '4502169', '73747889', '21315078', '1654220559', '17507875', '134142337', '3183518', '9629361', '597517265', '153217451', '116077694', '156104889', '21327705', '13027636', '116076351', '83758679', '124809506', '15927174', '62201602', '83699673', '160333370', '7657508', '90421313', '21392848', '37187860', '38788193', '38258652', '21464101', '5174547', '12381848', '11141885', '11275980', '67463989', '534286618', '13128862', '4503219', '62526033', '149631', '41872631', '9966877', '13399304', '13124881', '116516899', '528078313', '55956923', '110611243', '88702791', '85666113', '21489979', '1797100823', '124809271', '1575471', '86990435', '14719829', '151101270', '536029', '148745659', '32400300', '49168602', '120997', '82503229', '22035600', '253722402', '78070770', '194306653', '20336229', '117940060', '53832009', '6323930', '180352', '317373446', '47123300', '68565218', '109633019', '4757840', '222080095', '735367775', '27597073', '23893668', '5729858', '223460826', '74356043', '4507791', '2182777540', '14790119', '302699239', '15610807', '139424501', '1730321', '4503779', '16130724', '115496662', '578162', '25148072', '16130689', '32307152', '13272532', '16128424', '23510348', '164058', '219518789', '120538355', '74734243', '67191027', '12644416', '119508433', '71746704', '38156699']\n",
      "421\n"
     ]
    }
   ],
   "source": [
    "print(protein_ids)\n",
    "print(f'Require multiple sequencing alignment for {len(protein_ids)} proteins.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we retrieve all the FASTA sequences of proteins tested for all of our compounds with Biopython API to Entrez of NCBI. The FASTA sequence is saved as \"sequences.fasta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always tell NCBI who you are\n",
    "Entrez.email = \"hdong26@amherst.edu\"\n",
    "\n",
    "# The filename where you want to save the sequences\n",
    "output_filename = f'{data_folder}/before_finished/step_11/11_1/sequences.fasta'\n",
    "\n",
    "# Open a file to write the sequences\n",
    "with open(output_filename, \"w\") as output_file:\n",
    "    for id in protein_ids:\n",
    "        try:\n",
    "            # Fetch the sequence from NCBI\n",
    "            handle = Entrez.efetch(db=\"protein\", id=id, rettype=\"fasta\", retmode=\"text\")\n",
    "            sequence_data = handle.read()\n",
    "            handle.close()\n",
    "            \n",
    "            # Write the sequence data to the file\n",
    "            output_file.write(sequence_data)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while fetching {id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the FASTA sequence, we also need to retrieve the list of protein names, since these are different from the protein GIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_protein_names(file_path):\n",
    "    protein_names = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('>'):\n",
    "                # Split the line at spaces and take the first item\n",
    "                parts = line.split(' ')\n",
    "                protein_name = parts[0]\n",
    "                # Remove the leading '>' character\n",
    "                protein_name = protein_name[1:]\n",
    "                protein_names.append(protein_name)\n",
    "    return protein_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NP_418280.4', 'NP_001167549.1', 'NP_000762.2', 'CAA41086.1', 'CAG29341.1', 'AAC83551.1', 'NP_000900.1', 'AAB34216.1', 'NP_208344.1', 'NP_032426.2', 'NP_001903.1', 'AAI27629.1', 'AAB69001.1', 'NP_612200.1', 'AAR18078.1', 'sp|P21964.2|COMT_HUMAN', 'CAD52000.1', 'EAW58811.1', 'NP_004221.3', 'EAW59941.1', 'NP_000786.1', 'NP_002733.2', 'NP_001428.1', 'EAN77629.1', 'sp|P61105.1|RAB2A_CANLF', 'NP_061197.4', 'AAH10859.1', 'AAH95408.1', 'NP_005893.1', 'EAW82767.1', 'sp|Q15084.1|PDIA6_HUMAN', 'pdb|1N8E|E', 'NP_660205.3', 'AAA36557.1', 'sp|O43603.1|GALR2_HUMAN', 'NP_005152.1', 'CAI19360.1', 'NP_663745.1', 'NP_001421.2', 'AAI21795.1', 'NP_009330.1', 'NP_055369.1', 'NP_207880.1', 'AAH19268.2', 'NP_068810.3', 'NP_003339.1', 'NP_004447.2', 'CAL20848.1', 'sp|P40261.1|NNMT_HUMAN', 'AAH17351.1', 'NP_002919.3', 'NP_004942.1', 'NP_858045.1', 'sp|P10415.2|BCL2_HUMAN', 'AAB23646.1', 'CAI19851.1', 'NP_004960.2', 'NP_036559.1', 'CAD53427.1', 'CAC29064.1', 'AAA34498.1', 'NP_002727.2', 'ABD72211.1', 'NP_001008709.1', 'NP_001017408.1', 'NP_598230.2', 'NP_006333.1', 'NP_001136020.1', 'AAH04460.1', 'NP_004408.1', 'AAI02981.1', 'AAZ82016.1', 'NP_008837.1', 'NP_000732.2', 'NP_000697.1', 'ABY84639.1', 'NP_001074551.1', 'NP_002383.2', 'pdb|1ZHH|A', 'AAH14970.1', 'NP_032451.1', 'NP_000428.2', 'AAD14062.3', 'NP_076917.1', 'CAA54142.1', 'NP_006555.1', 'NP_217783.1', 'NP_004950.2', 'NP_004823.1', 'CCE37082.1', 'NP_004827.4', 'YP_002440506.1', 'AAA73923.1', 'CAA80661.1', 'NP_006321.1', 'CAA56931.1', 'CAA96025.1', 'CAG33322.1', 'NP_003833.4', 'pdb|2VM6|A', 'AAH93020.1', 'NP_065394.1', 'NP_005680.1', 'CAA46986.1', 'NP_003734.3', 'AAF04852.1', 'NP_766400.1', 'NP_001725.1', 'NP_417296.1', 'sp|P53779.2|MK10_HUMAN', 'NP_002037.2', 'sp|P54760.2|EPHB4_HUMAN', 'CAA75532.1', 'YP_001253342.1', 'NP_037457.3', 'ABC47431.1', 'ABC94590.1', 'NP_217982.1', 'AAC50179.2', 'NP_057685.1', 'NP_783699.1', 'AAC03365.1', 'NP_002418.1', 'CAA62974.1', 'NP_066268.1', 'NP_057231.1', 'pdb|1VRU|A', 'AAF61483.1', 'NP_079406.4', 'ZP_02619427.1', 'EAW86723.1', 'NP_001005738.1', 'NP_005604.1', 'BAH02301.1', 'NP_003271.1', 'NP_001612.1', 'NP_001745.2', 'NP_602296.2', 'ABN45876.1', 'CAG30396.1', 'CAG33189.1', 'NP_000302.1', 'NP_058021.1', 'NP_002231.1', 'WP_006493245.1', 'NP_001001431.1', 'NP_000901.1', 'NP_001138884.1', 'NP_010497.3', 'ADQ57959.1', 'XP_711691.2', 'NP_036923.1', 'NP_987096.1', 'sp|Q9XUB2.1|MEX5_CAEEL', 'AAH26347.1', 'AAH32261.1', 'AAB09055.1', 'NP_387512.3', 'NP_000918.2', 'AAH03636.1', 'CAB06100.1', 'AAC50996.1', 'AAG02439.1', 'NP_000466.2', 'AAA62473.1', 'sp|P08482.1|ACM1_RAT', 'sp|Q8TDV0.1|GP151_HUMAN', 'AAH18648.1', 'XP_717710.1', 'NP_112168.1', 'NP_001370.1', 'NP_004070.3', 'CAH72619.1', 'NP_003292.1', 'AAI08696.1', 'NP_004349.1', 'NP_001013728.2', 'NP_777239.1', 'AAH32638.1', 'NP_006828.2', 'DAA06693.1', 'NP_032062.1', 'NP_005253.3', 'NP_001234925.1', 'sp|Q9BTU6.1|P4K2A_HUMAN', 'NP_003812.1', 'AAI32679.1', 'CAI12638.1', 'ABM97548.1', 'AAB17381.1', 'NP_001041666.1', 'AAH65243.1', 'NP_000209.2', 'AAG29538.1', 'NP_852610.1', 'AAN87168.1', 'sp|Q8C6L5.1|CGAS_MOUSE', 'WP_045552426.1', 'NP_004283.2', 'AAG29340.1', 'AAA24585.1', 'AAF64255.1', 'NP_000902.3', 'YP_325663.1', 'AAC63054.1', 'NP_005339.3', 'sp|P24666.3|PPAC_HUMAN', 'AAH00750.4', 'NP_036543.4', 'NP_041724.2', 'NP_001161829.1', 'sp|Q92560.2|BAP1_HUMAN', 'DAA10558.1', 'NP_003605.1', 'AAW83741.1', 'NP_821133.1', 'NP_001029027.1', 'NP_269944.1', 'NP_002810.1', 'NP_218326.1', 'NP_002721.1', 'NP_417299.1', 'sp|Q9HD36.3|B2L10_HUMAN', 'NP_057090.2', 'AAH94064.1', 'CAI16307.1', 'NP_065688.1', 'NP_067021.1', 'NP_005021.2', 'NP_976226.1', 'NP_066285.1', 'AAH14460.1', 'NP_000623.2', 'NP_001139412.1', 'BAC78637.1', 'NP_036519.2', 'sp|P04062.3|GBA1_HUMAN', 'ACG60652.1', 'NP_579856.2', 'AAI36467.1', 'pdb|2QQI|A', 'AAI36532.1', 'NP_000441.2', 'AAI28575.1', 'sp|P28566.1|5HT1E_HUMAN', 'AAH60765.1', 'sp|P35398.2|RORA_HUMAN', 'EAW86722.1', 'XP_718648.1', 'NP_057856.1', 'CAB53579.5', 'AAC05178.1', 'sp|P11086.1|PNMT_HUMAN', 'NP_001341533.1', 'CAA81943.1', 'sp|O75388.1|GPR32_HUMAN', 'sp|Q9HBX9.2|RXFP1_HUMAN', 'NP_005148.2', 'NP_899192.1', 'NP_000469.3', 'NP_001024547.1', 'NP_004841.2', 'NP_031943.3', 'NP_063937.2', 'CAB40158.1', 'NP_000947.2', 'CDO16711.1', 'NP_004986.1', 'sp|P50135.1|HNMT_HUMAN', 'EAX02111.1', 'NP_000729.2', 'AAC51766.1', 'NP_001610.2', 'NP_003989.2', 'NP_619527.1', 'AAH09524.1', 'NP_000610.2', 'NP_001171675.1', 'AAI03867.1', 'NP_006597.2', 'NP_217253.1', 'NP_031863.3', 'NP_776412.2', 'NP_001357589.1', 'NP_000785.1', 'BAA85004.1', 'NP_000567.1', 'NP_003801.1', 'YP_001085402.1', 'NP_997461.1', 'sp|Q14353.1|GAMT_HUMAN', 'EAW58774.1', 'AAF25870.1', 'NP_003813.1', 'NP_848757.5', 'YP_001087135.1', 'NP_002559.2', 'sp|Q05DJ8|Q05DJ8_HUMAN', 'NP_035230.1', 'sp|P31749.2|AKT1_HUMAN', 'AAC50351.1', 'sp|O86157|O86157_CAMJE', 'NP_036257.1', 'YP_001129431.1', 'NP_214877.1', 'BAG55070.1', 'NP_631918.3', 'AAH02453.1', 'sp|P42858.2|HD_HUMAN', 'NP_015090.1', 'pdb|1O1W|A', 'sp|P86926.1|RLGM1_TRYBB', 'NP_002084.2', 'NP_003896.1', 'NP_003174.3', 'AAH30775.1', 'NP_598837.3', 'NP_492143.1', 'NP_004987.2', 'sp|Q05397.2|FAK1_HUMAN', 'NP_057851.1', 'CDO16358.1', 'AAI51237.1', 'ABJ55414.1', 'NP_004520.2', 'NP_644806.1', 'NP_001391.2', 'ABJ54071.1', 'BAE54513.1', 'XP_001348591.1', 'NP_374707.1', 'AAH92442.1', 'ABC40742.1', 'NP_038866.2', 'NP_055063.1', 'NP_000483.3', 'NP_652928.1', 'NP_004358.2', 'NP_005217.2', 'sp|Q9NXA8.2|SIR5_HUMAN', 'NP_036611.2', 'NP_005914.1', 'CAC24715.1', 'NP_068587.1', 'AAG33848.1', 'pdb|1ZHH|B', 'pdb|4KC3|B', 'NP_003874.2', 'NP_000760.1', 'NP_004818.2', 'AAA25265.1', 'NP_004095.4', 'NP_065132.1', 'NP_068594.1', 'NP_074036.1', 'YP_815859.1', 'NP_000256.4', 'NP_000515.2', 'NP_002522.2', 'NP_002384.2', 'NP_009905.3', 'NP_659558.1', 'NP_000015.2', 'XP_001348533.1', 'AAB09537.1', 'NP_001034556.1', 'NP_127497.1', 'NP_000354.4', 'CAA84846.1', 'AAI42682.1', 'BAC78638.1', 'CAG38796.1', 'sp|P08753.3|GNAI3_RAT', 'YP_401673.1', 'NP_004570.2', 'pdb|1ULL|B', 'AAI07736.1', 'NP_001123617.1', 'NP_056953.2', 'NP_000905.3', 'NP_066921.2', 'NP_014001.1', 'AAA51985.1', 'sp|P00748.3|FA12_HUMAN', 'AAH70052.1', 'sp|Q8N884.2|CGAS_HUMAN', 'NP_001035889.1', 'NP_004040.1', 'NP_001516.2', 'NP_000202.3', 'NP_001970.2', 'CAD53472.1', 'NP_006531.1', 'AAI36361.1', 'BAE44387.1', 'NP_003960.1', 'NP_057051.4', 'NP_004337.2', 'NP_004944.3', 'NP_218188.1', 'YP_001129466.1', 'AAC14371.1', 'NP_002020.1', 'NP_417297.1', 'NP_001069826.1', 'gi|578162', 'NP_741406.1', 'NP_417262.1', 'NP_000907.2', 'AAK17196.1', 'NP_414973.1', 'NP_057698.2', 'AAA30890.1', 'AAI43360.1', 'AAI29989.1', 'sp|Q9HAT2.1|SIAE_HUMAN', 'NP_000876.3', 'sp|Q14749.3|GNMT_HUMAN', 'NP_005903.2', 'XP_822407.1', 'NP_937802.1']\n"
     ]
    }
   ],
   "source": [
    "file_path = f'{data_folder}/before_finished/step_11/11_1/sequences.fasta'\n",
    "protein_names = extract_protein_names(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map protein IDs to protein names by index \n",
    "protein_id_to_name = {protein_ids[i]: protein_names[i] for i in range(len(protein_ids))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.3 Percent Sequence Identity by Multiple Sequence Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sequences.fasta file is submitted to https://www.ebi.ac.uk/jdispatcher/msa/clustalo for multiple sequencing alignment. The resulted table of percent sequence identity matrix is saved and imported for the calculation of FoH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Submit sequences.fasta to https://www.ebi.ac.uk/jdispatcher/msa/clustalo\n",
    "    Input sequence type: Protein\n",
    "    Output format: ClustalW with character counts\n",
    "Download the resulted Percent Identity Matrix file file and save as \"percent_identity_matrix.txt\"\n",
    "\"\"\"\n",
    "\n",
    "#import the identity matrix:\n",
    "protein_si = pd.read_csv(\n",
    "    f'{data_folder}/before_finished/step_11/11_1/percent_identity_matrix.txt',\n",
    "    delimiter='\\s+',\n",
    "    header=None,\n",
    "    skiprows=6 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the first column:\n",
    "protein_si = protein_si.drop(protein_si.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = protein_si[1].tolist()\n",
    "name = ['protein name'] + name\n",
    "protein_si.columns = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein name</th>\n",
       "      <th>NP_063937.2</th>\n",
       "      <th>NP_002084.2</th>\n",
       "      <th>NP_000302.1</th>\n",
       "      <th>NP_004447.2</th>\n",
       "      <th>NP_057856.1</th>\n",
       "      <th>NP_001123617.1</th>\n",
       "      <th>NP_001357589.1</th>\n",
       "      <th>NP_492143.1</th>\n",
       "      <th>NP_036543.4</th>\n",
       "      <th>...</th>\n",
       "      <th>NP_001136020.1</th>\n",
       "      <th>NP_001167549.1</th>\n",
       "      <th>EAW58811.1</th>\n",
       "      <th>NP_217253.1</th>\n",
       "      <th>EAW82767.1</th>\n",
       "      <th>NP_066921.2</th>\n",
       "      <th>AAA62473.1</th>\n",
       "      <th>NP_004944.3</th>\n",
       "      <th>NP_004283.2</th>\n",
       "      <th>NP_004095.4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NP_063937.2</td>\n",
       "      <td>100.00</td>\n",
       "      <td>76.85</td>\n",
       "      <td>15.69</td>\n",
       "      <td>13.91</td>\n",
       "      <td>15.68</td>\n",
       "      <td>8.22</td>\n",
       "      <td>14.77</td>\n",
       "      <td>10.42</td>\n",
       "      <td>14.56</td>\n",
       "      <td>...</td>\n",
       "      <td>6.94</td>\n",
       "      <td>8.09</td>\n",
       "      <td>6.87</td>\n",
       "      <td>10.00</td>\n",
       "      <td>12.07</td>\n",
       "      <td>7.69</td>\n",
       "      <td>7.95</td>\n",
       "      <td>5.45</td>\n",
       "      <td>7.89</td>\n",
       "      <td>12.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NP_002084.2</td>\n",
       "      <td>76.85</td>\n",
       "      <td>100.00</td>\n",
       "      <td>17.65</td>\n",
       "      <td>14.02</td>\n",
       "      <td>15.73</td>\n",
       "      <td>9.72</td>\n",
       "      <td>11.88</td>\n",
       "      <td>10.53</td>\n",
       "      <td>12.42</td>\n",
       "      <td>...</td>\n",
       "      <td>6.76</td>\n",
       "      <td>9.84</td>\n",
       "      <td>8.55</td>\n",
       "      <td>11.11</td>\n",
       "      <td>12.77</td>\n",
       "      <td>8.70</td>\n",
       "      <td>12.50</td>\n",
       "      <td>9.66</td>\n",
       "      <td>5.88</td>\n",
       "      <td>12.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NP_000302.1</td>\n",
       "      <td>15.69</td>\n",
       "      <td>17.65</td>\n",
       "      <td>100.00</td>\n",
       "      <td>11.11</td>\n",
       "      <td>16.82</td>\n",
       "      <td>17.20</td>\n",
       "      <td>5.98</td>\n",
       "      <td>12.15</td>\n",
       "      <td>11.86</td>\n",
       "      <td>...</td>\n",
       "      <td>5.97</td>\n",
       "      <td>5.06</td>\n",
       "      <td>5.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.53</td>\n",
       "      <td>14.39</td>\n",
       "      <td>8.79</td>\n",
       "      <td>8.11</td>\n",
       "      <td>16.67</td>\n",
       "      <td>13.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NP_004447.2</td>\n",
       "      <td>13.91</td>\n",
       "      <td>14.02</td>\n",
       "      <td>11.11</td>\n",
       "      <td>100.00</td>\n",
       "      <td>15.94</td>\n",
       "      <td>12.43</td>\n",
       "      <td>10.51</td>\n",
       "      <td>13.64</td>\n",
       "      <td>11.64</td>\n",
       "      <td>...</td>\n",
       "      <td>7.01</td>\n",
       "      <td>10.91</td>\n",
       "      <td>10.80</td>\n",
       "      <td>8.33</td>\n",
       "      <td>13.16</td>\n",
       "      <td>10.00</td>\n",
       "      <td>9.21</td>\n",
       "      <td>8.81</td>\n",
       "      <td>8.33</td>\n",
       "      <td>11.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NP_057856.1</td>\n",
       "      <td>15.68</td>\n",
       "      <td>15.73</td>\n",
       "      <td>16.82</td>\n",
       "      <td>15.94</td>\n",
       "      <td>100.00</td>\n",
       "      <td>11.92</td>\n",
       "      <td>9.65</td>\n",
       "      <td>10.75</td>\n",
       "      <td>11.50</td>\n",
       "      <td>...</td>\n",
       "      <td>13.68</td>\n",
       "      <td>12.62</td>\n",
       "      <td>10.80</td>\n",
       "      <td>12.00</td>\n",
       "      <td>16.16</td>\n",
       "      <td>9.52</td>\n",
       "      <td>13.41</td>\n",
       "      <td>8.50</td>\n",
       "      <td>8.33</td>\n",
       "      <td>12.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>NP_066921.2</td>\n",
       "      <td>7.69</td>\n",
       "      <td>8.70</td>\n",
       "      <td>14.39</td>\n",
       "      <td>10.00</td>\n",
       "      <td>9.52</td>\n",
       "      <td>10.78</td>\n",
       "      <td>12.85</td>\n",
       "      <td>14.43</td>\n",
       "      <td>10.61</td>\n",
       "      <td>...</td>\n",
       "      <td>18.18</td>\n",
       "      <td>19.10</td>\n",
       "      <td>17.38</td>\n",
       "      <td>20.27</td>\n",
       "      <td>19.38</td>\n",
       "      <td>100.00</td>\n",
       "      <td>16.21</td>\n",
       "      <td>16.93</td>\n",
       "      <td>15.37</td>\n",
       "      <td>19.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>AAA62473.1</td>\n",
       "      <td>7.95</td>\n",
       "      <td>12.50</td>\n",
       "      <td>8.79</td>\n",
       "      <td>9.21</td>\n",
       "      <td>13.41</td>\n",
       "      <td>9.85</td>\n",
       "      <td>9.09</td>\n",
       "      <td>4.63</td>\n",
       "      <td>9.52</td>\n",
       "      <td>...</td>\n",
       "      <td>9.04</td>\n",
       "      <td>10.83</td>\n",
       "      <td>12.28</td>\n",
       "      <td>12.62</td>\n",
       "      <td>16.04</td>\n",
       "      <td>16.21</td>\n",
       "      <td>100.00</td>\n",
       "      <td>16.28</td>\n",
       "      <td>14.60</td>\n",
       "      <td>20.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>NP_004944.3</td>\n",
       "      <td>5.45</td>\n",
       "      <td>9.66</td>\n",
       "      <td>8.11</td>\n",
       "      <td>8.81</td>\n",
       "      <td>8.50</td>\n",
       "      <td>13.70</td>\n",
       "      <td>9.68</td>\n",
       "      <td>9.43</td>\n",
       "      <td>11.03</td>\n",
       "      <td>...</td>\n",
       "      <td>13.10</td>\n",
       "      <td>17.65</td>\n",
       "      <td>17.04</td>\n",
       "      <td>14.77</td>\n",
       "      <td>12.78</td>\n",
       "      <td>16.93</td>\n",
       "      <td>16.28</td>\n",
       "      <td>100.00</td>\n",
       "      <td>17.60</td>\n",
       "      <td>21.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>NP_004283.2</td>\n",
       "      <td>7.89</td>\n",
       "      <td>5.88</td>\n",
       "      <td>16.67</td>\n",
       "      <td>8.33</td>\n",
       "      <td>8.33</td>\n",
       "      <td>8.77</td>\n",
       "      <td>9.20</td>\n",
       "      <td>9.38</td>\n",
       "      <td>3.80</td>\n",
       "      <td>...</td>\n",
       "      <td>14.75</td>\n",
       "      <td>16.67</td>\n",
       "      <td>15.56</td>\n",
       "      <td>11.46</td>\n",
       "      <td>15.98</td>\n",
       "      <td>15.37</td>\n",
       "      <td>14.60</td>\n",
       "      <td>17.60</td>\n",
       "      <td>100.00</td>\n",
       "      <td>25.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>NP_004095.4</td>\n",
       "      <td>12.64</td>\n",
       "      <td>12.05</td>\n",
       "      <td>13.33</td>\n",
       "      <td>11.81</td>\n",
       "      <td>12.50</td>\n",
       "      <td>12.37</td>\n",
       "      <td>11.76</td>\n",
       "      <td>11.83</td>\n",
       "      <td>10.00</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>16.61</td>\n",
       "      <td>16.40</td>\n",
       "      <td>18.23</td>\n",
       "      <td>19.02</td>\n",
       "      <td>19.26</td>\n",
       "      <td>20.41</td>\n",
       "      <td>21.53</td>\n",
       "      <td>25.11</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421 rows × 422 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    protein name  NP_063937.2  NP_002084.2  NP_000302.1  NP_004447.2  \\\n",
       "0    NP_063937.2       100.00        76.85        15.69        13.91   \n",
       "1    NP_002084.2        76.85       100.00        17.65        14.02   \n",
       "2    NP_000302.1        15.69        17.65       100.00        11.11   \n",
       "3    NP_004447.2        13.91        14.02        11.11       100.00   \n",
       "4    NP_057856.1        15.68        15.73        16.82        15.94   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "416  NP_066921.2         7.69         8.70        14.39        10.00   \n",
       "417   AAA62473.1         7.95        12.50         8.79         9.21   \n",
       "418  NP_004944.3         5.45         9.66         8.11         8.81   \n",
       "419  NP_004283.2         7.89         5.88        16.67         8.33   \n",
       "420  NP_004095.4        12.64        12.05        13.33        11.81   \n",
       "\n",
       "     NP_057856.1  NP_001123617.1  NP_001357589.1  NP_492143.1  NP_036543.4  \\\n",
       "0          15.68            8.22           14.77        10.42        14.56   \n",
       "1          15.73            9.72           11.88        10.53        12.42   \n",
       "2          16.82           17.20            5.98        12.15        11.86   \n",
       "3          15.94           12.43           10.51        13.64        11.64   \n",
       "4         100.00           11.92            9.65        10.75        11.50   \n",
       "..           ...             ...             ...          ...          ...   \n",
       "416         9.52           10.78           12.85        14.43        10.61   \n",
       "417        13.41            9.85            9.09         4.63         9.52   \n",
       "418         8.50           13.70            9.68         9.43        11.03   \n",
       "419         8.33            8.77            9.20         9.38         3.80   \n",
       "420        12.50           12.37           11.76        11.83        10.00   \n",
       "\n",
       "     ...  NP_001136020.1  NP_001167549.1  EAW58811.1  NP_217253.1  EAW82767.1  \\\n",
       "0    ...            6.94            8.09        6.87        10.00       12.07   \n",
       "1    ...            6.76            9.84        8.55        11.11       12.77   \n",
       "2    ...            5.97            5.06        5.06          NaN       10.53   \n",
       "3    ...            7.01           10.91       10.80         8.33       13.16   \n",
       "4    ...           13.68           12.62       10.80        12.00       16.16   \n",
       "..   ...             ...             ...         ...          ...         ...   \n",
       "416  ...           18.18           19.10       17.38        20.27       19.38   \n",
       "417  ...            9.04           10.83       12.28        12.62       16.04   \n",
       "418  ...           13.10           17.65       17.04        14.77       12.78   \n",
       "419  ...           14.75           16.67       15.56        11.46       15.98   \n",
       "420  ...           13.86           16.61       16.40        18.23       19.02   \n",
       "\n",
       "     NP_066921.2  AAA62473.1  NP_004944.3  NP_004283.2  NP_004095.4  \n",
       "0           7.69        7.95         5.45         7.89        12.64  \n",
       "1           8.70       12.50         9.66         5.88        12.05  \n",
       "2          14.39        8.79         8.11        16.67        13.33  \n",
       "3          10.00        9.21         8.81         8.33        11.81  \n",
       "4           9.52       13.41         8.50         8.33        12.50  \n",
       "..           ...         ...          ...          ...          ...  \n",
       "416       100.00       16.21        16.93        15.37        19.26  \n",
       "417        16.21      100.00        16.28        14.60        20.41  \n",
       "418        16.93       16.28       100.00        17.60        21.53  \n",
       "419        15.37       14.60        17.60       100.00        25.11  \n",
       "420        19.26       20.41        21.53        25.11       100.00  \n",
       "\n",
       "[421 rows x 422 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_si"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.4 Calculation of FoHs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, we have a dictionary of (cid: assays tested); (assay_tested:protein name), and percentage identity matrix with first columns as protein names. \n",
    "For each compound, we retrieve the list of all protein names tested on that compounds by matching between the two first dictionary. From this list, we retrieve the corresponding matrix of percentages identitiy of these proteins corresponding to these compounds and calculate the FoH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_si_dict = {}\n",
    "for name in protein_si['protein name']: \n",
    "    for other_name in protein_si['protein name']: \n",
    "        if other_name != name: \n",
    "            protein_si_dict[(name, other_name)] = protein_si.loc[protein_si['protein name'] == name, other_name].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:11<00:00,  7.79it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "foh_dict = {}\n",
    "\n",
    "for cid, targets in tqdm.tqdm(results_dict.items()):\n",
    "    active_weight_list = []\n",
    "    total_weight_list = []\n",
    "\n",
    "    for target_id, result in targets.items():\n",
    "        if target_id == '':\n",
    "            continue\n",
    "\n",
    "        protein_name = protein_id_to_name[target_id]\n",
    "        max_weight = 0\n",
    "\n",
    "        for other_id, other_result in targets.items():\n",
    "            if other_id != target_id and other_id != '':\n",
    "                other_protein_name = protein_id_to_name[other_id]\n",
    "                value = protein_si_dict[(protein_name, other_protein_name)]\n",
    "                max_weight = max(max_weight, value)\n",
    "\n",
    "        target_weight = 1 - max_weight / 100\n",
    "\n",
    "        if result:\n",
    "            active_weight_list.append(target_weight)\n",
    "        total_weight_list.append(target_weight)\n",
    "\n",
    "    if total_weight_list:\n",
    "        foh_score = sum(active_weight_list) / sum(total_weight_list)\n",
    "        foh_dict[cid] = foh_score\n",
    "    else: \n",
    "        foh_dict[cid] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export foh_dict\n",
    "with open(f'{data_folder}/before_finished/step_11/11_1/foh_dict.json', 'w') as f:\n",
    "    json.dump(foh_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For compounds with FoH larger than 0.26, we remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 compounds with FoH larger than 0.26\n"
     ]
    }
   ],
   "source": [
    "to_drop = []\n",
    "for cid, foh_score in foh_dict.items():\n",
    "    if foh_score > 0.26: \n",
    "        to_drop.append(cid)\n",
    "\n",
    "post_FoH_hits = pre11_hits[~pre11_hits['PUBCHEM_CID'].isin(to_drop)]\n",
    "print(f'Dropped {(len(to_drop))} compounds with FoH larger than 0.26')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save post_FoH_hits: \n",
    "post_FoH_hits.to_csv(f'{data_folder}/before_finished/step_11/11_1/post_FoH_hits.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre11_inactives.to_csv(f'{data_folder}/before_finished/step_11/11_1/post_FoH_inactives.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 Autofluoresence & Luceferase inhibition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finding false positive due to autofluorescence and luceferase inhibition, it is important to check if the particular assays use one of these technologies. Here, all three assays (AID626, AID1488, and AID1741) use fluorescence technologies, so it is optimal to remove compounds that are active in AIDs: 587, 588, 590, 591, 592, 593, 594"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "autofluorescence_aids = ['587', '588', '590', '591', '592', '593', '594']\n",
    "autofluorescence_cids = []\n",
    "col_list = ['PUBCHEM_CID', 'PUBCHEM_ACTIVITY_OUTCOME']\n",
    "\n",
    "count = 0\n",
    "for AID in autofluorescence_aids:\n",
    "    url = f'https://pubchem.ncbi.nlm.nih.gov/assay/pcget.cgi?query=download&record_type=datatable&actvty=all&response_type=save&aid={AID}'\n",
    "    autofluorescence_df = pd.read_csv(url, usecols=col_list)\n",
    "    #delete rows with nan values\n",
    "    autofluorescence_df = autofluorescence_df.dropna(subset=['PUBCHEM_CID', 'PUBCHEM_ACTIVITY_OUTCOME'])\n",
    "\n",
    "    #convert cids to int: \n",
    "    autofluorescence_df['PUBCHEM_CID'] = autofluorescence_df['PUBCHEM_CID'].astype(int)\n",
    "\n",
    "    #keep only rows said \"Active\"\n",
    "    autofluorescence_df = autofluorescence_df[autofluorescence_df['PUBCHEM_ACTIVITY_OUTCOME'] == 'Active']\n",
    "    autofluorescence_cids.extend(autofluorescence_df['PUBCHEM_CID'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates in the list:\n",
    "autofluorescence_cids = [item for item in set(autofluorescence_cids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 autofluorescence compounds\n"
     ]
    }
   ],
   "source": [
    "to_drop_hits = []\n",
    "for cid in post_FoH_hits: \n",
    "    if cid in autofluorescence_cids:\n",
    "        to_drop.append(cid)\n",
    "post_autofluorescence = post_FoH_hits[~post_FoH_hits['PUBCHEM_CID'].isin(to_drop_hits)]\n",
    "print(f'Dropped {(len(to_drop_hits))} autofluorescence compounds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUBCHEM_CID</th>\n",
       "      <th>PUBCHEM_EXT_DATASOURCE_SMILES</th>\n",
       "      <th>PUBCHEM_ACTIVITY_OUTCOME</th>\n",
       "      <th>InChI</th>\n",
       "      <th>Mol removed from mixture</th>\n",
       "      <th>Small inorganic molecule</th>\n",
       "      <th>Small organic molecule</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1263872</td>\n",
       "      <td>Cc1cc(N2CCN(c3nc(N4CCOCC4)nc4ccccc34)CC2)c2ccc...</td>\n",
       "      <td>Active</td>\n",
       "      <td>InChI=1S/C26H28N6O/c1-19-18-24(20-6-2-4-8-22(2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>655606</td>\n",
       "      <td>Cc1ccc2nc(NC3=NCN(CCN4CCOCC4)CN3)nc(C)c2c1</td>\n",
       "      <td>Active</td>\n",
       "      <td>InChI=1S/C19H27N7O/c1-14-3-4-17-16(11-14)15(2)...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3236651</td>\n",
       "      <td>C=CCSc1nnc2c(n1)OC(c1cccnc1)N(C(C)=O)c1ccccc1-2</td>\n",
       "      <td>Active</td>\n",
       "      <td>InChI=1S/C20H17N5O2S/c1-3-11-28-20-22-18-17(23...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6603423</td>\n",
       "      <td>Brc1cccc(-c2cnc3n2CCCCC3)c1</td>\n",
       "      <td>Active</td>\n",
       "      <td>InChI=1S/C14H15BrN2/c15-12-6-4-5-11(9-12)13-10...</td>\n",
       "      <td>Cl</td>\n",
       "      <td>Cl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2998899</td>\n",
       "      <td>Cc1ccccc1C(OCC(O)CN1CCCCC1CCO)c1ccccc1</td>\n",
       "      <td>Active</td>\n",
       "      <td>InChI=1S/C24H33NO3/c1-19-9-5-6-13-23(19)24(20-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>3238898</td>\n",
       "      <td>CCOC(=O)N1CCN(C(=O)c2ccc3c(c2)sc2nc(-c4ccccc4)...</td>\n",
       "      <td>Active</td>\n",
       "      <td>InChI=1S/C23H22N4O3S/c1-2-30-23(29)26-12-10-25...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2999354</td>\n",
       "      <td>CN(C(=O)COC(=O)c1nc(-c2ccccc2)n(-c2ccccc2)n1)C...</td>\n",
       "      <td>Active</td>\n",
       "      <td>InChI=1S/C22H22N4O5S/c1-25(18-12-13-32(29,30)1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>663466</td>\n",
       "      <td>CN1CCN(CC#CCn2c3ccccc3c3ccccc32)CC1</td>\n",
       "      <td>Active</td>\n",
       "      <td>InChI=1S/C21H23N3/c1-22-14-16-23(17-15-22)12-6...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2967872</td>\n",
       "      <td>CC(=O)c1ccccc1OCC(O)CN1CCN(C(c2ccccc2)c2ccccc2...</td>\n",
       "      <td>Active</td>\n",
       "      <td>InChI=1S/C28H32N2O3/c1-22(31)26-14-8-9-15-27(2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>6602782</td>\n",
       "      <td>CCOC(=O)Nc1ccc2c(c1)N(C(=O)CN1CCN(C)CC1)c1cccc...</td>\n",
       "      <td>Active</td>\n",
       "      <td>InChI=1S/C22H26N4O3S/c1-3-29-22(28)23-16-8-9-2...</td>\n",
       "      <td>Cl</td>\n",
       "      <td>Cl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PUBCHEM_CID                      PUBCHEM_EXT_DATASOURCE_SMILES  \\\n",
       "0       1263872  Cc1cc(N2CCN(c3nc(N4CCOCC4)nc4ccccc34)CC2)c2ccc...   \n",
       "1        655606         Cc1ccc2nc(NC3=NCN(CCN4CCOCC4)CN3)nc(C)c2c1   \n",
       "2       3236651    C=CCSc1nnc2c(n1)OC(c1cccnc1)N(C(C)=O)c1ccccc1-2   \n",
       "3       6603423                        Brc1cccc(-c2cnc3n2CCCCC3)c1   \n",
       "4       2998899             Cc1ccccc1C(OCC(O)CN1CCCCC1CCO)c1ccccc1   \n",
       "..          ...                                                ...   \n",
       "82      3238898  CCOC(=O)N1CCN(C(=O)c2ccc3c(c2)sc2nc(-c4ccccc4)...   \n",
       "83      2999354  CN(C(=O)COC(=O)c1nc(-c2ccccc2)n(-c2ccccc2)n1)C...   \n",
       "84       663466                CN1CCN(CC#CCn2c3ccccc3c3ccccc32)CC1   \n",
       "85      2967872  CC(=O)c1ccccc1OCC(O)CN1CCN(C(c2ccccc2)c2ccccc2...   \n",
       "86      6602782  CCOC(=O)Nc1ccc2c(c1)N(C(=O)CN1CCN(C)CC1)c1cccc...   \n",
       "\n",
       "   PUBCHEM_ACTIVITY_OUTCOME  \\\n",
       "0                    Active   \n",
       "1                    Active   \n",
       "2                    Active   \n",
       "3                    Active   \n",
       "4                    Active   \n",
       "..                      ...   \n",
       "82                   Active   \n",
       "83                   Active   \n",
       "84                   Active   \n",
       "85                   Active   \n",
       "86                   Active   \n",
       "\n",
       "                                                InChI  \\\n",
       "0   InChI=1S/C26H28N6O/c1-19-18-24(20-6-2-4-8-22(2...   \n",
       "1   InChI=1S/C19H27N7O/c1-14-3-4-17-16(11-14)15(2)...   \n",
       "2   InChI=1S/C20H17N5O2S/c1-3-11-28-20-22-18-17(23...   \n",
       "3   InChI=1S/C14H15BrN2/c15-12-6-4-5-11(9-12)13-10...   \n",
       "4   InChI=1S/C24H33NO3/c1-19-9-5-6-13-23(19)24(20-...   \n",
       "..                                                ...   \n",
       "82  InChI=1S/C23H22N4O3S/c1-2-30-23(29)26-12-10-25...   \n",
       "83  InChI=1S/C22H22N4O5S/c1-25(18-12-13-32(29,30)1...   \n",
       "84  InChI=1S/C21H23N3/c1-22-14-16-23(17-15-22)12-6...   \n",
       "85  InChI=1S/C28H32N2O3/c1-22(31)26-14-8-9-15-27(2...   \n",
       "86  InChI=1S/C22H26N4O3S/c1-3-29-22(28)23-16-8-9-2...   \n",
       "\n",
       "   Mol removed from mixture Small inorganic molecule Small organic molecule  \n",
       "0                       NaN                      NaN                    NaN  \n",
       "1                       NaN                      NaN                    NaN  \n",
       "2                       NaN                      NaN                    NaN  \n",
       "3                        Cl                       Cl                    NaN  \n",
       "4                       NaN                      NaN                    NaN  \n",
       "..                      ...                      ...                    ...  \n",
       "82                      NaN                      NaN                    NaN  \n",
       "83                      NaN                      NaN                    NaN  \n",
       "84                      NaN                      NaN                    NaN  \n",
       "85                      NaN                      NaN                    NaN  \n",
       "86                       Cl                       Cl                    NaN  \n",
       "\n",
       "[87 rows x 7 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_autofluorescence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f'{data_folder}/before_finished/step_11/11_2'):\n",
    "    os.makedirs(f'{data_folder}/before_finished/step_11/11_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save: \n",
    "post_autofluorescence.to_csv(f'{data_folder}/before_finished/step_11/11_2/post_autofluorescence_hits.csv', index=False)\n",
    "pre11_inactives.to_csv(f'{data_folder}/before_finished/step_11/11_2/post_autofluorescence_inactives.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3 RDKit PAIN filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = FilterCatalogParams()\n",
    "params.AddCatalog(FilterCatalogParams.FilterCatalogs.PAINS)\n",
    "catalog = FilterCatalog(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 pains detected\n",
      "2 pains detected\n",
      "3 pains detected\n",
      "4 pains detected\n",
      "5 pains detected\n",
      "6 pains detected\n",
      "7 pains detected\n"
     ]
    }
   ],
   "source": [
    "def detect_pains(df):\n",
    "    pains = []\n",
    "    count_pains = 0\n",
    "    count_not_pains = 0\n",
    "    smiles_column = 'PUBCHEM_EXT_DATASOURCE_SMILES'\n",
    "    cids_column = 'PUBCHEM_CID'\n",
    "    for i in df.index:\n",
    "        smile = str(df.loc[i, smiles_column])\n",
    "        cid = df.loc[i, cids_column]\n",
    "        mol = Chem.MolFromSmiles(smile)\n",
    "        if mol is not None:\n",
    "            if catalog.HasMatch(mol):\n",
    "                pains.append(cid)\n",
    "                count_pains += 1\n",
    "                print(f'{count_pains} pains detected')\n",
    "            else: \n",
    "                count_not_pains += 1\n",
    "    return pains\n",
    "\n",
    "pains = detect_pains(post_autofluorescence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_pains_hits = post_autofluorescence[~post_autofluorescence['PUBCHEM_CID'].isin(pains)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f'{data_folder}/before_finished/step_11/11_3'):\n",
    "    os.makedirs(f'{data_folder}/before_finished/step_11/11_3')\n",
    "\n",
    "post_pains_hits.to_csv(f'{data_folder}/before_finished/step_11/11_3/post_pains_hits.csv', index=False)\n",
    "pre11_inactives.to_csv(f'{data_folder}/before_finished/step_11/11_3/post_pains_inactives.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Drug-likeness filter: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre12_hits = pd.read_csv(f'{data_folder}/before_finished/step_11/11_3/post_pains_hits.csv', sep=',', header=0)\n",
    "pre12_inactives = pd.read_csv(f'{data_folder}/before_finished/step_11/11_3/post_pains_inactives.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def drug_likeness_filter(smiles):\n",
    "    \"\"\"\n",
    "    This functions check if a given smiles satisfies the common standard conditions for drug-likeness. \n",
    "    Input:\n",
    "        SMILES (str)\n",
    "    Output: \n",
    "        Result (bool)\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert SMILES string to RDKit molecule object\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return False  # Return False if the molecule cannot be parsed\n",
    "    \n",
    "    # Check molecular weight\n",
    "    mw = Chem.rdMolDescriptors.CalcExactMolWt(mol)\n",
    "    if not (150 < mw < 800):\n",
    "        return False\n",
    "    \n",
    "    # Check AlogP\n",
    "    logp = Chem.Crippen.MolLogP(mol)\n",
    "    if not (-0.3 < logp < 5):\n",
    "        return False\n",
    "    \n",
    "    # Check number of rotatable bonds\n",
    "    rotatable_bonds = Lipinski.NumRotatableBonds(mol)\n",
    "    if rotatable_bonds >= 15:\n",
    "        return False\n",
    "    \n",
    "    # Check H-bond acceptor count and H-bond donor count\n",
    "    hba = Lipinski.NumHAcceptors(mol)\n",
    "    hbd = Lipinski.NumHDonors(mol)\n",
    "    if hba >= 15 or hbd >= 15:\n",
    "        return False\n",
    "    \n",
    "    # Check total formal charge\n",
    "    total_charge = sum(atom.GetFormalCharge() for atom in mol.GetAtoms())\n",
    "    if not (-2 < total_charge < 2):\n",
    "        return False\n",
    "    \n",
    "    # If all filters passed, return True\n",
    "    return True\n",
    "\n",
    "def drug_likeness_filter_multiprocessing(df):\n",
    "    \"\"\"\n",
    "    This function update a given dataframe by dropping molecules that don't pass the drug-likeness filter.\n",
    "    \"\"\"\n",
    "    to_drop = []\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        # Create future tasks for each SMILES string in the dataframe\n",
    "        futures = {executor.submit(drug_likeness_filter, row['PUBCHEM_EXT_DATASOURCE_SMILES']): row['PUBCHEM_CID'] for index, row in df.iterrows()}\n",
    "        \n",
    "        # Use tqdm to display progress bar\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing SMILES\"):\n",
    "            cid = futures[future]\n",
    "            if not future.result():\n",
    "                to_drop.append(cid)\n",
    "    return to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing SMILES: 100%|██████████| 80/80 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "not_drug_hits = drug_likeness_filter_multiprocessing(pre12_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing SMILES: 100%|██████████| 61464/61464 [00:00<00:00, 189179.37it/s]\n"
     ]
    }
   ],
   "source": [
    "not_drug_inactives = drug_likeness_filter_multiprocessing(pre12_inactives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 hit compounds that do not pass the drug likeness filter\n",
      "Dropped 1171 inactive compounds that do not pass the drug likeness filter\n"
     ]
    }
   ],
   "source": [
    "post12_hits = pre12_hits[~pre12_hits['PUBCHEM_CID'].isin(not_drug_hits)]\n",
    "post12_inactives = pre12_inactives[~pre12_inactives['PUBCHEM_CID'].isin(not_drug_inactives)]\n",
    "\n",
    "print(f'Dropped {(len(not_drug_hits))} hit compounds that do not pass the drug likeness filter')\n",
    "print(f'Dropped {(len(not_drug_inactives))} inactive compounds that do not pass the drug likeness filter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f'{data_folder}/before_finished/step_12'):\n",
    "    os.makedirs(f'{data_folder}/before_finished/step_12')\n",
    "\n",
    "#Export not_drug_hits and inactives:\n",
    "with open(f'{data_folder}/before_finished/step_12/not_drug_hits.json', 'w') as f:\n",
    "    json.dump(not_drug_hits, f)\n",
    "with open(f'{data_folder}/before_finished/step_12/not_drug_inactives.json', 'w') as f:\n",
    "    json.dump(not_drug_inactives, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save: \n",
    "post12_hits.to_csv(f'{data_folder}/before_finished/step_12/post12_hits.csv', index=False)\n",
    "post12_inactives.to_csv(f'{data_folder}/before_finished/step_12/post12_inactives.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. ChemBL Curation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre13_hits = pd.read_csv(f'{data_folder}/before_finished/step_12/post12_hits.csv', sep=',', header=0)\n",
    "pre13_inactives = pd.read_csv(f'{data_folder}/before_finished/step_12/post12_inactives.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checker_score(smiles, cid):\n",
    "    result = checker.check_molblock(Chem.MolToMolBlock(Chem.MolFromSmiles(smiles)))\n",
    "    if result == ():\n",
    "        penalty_score = 0\n",
    "    else:\n",
    "        penalty_score = result[0][0]\n",
    "    return cid, penalty_score\n",
    "\n",
    "def checker_multiprocessing(df):\n",
    "    chembl_score_dict = {}\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        # Map futures to CIDs directly for easier reference\n",
    "        futures = {executor.submit(checker_score, row['PUBCHEM_EXT_DATASOURCE_SMILES'], row['PUBCHEM_CID']): row['PUBCHEM_CID'] for _, row in df.iterrows()}\n",
    "        # Properly use tqdm to create a progress bar\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing SMILES\"):\n",
    "            cid, penalty_score = future.result()\n",
    "            chembl_score_dict[cid] = penalty_score\n",
    "    return chembl_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing SMILES: 100%|██████████| 78/78 [00:00<?, ?it/s]\n",
      "Processing SMILES: 100%|██████████| 60293/60293 [00:30<00:00, 1989.84it/s] \n"
     ]
    }
   ],
   "source": [
    "score_hits = checker_multiprocessing(pre13_hits)\n",
    "score_inactives = checker_multiprocessing(pre13_inactives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 2}\n",
      "{0, 2, 5, 6}\n"
     ]
    }
   ],
   "source": [
    "#print all unique values in the dictionary:\n",
    "print(set(score_hits.values()))\n",
    "print(set(score_inactives.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new step folder\n",
    "if not os.path.exists(f'{data_folder}/before_finished/step_13'):\n",
    "    os.makedirs(f'{data_folder}/before_finished/step_13')\n",
    "\n",
    "# save the scores:\n",
    "with open(f'{data_folder}/before_finished/step_13/score_hits.json', 'w') as f:\n",
    "    json.dump(score_hits, f)\n",
    "with open(f'{data_folder}/before_finished/step_13/score_inactives.json', 'w') as f:\n",
    "    json.dump(score_inactives, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all compounds with a penalty score of 7:\n",
    "to_drop_hits = []\n",
    "to_drop_inactives = []\n",
    "for cid, penalty_score in score_hits.items():\n",
    "    if penalty_score == 7:\n",
    "        to_drop_hits.append(cid)\n",
    "for cid, penalty_score in score_inactives.items():\n",
    "    if penalty_score == 7:\n",
    "        to_drop_inactives.append(cid)\n",
    "\n",
    "post13_hits = pre13_hits[~pre13_hits['PUBCHEM_CID'].isin(to_drop_hits)]\n",
    "post13_inactives = pre13_inactives[~pre13_inactives['PUBCHEM_CID'].isin(to_drop_inactives)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save final_hits and inactives:\n",
    "post13_hits.to_csv(f'{data_folder}/before_finished/step_13/post13_hits.csv', index=False)\n",
    "post13_inactives.to_csv(f'{data_folder}/before_finished/step_13/post13_inactives.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. Final handling of chemical representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two problems that requires InChI update: \n",
    "\n",
    "(1) Some of the InChI will be missing, since the PubChem Identifier Exchange service might not able to find the corresponding InChI for the aromatized, neutralized SMILES. \n",
    "\n",
    "(2) While handling mixtures, some mixtures whose component molecules are identical will result in duplicates. Therefore, we need to check their activities. \n",
    "- If all duplicates share the same results (active/inactive), we keep one of them. \n",
    "- If duplicates of the same molecules returned different activity, we remove both of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import: \n",
    "pre14_hits = pd.read_csv(f'{data_folder}/before_finished/step_13/post13_hits.csv', sep=',', header=0)\n",
    "pre14_inactives = pd.read_csv(f'{data_folder}/before_finished/step_13/post13_inactives.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.1 Update InChI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smi_to_inchi(smi):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    inchi = Chem.inchi.MolToInchi(mol)\n",
    "    return inchi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 0 InChI values in pre14_hits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02:07:04] WARNING: Charges were rearranged\n",
      "\n",
      "[02:07:04] WARNING: Omitted undefined stereo\n",
      "\n",
      "[02:07:04] WARNING: Omitted undefined stereo\n",
      "\n",
      "[02:07:04] WARNING: Omitted undefined stereo\n",
      "\n",
      "[02:07:04] WARNING: Omitted undefined stereo\n",
      "\n",
      "[02:07:05] WARNING: Omitted undefined stereo\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 25 InChI values in pre14_inactives\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02:07:05] WARNING: Omitted undefined stereo\n",
      "\n",
      "[02:07:05] WARNING: Omitted undefined stereo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0 \n",
    "for index, row in pre14_hits.iterrows():\n",
    "    if row['InChI'] != row['InChI']:\n",
    "        pre14_hits.at[index, 'InChI'] = smi_to_inchi(row['PUBCHEM_EXT_DATASOURCE_SMILES'])\n",
    "        count += 1\n",
    "print(f'Updated {count} InChI values in pre14_hits')\n",
    "\n",
    "count = 0\n",
    "for index, row in pre14_inactives.iterrows():\n",
    "    if row['InChI'] != row['InChI']:\n",
    "        pre14_inactives.at[index, 'InChI'] = smi_to_inchi(row['PUBCHEM_EXT_DATASOURCE_SMILES'])\n",
    "        count += 1\n",
    "print(f'Updated {count} InChI values in pre14_inactives')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.2 Handle duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of InChI duplicates in hits:  0\n",
      "Number of InChI duplicates in inactives:  22\n",
      "Number of SMILES duplicates in hits:  0\n",
      "Number of SMILES duplicates in inactives:  22\n"
     ]
    }
   ],
   "source": [
    "#Check if a mol in hit set appeared in inactive set:\n",
    "for i in pre14_hits['PUBCHEM_EXT_DATASOURCE_SMILES']:\n",
    "    if i in list(pre14_inactives['PUBCHEM_EXT_DATASOURCE_SMILES']):\n",
    "        print(f'{i} SMILES appeared in both hit and inactive sets')\n",
    "for i in pre14_hits['InChI']:\n",
    "    if i in list(pre14_inactives['InChI']):\n",
    "        print(f'{i} InChI appeared in both hit and inactive sets')\n",
    "\n",
    "#Return all duplicates by comparing InChI:\n",
    "final_hits_duplicates_InChI = pre14_hits[pre14_hits.duplicated(subset=['InChI'], keep=False)]\n",
    "final_inactives_duplicates_InChI = pre14_inactives[pre14_inactives.duplicated(subset=['InChI'], keep=False)]\n",
    "final_hits_duplicates_smi = pre14_hits[pre14_hits.duplicated(subset=['PUBCHEM_EXT_DATASOURCE_SMILES'], keep=False)]\n",
    "final_inactives_duplicates_smi = pre14_inactives[pre14_inactives.duplicated(subset=['PUBCHEM_EXT_DATASOURCE_SMILES'], keep=False)]\n",
    "\n",
    "print('Number of InChI duplicates in hits: ', len(final_hits_duplicates_InChI))\n",
    "print('Number of InChI duplicates in inactives: ', len(final_inactives_duplicates_InChI))\n",
    "print('Number of SMILES duplicates in hits: ', len(final_hits_duplicates_smi))\n",
    "print('Number of SMILES duplicates in inactives: ', len(final_inactives_duplicates_smi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f'{data_folder}/before_finished/step_14'):\n",
    "    os.makedirs(f'{data_folder}/before_finished/step_14')\n",
    "\n",
    "#write all the duplicates to a file:\n",
    "#write duplicates to a txt file: \n",
    "with open(f'{data_folder}/before_finished/step_14/duplicates.txt', 'w') as f:\n",
    "    f.write('InChI duplicates in hits: \\n')\n",
    "    f.write(final_hits_duplicates_InChI.to_string())\n",
    "    f.write('\\n\\n')\n",
    "    f.write('InChI duplicates in inactives: \\n')\n",
    "    f.write(final_inactives_duplicates_InChI.to_string())\n",
    "    f.write('\\n\\n')\n",
    "    f.write('SMILES duplicates in hits: \\n')\n",
    "    f.write(final_hits_duplicates_smi.to_string())\n",
    "    f.write('\\n\\n')\n",
    "    f.write('SMILES duplicates in inactives: \\n')\n",
    "    f.write(final_inactives_duplicates_smi.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove these duplicates, keep the first one: \n",
    "#by inchi:\n",
    "final_hits = pre14_hits.drop_duplicates(subset=['InChI'], keep='first')\n",
    "final_inactives = pre14_inactives.drop_duplicates(subset=['InChI'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more duplicates in hits\n",
      "No more duplicates in inactives\n"
     ]
    }
   ],
   "source": [
    "#as expected, there might still be SMILES duplicates:\n",
    "if len(final_hits[final_hits.duplicated(subset=['PUBCHEM_EXT_DATASOURCE_SMILES'], keep=False)]) == 0:\n",
    "    print('No more duplicates in hits')\n",
    "\n",
    "if len(final_inactives[final_inactives.duplicated(subset=['PUBCHEM_EXT_DATASOURCE_SMILES'], keep=False)]) == 0:\n",
    "    print('No more duplicates in inactives')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save: \n",
    "if not os.path.exists(f'{data_folder}/finished'):\n",
    "    os.makedirs(f'{data_folder}/finished')\n",
    "final_hits.to_csv(f'{data_folder}/finished/final_hits.csv',sep=',', index=False)\n",
    "final_inactives.to_csv(f'{data_folder}/finished/final_inactives.csv',sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1. Adjust columns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hits = pd.read_csv(f'{data_folder}/finished/final_hits.csv', sep=',', header=0)\n",
    "final_inactives = pd.read_csv(f'{data_folder}/finished/final_inactives.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add another column: \"activity_value\" with all empty NaN values: \n",
    "final_hits['activity_value'] = np.nan\n",
    "final_inactives['activity_value'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns:\n",
    "final_hits = final_hits.rename(columns={\n",
    "    'PUBCHEM_CID': 'CID', \n",
    "    'PUBCHEM_ACTIVITY_OUTCOME': 'activity_outcome',\n",
    "    'PUBCHEM_EXT_DATASOURCE_SMILES': 'SMILES',\n",
    "    'Mol removed from mixture': 'mol_removed_from_mixture',\n",
    "    'Small inorganic molecule': 'small_inorganic_mol_from_mixture',\n",
    "    'Small organic molecule': 'small_organic_mol_from_mixture'\n",
    "})\n",
    "final_inactives = final_inactives.rename(columns={\n",
    "    'PUBCHEM_CID': 'CID', \n",
    "    'PUBCHEM_ACTIVITY_OUTCOME': 'activity_outcome',\n",
    "    'PUBCHEM_EXT_DATASOURCE_SMILES': 'SMILES',\n",
    "    'Mol removed from mixture': 'mol_removed_from_mixture',\n",
    "    'Small inorganic molecule': 'small_inorganic_mol_from_mixture',\n",
    "    'Small organic molecule': 'small_organic_mol_from_mixture'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#swap the positions of the columns InChI and activity_outcome: \n",
    "final_hits = final_hits[['CID', 'SMILES', 'InChI', 'activity_outcome', 'activity_value', 'mol_removed_from_mixture', 'small_inorganic_mol_from_mixture', 'small_organic_mol_from_mixture']]\n",
    "final_inactives = final_inactives[['CID', 'SMILES', 'InChI', 'activity_outcome', 'activity_value', 'mol_removed_from_mixture', 'small_inorganic_mol_from_mixture', 'small_organic_mol_from_mixture']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export: \n",
    "final_hits.to_csv(f'{data_folder}/finished/final_hits.csv', sep=',', index=False)\n",
    "final_inactives.to_csv(f'{data_folder}/finished/final_inactives.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.2. Convert to txt for CORINA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the final hits and inactives:\n",
    "final_hits = pd.read_csv(f'{data_folder}/finished/final_hits.csv', sep=',', header=0)\n",
    "final_inactives = pd.read_csv(f'{data_folder}/finished/final_inactives.csv', sep=',', header=0) \n",
    "\n",
    "# export to .txt files:\n",
    "final_hits.to_csv(f'{data_folder}/finished/final_hits.txt', sep=';', index=False, header=False)\n",
    "final_inactives.to_csv(f'{data_folder}/finished/final_inactives.txt', sep=';', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.3. Exporting raw data without further curation (only smiles, inchi) for control experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for AID in AIDs: \n",
    "    exec(f\"raw{AID} = pd.read_csv(f'{data_folder}/before_finished/step_1/AID{AID}.csv', sep=',', header=0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import inchi:\n",
    "for AID in AIDs: \n",
    "    exec(f\"std_inchi{AID} = pd.read_csv(f'{data_folder}/before_finished/step_3/std_inchi_{AID}.txt', sep='\\t', header=None)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update inchi\n",
    "for AID in AIDs: \n",
    "    exec(f\"\"\"\n",
    "raw_inchi_dict{AID} = dict(zip(std_inchi{AID}[0], std_inchi{AID}[1]))\n",
    "raw{AID}['InChI'] = raw{AID}['PUBCHEM_CID'].map(raw_inchi_dict{AID})\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_hits = raw628[raw628['PUBCHEM_ACTIVITY_OUTCOME'] == 'Active']\n",
    "raw_inactives = raw628[raw628['PUBCHEM_ACTIVITY_OUTCOME'] == 'Inactive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some other columns to match the format of the curated data: \n",
    "raw_hits.loc[:, 'activity_value'] = np.nan\n",
    "raw_hits.loc[:, 'mol_removed_from_mixture'] = np.nan\n",
    "raw_hits.loc[:, 'small_inorganic_mol_from_mixture'] = np.nan\n",
    "raw_hits.loc[:, 'small_organic_mol_from_mixture'] = np.nan\n",
    "\n",
    "raw_inactives.loc[:, 'activity_value'] = np.nan\n",
    "raw_inactives.loc[:, 'mol_removed_from_mixture'] = np.nan\n",
    "raw_inactives.loc[:, 'small_inorganic_mol_from_mixture'] = np.nan\n",
    "raw_inactives.loc[:, 'small_organic_mol_from_mixture'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns:\n",
    "raw_hits = raw_hits.rename(columns={\n",
    "    'PUBCHEM_CID': 'CID', \n",
    "    'PUBCHEM_ACTIVITY_OUTCOME': 'activity_outcome',\n",
    "    'PUBCHEM_EXT_DATASOURCE_SMILES': 'SMILES',\n",
    "})\n",
    "raw_inactives = raw_inactives.rename(columns={\n",
    "    'PUBCHEM_CID': 'CID', \n",
    "    'PUBCHEM_ACTIVITY_OUTCOME': 'activity_outcome',\n",
    "    'PUBCHEM_EXT_DATASOURCE_SMILES': 'SMILES',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#swap the positions of the columns InChI and activity_outcome: \n",
    "raw_hits = raw_hits[['CID', 'SMILES', 'InChI', 'activity_outcome', 'activity_value', 'mol_removed_from_mixture', 'small_inorganic_mol_from_mixture', 'small_organic_mol_from_mixture']]\n",
    "raw_inactives = raw_inactives[['CID', 'SMILES', 'InChI', 'activity_outcome', 'activity_value', 'mol_removed_from_mixture', 'small_inorganic_mol_from_mixture', 'small_organic_mol_from_mixture']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f'{data_folder}/finished/control_data'):\n",
    "    os.makedirs(f'{data_folder}/finished/control_data')\n",
    "\n",
    "#save the hits and inactives\n",
    "raw_hits.to_csv(f'{data_folder}/finished/control_data/raw_hits.csv', sep=',', index=False)\n",
    "raw_inactives.to_csv(f'{data_folder}/finished/control_data/raw_inactives.csv', sep=',', index=False)\n",
    "\n",
    "#save as txt: \n",
    "raw_hits.to_csv(f'{data_folder}/finished/control_data/raw_hits.txt', sep=';', index=False, header=False)\n",
    "raw_inactives.to_csv(f'{data_folder}/finished/control_data/raw_inactives.txt', sep=';', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
