{"cells":[{"cell_type":"markdown","metadata":{"id":"L0WC0D7rrq36"},"source":["# 0. Initial Set-up"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"viEvaignrq38","outputId":"e1db7848-fbab-4ec9-b64b-ea5c28e0afb4"},"outputs":[{"name":"stderr","output_type":"stream","text":["[06:33:37] Initializing Normalizer\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import requests\n","import os\n","import json\n","import tqdm\n","\n","from rdkit import Chem\n","from tqdm import tqdm\n","from thermo import functional_groups\n","from Bio import Entrez\n","from chembl_structure_pipeline import checker\n","from rdkit.Chem import rdMolDescriptors, Descriptors, Lipinski, Crippen, inchi\n","from rdkit.Chem.FilterCatalog import FilterCatalog, FilterCatalogParams\n","from concurrent.futures import ThreadPoolExecutor, as_completed\n","\n","import utils\n","import filters\n","from data_gathering import download_and_save"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Save the path to your curation folder to \"curation_path\"\n","dataset_name = 'AID435034'\n","curation_path = 'S:/coding/WelQrate/' \n","data_folder = f'{curation_path}/data/{dataset_name}'\n","\n","# Columns to be extracted from the assays:\n","# Modify if your datasets have different format\n","smi_col = 'PUBCHEM_EXT_DATASOURCE_SMILES' # Column containing SMILES\n","cid_col = 'PUBCHEM_CID' # Column containing identifiers (e.g, CIDs)\n","activity_col = 'PUBCHEM_ACTIVITY_OUTCOME' # Column containing activity outcomes\n","col_list = [cid_col, smi_col, activity_col]"]},{"cell_type":"markdown","metadata":{"id":"y1Am6ghyrq3-"},"source":["# 1. Data gathering"]},{"cell_type":"markdown","metadata":{"id":"L5QrVbRKrq3-"},"source":["Before importing data, need to identify which AIDs will be included. \n","\n","Data will be imported from https://pubchem.ncbi.nlm.nih.gov/assay/. For more information on PubChem's programmatic access, refer to: https://pubchem.ncbi.nlm.nih.gov/docs/bioassays. Some other programmatic access options available such as PUG-REST. However, these might not be optimal for bulk retrieval or handling of large dataset due to the limitation of request volume.\n","\n","Data for individual assays include 7 required columns (CIDs, isomeric SMILES, etc.) and optional test results. Refer to https://ftp.ncbi.nlm.nih.gov/pubchem/Bioassay/CSV/README for further details. For datasets intended for regression model, additional columns could be extracted accordingly."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Desired AIDs:\n","AIDs = [628, 677, 859, 860]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-6TZgdkvrq3-","outputId":"db659d62-6285-4f06-b703-95ae5aab7d81"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of datasets retrieving:  4\n"]}],"source":["#Keep unique values in list AIDs (since there could be overlapping AIDs from different targets or project)\n","AIDs = list(set(AIDs))\n","AIDs = [str(AID) for AID in AIDs]\n","print('Number of datasets retrieving: ', len(AIDs))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S6znbQJzrq3-","outputId":"0d17b49a-f6c4-4bce-c3e3-d1790389a764"},"outputs":[{"name":"stdout","output_type":"stream","text":["1 out of 4 complete\n","2 out of 4 complete\n","3 out of 4 complete\n","4 out of 4 complete\n"]}],"source":["download_and_save(AIDs, data_folder, col_list, smi_col, cid_col, activity_col)"]},{"cell_type":"markdown","metadata":{"id":"mDPcWYlWrq3_"},"source":["# 2. Isomeric SMILES"]},{"cell_type":"markdown","metadata":{"id":"oZB6udkJrq3_"},"source":["For the purpose of our project, we would like to include isomeric form of SMILES representation in our final dataset. Although PubChem claimed that their datatable should include isomeric SMILES (https://pubchem.ncbi.nlm.nih.gov/docs/bioassays), some dataset might include non-isomeric SMILES. This step is to import isomeric SMILES based on CIDs.\n","\n","Several packages such as RDkit have modules to return isomeric SMILES from a given input SMILES. However, for consistency, we decided to use the PubChem Identifier Exchange Service, which take an input identifier (CIDs, SMILES, InChI, etc.)  and return the corresponding identifier (CIDs, isomeric SMILES, InChIs, etc.). Here, we export the list of CIDs for compounds in our dataset and use this server to retrieve their isomeric SMILES. For more information, refer to: https://pubchem.ncbi.nlm.nih.gov/docs/identifier-exchange-service"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bDJNQYXbrq3_"},"outputs":[],"source":["#Create a new step folder:\n","if not os.path.exists(f'{data_folder}/before_finished/step_2'):\n","    os.makedirs(f'{data_folder}/before_finished/step_2')\n","\n","#Export list of CIDs to csv with one column (without the column name):\n","for AID in AIDs:\n","    assay = pd.read_csv(f'{data_folder}/before_finished/step_1/AID{AID}.csv')\n","    cids = assay['PUBCHEM_CID'].astype(int)  # Ensure the CIDs are integers\n","    cids.to_csv(f'{data_folder}/before_finished/step_2/CID{AID}.csv', index=False, header=False)\n","\n","#After this step, we submit the list at https://pubchem.ncbi.nlm.nih.gov/idexchange/idexchange.cgi with operator type \"same CID\" and Output IDs \"SMILES\" (isomeric SMILES by default)\n","#https://pubchem.ncbi.nlm.nih.gov/docs/identifier-exchange-service for more details\n","#Here I named the output file as \"SMILES{AID}.txt\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Qxq5IHTrq3_"},"outputs":[],"source":["def check_isomeric_smiles(AIDs):\n","    \"\"\"\n","    Check if the SMILES in the assay are the same as the isomeric forms returned by pubchem idexchange.\n","    Input: AIDs (list of strings)\n","    Output: non_isomeric_smi_cids (dictionary with AID as key and list of CIDs as values for the datasets in AIDs\n","    \"\"\"\n","    non_isomeric_smi_cids = {}\n","    for AID in AIDs:    \n","        non_isomeric_smi_cids[AID] = []\n","        #import SMILES.txt file as a table:\n","        correct_isomeric_smiles = pd.read_csv(f'{data_folder}/before_finished/step_2/isomeric_smi_{AID}.txt', sep='\\t', header=None)\n","        assay = pd.read_csv(f'{data_folder}/before_finished/step_1/AID{AID}.csv')\n","\n","        #compare smiles in assay with smiles in correct_smiles:\n","        for cid in assay['PUBCHEM_CID']:\n","            if assay.loc[assay['PUBCHEM_CID'] == cid, 'PUBCHEM_EXT_DATASOURCE_SMILES'].values[0] != correct_isomeric_smiles.loc[correct_isomeric_smiles[0] == cid, 1].values[0]:\n","                non_isomeric_smi_cids[AID].append(cid)\n","\n","        if len(non_isomeric_smi_cids[AID]) == 0:\n","            print(f'All SMILES in AID {AID} are isomeric')\n","        else:\n","            print(f'There are some potential non-isomeric SMILES in AID {AID}:')\n","            print(non_isomeric_smi_cids[AID])\n","\n","    return non_isomeric_smi_cids\n","\n","def update_isomeric(AIDs, non_isomeric_smi_cids):\n","    \"\"\"\n","    Update the SMILES in the assay to isomeric SMILES.\n","    Input: AIDs (list of strings), non_isomeric_smi_cids (dictionary with AID as key and list of non-isomeric CIDs as values)\n","    \"\"\"\n","    with open(f'{data_folder}/before_finished/step_2/non_isomeric_smi_cids.txt', 'w') as f:\n","        # record the non-isomeric SMILES \n","        for AID in AIDs:\n","            assay = pd.read_csv(f'{data_folder}/before_finished/step_1/AID{AID}.csv')\n","            correct_isomeric_smiles = pd.read_csv(f'{data_folder}/before_finished/step_2/isomeric_smi_{AID}.txt', sep='\\t', header=None)\n","            f.write(f'AID {AID}: {non_isomeric_smi_cids[AID]}\\n')\n","\n","            for cid in non_isomeric_smi_cids[AID]:\n","                f.write(f'CID {cid}: {assay.loc[assay[\"PUBCHEM_CID\"] == cid, \"PUBCHEM_EXT_DATASOURCE_SMILES\"].values[0]} -> {correct_isomeric_smiles.loc[correct_isomeric_smiles[0] == cid, 1].values[0]}\\n')\n","                assay.loc[assay['PUBCHEM_CID'] == cid, 'PUBCHEM_EXT_DATASOURCE_SMILES'] = correct_isomeric_smiles.loc[correct_isomeric_smiles[0] == cid, 1].values[0]\n","\n","            f.write(f'===\\n')\n","            assay.to_csv(f'{data_folder}/before_finished/step_2/AID{AID}.csv', index=False)       "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mYJrYRd8rq3_","outputId":"8a0608c5-cf71-4a5f-e7d7-da0a1670bbc4"},"outputs":[{"name":"stdout","output_type":"stream","text":["All SMILES in AID 859 are isomeric\n","There are some non-isomeric SMILES in AID 628:\n","[2997662, 2997957, 2999888]\n","All SMILES in AID 677 are isomeric\n","All SMILES in AID 860 are isomeric\n"]}],"source":["non_isomeric_smi_cids = check_isomeric_smiles(AIDs)"]},{"cell_type":"markdown","metadata":{"id":"24FEuZDqrq4A"},"source":["Note: Here they returned that three smiles in AID628 were not isomeric. This shows that the SMILES representation of some compounds in the given datasets might not be isomeric."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GN4UdXIfrq4A"},"outputs":[],"source":["update_isomeric(AIDs, non_isomeric_smi_cids)"]},{"cell_type":"markdown","metadata":{"id":"omk-aqHkrq4A"},"source":["# 3. Import InChIs"]},{"cell_type":"markdown","metadata":{"id":"PPLgtPyQrq4A"},"source":["We would like to include standard InChI to diversify users' choice of which data they would like to use for their own benchmark."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MM7hi_lcrq4A"},"outputs":[],"source":["# Create a new step folder:\n","if not os.path.exists(f'{data_folder}/before_finished/step_3'):\n","    os.makedirs(f'{data_folder}/before_finished/step_3')"]},{"cell_type":"markdown","metadata":{"id":"Gj72Gg6Zrq4A"},"source":["Again, it is convenient to use the PubChem Identifier Exchange Service (https://pubchem.ncbi.nlm.nih.gov/idexchange/idexchange.cgi) with operator type \"same CID\" and Output IDs \"InChI\" to retrieve InChI from a given list of input CIDs. The same CID lists from STEP 2 could be used here. The resulted InChIs could be checked if being standard by indentifying the presence of 'InChI=1S' at the begining of each InChI string."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kojz6qvtrq4A"},"outputs":[],"source":["\"\"\"\n","CID lists (in \"step_2\" folder should be submitted to PubChem Identifier Exchange Service)\n","    Operator type: \"same CID\" \n","    Output IDs \"InChI\"\n","    Output method: \"Two column file showing each input output-correspondence\"\n","    Compression: \"No compression\"\n","InChI list should be saved into \"step_3\" folder, named as \"std_inchi_{AID}.txt\" \n","\"\"\"\n","# Import dataframes:\n","for AID in AIDs: \n","    exec(f'AID{AID} = pd.read_csv(\"{data_folder}/before_finished/step_2/AID{AID}.csv\")')\n","    exec(f'AID{AID}_InChI = pd.read_csv(\"{data_folder}/before_finished/step_3/std_inchi_{AID}.txt\", sep=\"\\\\t\", header=None)')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VIWaGZoNrq4B","outputId":"0fb4fc36-304a-4241-c966-524b89998c00"},"outputs":[{"name":"stdout","output_type":"stream","text":["All InChI in AID859 are standard\n","All InChI in AID628 are standard\n","All InChI in AID677 are standard\n","All InChI in AID860 are standard\n"]}],"source":["#Check if they are all standard InChI:\n","for AID in AIDs:\n","    check_inchi = f\"\"\"\n","non_standard_InChI = []\n","for i in range(len(AID{AID}_InChI[1])):\n","    if not AID{AID}_InChI[1][i].startswith('InChI=1S'):\n","        non_standard_InChI.append(AID{AID}_InChI[1][i])\n","if not non_standard_InChI:\n","    print('All InChI in AID{AID} are standard')\n","else:\n","    print('There are some non-standard InChI in AID{AID}')\n","    print(non_standard_InChI)\n","    print('===')\n","\"\"\"\n","    exec(check_inchi)"]},{"cell_type":"markdown","metadata":{"id":"ueoYeDpxrq4B"},"source":["Now we concatenate the InChIs in our tables:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dCI686Zyrq4B"},"outputs":[],"source":["# Update and save the files\n","for AID in AIDs: \n","    update_inchi = f\"\"\"\n","AID{AID}_InChI_dict = dict(zip(AID{AID}_InChI[0], AID{AID}_InChI[1]))\n","AID{AID}['InChI'] = AID{AID}[cid_col].map(AID{AID}_InChI_dict)\n","AID{AID}['InChI'] = AID{AID}['InChI'].astype(str)\n","AID{AID}[cid_col] = AID{AID}[cid_col].astype(int)\n","AID{AID}.to_csv(r\"{data_folder}/before_finished/step_3/AID{AID}.csv\", index=False)\n","\"\"\"\n","    exec(update_inchi)"]},{"cell_type":"markdown","metadata":{"id":"sfJwxkhwrq4B"},"source":["# 4. Check duplicates"]},{"cell_type":"markdown","metadata":{"id":"NIBZS75krq4B"},"source":["When checking duplicates in the datasets, we would like to know if there are\n","1) Multiple identical molecules\n","2) Molecules with identical CID but different InChIs or SMILES\n","3) Molecules with identical InChI but with different CIDs or SMILES"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wGv2it7Vrq4B"},"outputs":[],"source":["#import:\n","for AID in AIDs:\n","    exec(f\"AID{AID} = pd.read_csv(r'{data_folder}/before_finished/step_3/AID{AID}.csv', sep=',', header=0)\")\n","\n","#Create a new step folder:\n","if not os.path.exists(f'{data_folder}/before_finished/step_4'):\n","    os.makedirs(f'{data_folder}/before_finished/step_4')"]},{"cell_type":"markdown","metadata":{"id":"z2rcfEAUrq4B"},"source":["## 4.1. Checking identical molecules"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9lD9jpckrq4B","outputId":"8d17b874-b133-46bf-d368-6ad4fbf3480b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of AID859 InChI duplicates:  0\n","Number of AID859 SMILES duplicates:  0\n","Number of AID859 CID duplicates:  0\n","Number of AID628 InChI duplicates:  12\n","Number of AID628 SMILES duplicates:  12\n","Number of AID628 CID duplicates:  12\n","Number of AID677 InChI duplicates:  0\n","Number of AID677 SMILES duplicates:  0\n","Number of AID677 CID duplicates:  0\n","Number of AID860 InChI duplicates:  0\n","Number of AID860 SMILES duplicates:  0\n","Number of AID860 CID duplicates:  0\n"]}],"source":["#Return all duplicates by comparing InChI, SMILES, and CIDs:\n","for AID in AIDs:\n","    check_duplicate = f\"\"\"\n","AID{AID}_duplicates_InChI = AID{AID}[AID{AID}.duplicated(subset=['InChI'], keep=False)]\n","AID{AID}_duplicates_SMILES = AID{AID}[AID{AID}.duplicated(subset=[smi_col], keep=False)]\n","AID{AID}_duplicates_CIDs = AID{AID}[AID{AID}.duplicated(subset=[cid_col], keep=False)]\n","print('Number of AID{AID} InChI duplicates: ', len(AID{AID}_duplicates_InChI))\n","print('Number of AID{AID} SMILES duplicates: ', len(AID{AID}_duplicates_SMILES))\n","print('Number of AID{AID} CID duplicates: ', len(AID{AID}_duplicates_CIDs))\n","\"\"\"\n","    exec(check_duplicate)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xXK8nLIjrq4C"},"outputs":[],"source":["#write duplicates to a txt file: \n","with open(f'{data_folder}/before_finished/step_4/duplicates.txt', 'w') as f:\n","    for AID in AIDs: \n","        duplicates_InChI = eval(f'AID{AID}_duplicates_InChI')\n","        duplicates_SMILES = eval(f'AID{AID}_duplicates_SMILES')\n","        duplicates_CIDs = eval(f'AID{AID}_duplicates_CIDs')\n","        f.write(f'\\n\\nAID{AID} InChI duplicates:\\n')\n","        f.write(duplicates_InChI.to_string())\n","        f.write(f'\\nAID{AID} SMILES duplicates:\\n')\n","        f.write(duplicates_SMILES.to_string())\n","        f.write(f'\\nAID{AID} CID duplicates:\\n')\n","        f.write(duplicates_CIDs.to_string())"]},{"cell_type":"markdown","metadata":{"id":"WFXtZFKBrq4C"},"source":["## 4.2. Same CIDs but different chemical representations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qNFgAoT3rq4C"},"outputs":[],"source":["#reindex\n","for AID in AIDs:\n","    exec(f\"AID{AID}_duplicates_CIDs.reset_index(drop=True, inplace=True)\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_AqwM6L1rq4C"},"outputs":[],"source":["with open(f'{data_folder}/before_finished/step_4/sameCID_different_others.txt', 'w') as f:\n","    for AID in AIDs: \n","        sameCID_differentInChI = []\n","        sameCID_differentSMILES = []\n","        duplicates_CIDs = eval(f'AID{AID}_duplicates_CIDs')\n","        for i in range(len(duplicates_CIDs[cid_col])):\n","            for j in range(i+1, len(duplicates_CIDs[cid_col])):\n","                if duplicates_CIDs[cid_col][i] == duplicates_CIDs[cid_col][j]:\n","                    if duplicates_CIDs['InChI'][i] != duplicates_CIDs['InChI'][j]:\n","                        sameCID_differentInChI.append((duplicates_CIDs[cid_col][i], duplicates_CIDs[cid_col][j]))\n","                    if duplicates_CIDs[smi_col][i] != duplicates_CIDs[smi_col][j]:\n","                        sameCID_differentSMILES.append((duplicates_CIDs[cid_col][i], duplicates_CIDs[cid_col][j]))\n","\n","        if sameCID_differentInChI == []:\n","            f.write(f'No duplicate CIDs with different InChIs in AID{AID}\\n')\n","        else:\n","            f.write('Found duplicate CIDs with different InChIs in AID{AID}:\\n')\n","            f.write('\\n'.join(str(item) for item in sameCID_differentInChI))\n","            f.write(\"\\n\")\n","        \n","        if sameCID_differentSMILES == []:\n","            f.write(f'No duplicate CIDs with different SMILES in AID{AID}\\n')\n","        else:\n","            f.write(f'Found duplicate CIDs with different SMILES in AID{AID}:\\n')\n","            f.write('\\n'.join(str(item) for item in sameCID_differentSMILES))\n","            f.write(\"\\n\")\n","        f.write(\"===\\n\")"]},{"cell_type":"markdown","metadata":{"id":"P81psurYrq4C"},"source":["## 4.3. Same InChI but with different CIDs or SMILES"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rFKstR5qrq4C"},"outputs":[],"source":["#reindex\n","for AID in AIDs:\n","    exec(f\"AID{AID}_duplicates_InChI.reset_index(drop=True, inplace=True)\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ceyljwZrq4D"},"outputs":[],"source":["with open(f'{data_folder}/before_finished/step_4/sameInChI_different_others.txt', 'w') as f:\n","    for AID in AIDs: \n","        sameInChI_differentCID = []\n","        sameInChI_differentSMILES = []\n","        duplicates_InChI = eval(f'AID{AID}_duplicates_InChI')\n","        for i in range(len(duplicates_InChI['InChI'])):\n","            for j in range(i+1, len(duplicates_InChI['InChI'])):\n","                if duplicates_InChI['InChI'][i] == duplicates_InChI['InChI'][j]:\n","                    if duplicates_InChI[cid_col][i] != duplicates_InChI[cid_col][j]:\n","                        sameInChI_differentCID.append((duplicates_InChI[cid_col][i], duplicates_InChI[cid_col][j]))\n","                    if duplicates_InChI[smi_col][i] != duplicates_InChI[smi_col][j]:\n","                        sameInChI_differentSMILES.append((duplicates_InChI[cid_col][i], duplicates_InChI[cid_col][j]))\n","        \n","        if sameInChI_differentCID == []:\n","            f.write(f'No duplicate InChIs with different CIDs in AID{AID}\\n')\n","        else:\n","            f.write('Found duplicate InChIs with different CIDs in AID{AID}:\\n')\n","            f.write('\\n'.join(str(item) for item in sameInChI_differentCID))\n","            f.write(\"\\n\")\n","        \n","        if sameInChI_differentSMILES == []:\n","            f.write(f'No duplicate InChIs with different SMILES in AID{AID}\\n')\n","        else:\n","            f.write(f'Found duplicate InChIs with different SMILES in AID{AID}:\\n')\n","            f.write('\\n'.join(str(item) for item in sameInChI_differentSMILES))\n","            f.write(\"\\n\")\n","        f.write(\"===\\n\")"]},{"cell_type":"markdown","metadata":{"id":"nUUhEwxXrq4D"},"source":["## 4.4. Same SMILES but with different CIDs or SMILES"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ftlZbmfJrq4D"},"outputs":[],"source":["#reindex\n","for AID in AIDs:\n","    exec(f\"AID{AID}_duplicates_SMILES.reset_index(drop=True, inplace=True)\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tf74h81Rrq4D"},"outputs":[],"source":["with open(f'{data_folder}/before_finished/step_4/sameSMILES_different_others.txt', 'w') as f:\n","    for AID in AIDs: \n","        sameSMILES_differentCID = []\n","        sameSMILES_differentInChI = []\n","        duplicates_SMILES = eval(f'AID{AID}_duplicates_SMILES')\n","        for i in range(len(duplicates_SMILES[smi_col])):\n","            for j in range(i+1, len(duplicates_SMILES[smi_col])):\n","                if duplicates_SMILES[smi_col][i] == duplicates_SMILES[smi_col][j]:\n","                    if duplicates_SMILES[cid_col][i] != duplicates_SMILES[cid_col][j]:\n","                        sameSMILES_differentCID.append((duplicates_SMILES[cid_col][i], duplicates_SMILES[cid_col][j]))\n","                    if duplicates_SMILES['InChI'][i] != duplicates_SMILES['InChI'][j]:\n","                        sameSMILES_differentInChI.append((duplicates_SMILES[cid_col][i], duplicates_SMILES[cid_col][j]))\n","        \n","        if sameSMILES_differentCID == []:\n","            f.write(f'No duplicate SMILES with different CIDs in AID{AID}\\n')\n","        else:\n","            f.write(f'Found duplicate SMILES with different CIDs in AID{AID}:\\n')\n","            f.write('\\n'.join(str(item) for item in sameSMILES_differentCID))\n","            f.write(\"\\n\")\n","        \n","        if sameSMILES_differentInChI == []:\n","            f.write(f'No duplicate SMILES with different InChIs in AID{AID}\\n')\n","        else:\n","            f.write(f'Found duplicate SMILES with different InChIs in AID{AID}:\\n')\n","            f.write('\\n'.join(str(item) for item in sameSMILES_differentInChI))\n","            f.write(\"\\n\")\n","        f.write(\"===\\n\")"]},{"cell_type":"markdown","metadata":{"id":"0UD4HdCPrq4E"},"source":["## 4.5 Drop duplicates"]},{"cell_type":"markdown","metadata":{"id":"gH-f6NS4rq4E"},"source":["When dropping duplicates, we will keep the first molecule in a pair or a group of duplicates. For example, here there are 12 duplicates (6 pairs) so we keep 6 of them."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DHIOoIrTrq4E","outputId":"03b63d69-d2a2-42e1-e58c-4f0685050997"},"outputs":[{"name":"stdout","output_type":"stream","text":["No more duplicate InChI in AID859\n","No more duplicate InChI in AID628\n","No more duplicate InChI in AID677\n","No more duplicate InChI in AID860\n"]}],"source":["# Keep only the first duplicate in the dataframes:\n","for AID in AIDs: \n","    exec(f\"AID{AID}.drop_duplicates(subset=['InChI'], keep='first', inplace=True)\")\n","\n","    last_check = f\"\"\"\n","if len(AID{AID}[AID{AID}.duplicated(subset=['InChI'], keep=False)]) == 0:\n","    print('No more duplicate InChI in AID{AID}')\n","else:\n","    print('There are still duplicate InChI in AID{AID}')   \n","    \"\"\"\n","    exec(last_check)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for AID in AIDs: \n","    last_check = f\"\"\"\n","if len(AID{AID}[AID{AID}.duplicated(subset=[smi_col], keep=False)]) == 0:\n","    print('No more duplicate SMILES in AID{AID}')\n","else:\n","    print('There are still duplicate SMILES in AID{AID}')   \n","    \"\"\"\n","    exec(last_check)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for AID in AIDs: \n","    last_check = f\"\"\"\n","if len(AID{AID}[AID{AID}.duplicated(subset=[cid_col], keep=False)]) == 0:\n","    print('No more duplicate CID in AID{AID}')\n","else:\n","    print('There are still duplicate CID in AID{AID}')   \n","    \"\"\"\n","    exec(last_check)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hVwyQwyMrq4E"},"outputs":[],"source":["# Save the dataframes to csv:\n","for AID in AIDs: \n","    exec(f\"AID{AID}.to_csv(r'{data_folder}/before_finished/step_4/AID{AID}.csv', index=False)\")"]},{"cell_type":"markdown","metadata":{"id":"L5vs6XTurq4E"},"source":["# 5. Hierarchical Curation"]},{"cell_type":"markdown","metadata":{"id":"S30kCEhhrq4F"},"source":["For the hierarchical curation, there are some rules:\n","\n","(1) All assays used should be on the same or close species/cell lines. Optimally, they should also be from the same project/laboratory.\n","\n","(2) Primary actives (PrA) will have a large false-positive rate. Therefore, they should be tested in follow-up confirmatory screens (optimally dose-reponse).\n","\n","(3) Actives could be promiscuous. Therefore, it is optimal to have counter-screens on different targets to test specificity.\n","\n","(4) For some projects, compounds were tested in multiple rounds. Therefore, assays often have hierarchical relations. From a single primary screen (Pr), active compounds (Pr_A) could be tested in multiple rounds of confirmatory screens (Cf_1, Cf_2, ..., Cf_final) or counter screens (Ct_1, Ct_2, etc.). Actives from confirmatory screens (Cf_actives) have a higher possibility of being true active. If an active compound is tested active in counter screens (Cf_actives), it is likely to be a promiscuous compound and should not be included.\n","\n","(4) It is important to know the relationship between assays. Active sets from downstream screens always have a lower false-positive rate than active sets from upstream screens due to better assay technologies on a smaller set of compounds. Therefore, final hits should be taken from the intersection of the very last confirmatory assays, without tested active in any counter-screen:\n","Final hits = [Cf_final1_actives ∩ Cf_final2_actives ∩ ...] \\ [Ct_1_actives ∪ Ct_2_actives ∪ ...]\n","\n","However, if the confirmatory assays are unrelated (tested on different set of compounds), then we might have to take the union of their active sets instead of the intersections as in this formula.\n","\n","(5) The hierarchical relations should be inspected carefully to see if follow-up confirmatory screens include extra compounds (Ex) that were not tested in earlier screens or tested inactive in earlier screens. If exist, these compounds require manual inspection.\n","\n","(6) Final inactives should be taken from primary inactives (Pr_inactives) (not inconclusive, unspecified, or probes), plus extra compounds that were tested inactive in conformatory screens (Ex_inactives), if justified.\n","Final inactives = Pr_inactives ∪ Ex_inactives"]},{"cell_type":"markdown","metadata":{"id":"8fNVHhTgrq4F"},"source":["## 5.1. Classify groups of compounds in each assay by activities"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ScQjbHf3rq4F"},"outputs":[],"source":["path = f'{data_folder}/before_finished/step_4'\n","keynumbers = [628, 677, 859, 860] # specify the keynumbers you want to import\n","\n","for keynumber in keynumbers:\n","    filename = os.path.join(path, f'AID{keynumber}.csv')\n","    if os.path.exists(filename):\n","        df = pd.read_csv(filename, index_col=None, header=0)\n","        exec(f'AID{keynumber} = df')\n","        exec(f'AID{keynumber}_active = df[df[\"PUBCHEM_ACTIVITY_OUTCOME\"]==\"Active\"]')\n","        exec(f'AID{keynumber}_inactive = df[df[\"PUBCHEM_ACTIVITY_OUTCOME\"]==\"Inactive\"]')\n","        exec(f'AID{keynumber}_inconclusive = df[df[\"PUBCHEM_ACTIVITY_OUTCOME\"]==\"Inconclusive\"]')\n","        exec(f'AID{keynumber}_unspecified = df[df[\"PUBCHEM_ACTIVITY_OUTCOME\"]==\"Unspecified\"]')\n","        exec(f'AID{keynumber}_probe = df[df[\"PUBCHEM_ACTIVITY_OUTCOME\"]==\"Probe\"]')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_SBex-VOrq4F","outputId":"8b24f1f6-090b-4547-cc6c-fa26ecc8c25f"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>AID</th>\n","      <th>Tested Compounds</th>\n","      <th>Active</th>\n","      <th>Inactive</th>\n","      <th>Inconclusive</th>\n","      <th>Unspecified</th>\n","      <th>Probe</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AID628</td>\n","      <td>63656</td>\n","      <td>2179</td>\n","      <td>61477</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>AID677</td>\n","      <td>1665</td>\n","      <td>723</td>\n","      <td>942</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>AID859</td>\n","      <td>591</td>\n","      <td>231</td>\n","      <td>360</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>AID860</td>\n","      <td>719</td>\n","      <td>272</td>\n","      <td>447</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      AID  Tested Compounds  Active  Inactive  Inconclusive  Unspecified  \\\n","0  AID628             63656    2179     61477             0            0   \n","1  AID677              1665     723       942             0            0   \n","2  AID859               591     231       360             0            0   \n","3  AID860               719     272       447             0            0   \n","\n","   Probe  \n","0      0  \n","1      0  \n","2      0  \n","3      0  "]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["#Create a df with first column the variables name, and the second column the number of rows:\n","df = pd.DataFrame(columns=['AID', 'Tested Compounds', 'Active', 'Inactive', 'Inconclusive', 'Unspecified', 'Probe'])\n","for keynumber in keynumbers:\n","    exec(f'df.loc[len(df)] = [\"AID{keynumber}\", len(AID{keynumber}), len(AID{keynumber}_active), len(AID{keynumber}_inactive), len(AID{keynumber}_inconclusive), len(AID{keynumber}_unspecified), len(AID{keynumber}_probe)]')\n","df"]},{"cell_type":"markdown","metadata":{"id":"6HajGkVErq4F"},"source":["## 5.2. Check the hierachical relations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GwDauVNUrq4F"},"outputs":[],"source":["def check_is_in(downstream, upstream):\n","    downstream_in_upstream = downstream[downstream[cid_col].isin(upstream[cid_col])]\n","    downstream_notin_upstream = downstream[~downstream[cid_col].isin(upstream[cid_col])]\n","    return downstream_in_upstream, downstream_notin_upstream"]},{"cell_type":"markdown","metadata":{"id":"jjnGUezFrq4G"},"source":["### Flow: AID628 (Pr), AID677 (Cf_1), AID860 (Ct_1), and AID859 (Cf_2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a7yce69xrq4G","outputId":"db44b6bf-07ce-4c1e-c2a9-4e065e11f7bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Among AID859, 0 were tested inactive in AID677. Among these, 0 became active\n","Among AID859, 0 were tested inactive in AID628. Among these, 0 became active\n","Among AID859, 0 were not tested in the AID628. Among these, 0 became active\n","Among AID859, 219 were tested active in the counter AID860. Among these, 144 became active\n"]}],"source":["a1, a2 = check_is_in(AID859, AID677_inactive)\n","a3, a4 = check_is_in(a1, AID859_active)\n","print(f'Among AID859, {len(a1)} were tested inactive in AID677. Among these, {len(a3)} became active')\n","\n","b1, b2 = check_is_in(AID859, AID628_inactive)\n","b3, b4 = check_is_in(b1, AID859_active)\n","b5, b6 = check_is_in(AID859, AID628)\n","b7, b8 = check_is_in(b6, AID859_active)\n","print(f'Among AID859, {len(b1)} were tested inactive in AID628. Among these, {len(b3)} became active')\n","print(f'Among AID859, {len(b6)} were not tested in the AID628. Among these, {len(b7)} became active')\n","\n","c1, c2 = check_is_in(AID859, AID860_active)\n","c3, c4 = check_is_in(c1, AID859_active)\n","print(f'Among AID859, {len(c1)} were tested active in the counter AID860. Among these, {len(c3)} became active')"]},{"cell_type":"markdown","metadata":{"id":"K31D496Yrq4G"},"source":["Here, no extra compounds were found. The potential final hits therefore should be the confirmed actives from AID859, subtracted by compounds that were active in the counter screens. Inactives should be taken from the primary inactives."]},{"cell_type":"markdown","metadata":{"id":"XKnnmwPzrq4G"},"source":["## 5.3. Export the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"APwhhH9krq4G"},"outputs":[],"source":["potential_actives = AID859_active[~AID859_active[cid_col].isin(AID860_active[cid_col])]\n","potential_inactives = AID628_inactive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O7EX7408rq4G"},"outputs":[],"source":["if not os.path.exists(f'{data_folder}/before_finished/step_5'):\n","    os.makedirs(f'{data_folder}/before_finished/step_5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OUQYhOmfrq4H"},"outputs":[],"source":["#export the potential hits and inactives to csv:\n","potential_actives.to_csv(f'{data_folder}/before_finished/step_5/potential_actives.csv', index=False)\n","potential_inactives.to_csv(f'{data_folder}/before_finished/step_5/potential_inactives.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"6ycF0jeUrq4H"},"source":["# 6. RDkit Parse Check"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zOmKlJAsrq4H"},"outputs":[],"source":["potential_actives = pd.read_csv(f'{data_folder}/before_finished/step_5/potential_actives.csv', sep=',', header=0)\n","potential_inactives = pd.read_csv(f'{data_folder}/before_finished/step_5/potential_inactives.csv', sep=',', header=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xMH2q1YBrq4H","outputId":"27dca7aa-cb0f-4d46-fc29-ed7614cf7f1e"},"outputs":[{"name":"stdout","output_type":"stream","text":["No problems detected\n","No problems detected\n"]}],"source":["problems_actives, cannot_parse_actives = filters.rdkit_parse(potential_actives, smi_col, cid_col)\n","problems_inactives, cannot_parse_inactives = filters.rdkit_parse(potential_inactives, smi_col, cid_col)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xhCw_Oi3rq4H"},"outputs":[],"source":["#Create a new step folder:\n","if not os.path.exists(f'{data_folder}/before_finished/step_6'):\n","    os.makedirs(f'{data_folder}/before_finished/step_6')\n","\n","with open(f'{data_folder}/before_finished/step_6/problem_list_actives.txt', 'w') as f:\n","    f.write(\"Problems:\\n\")\n","    for item in problems_actives:\n","        f.write(\"%s\\n\" % item)\n","    f.write(\"Cannot parse:\\n\")\n","    for item in cannot_parse_actives:\n","        f.write(\"%s\\n\" % item)\n","\n","with open(f'{data_folder}/before_finished/step_6/problem_list_inactives.txt', 'w') as f:\n","    f.write(\"Problems:\\n\")\n","    for item in problems_inactives:\n","        f.write(\"%s\\n\" % item)\n","    f.write(\"Cannot parse:\\n\")\n","    for item in cannot_parse_inactives:\n","        f.write(\"%s\\n\" % item)"]},{"cell_type":"markdown","metadata":{"id":"I7sGnntrrq4I"},"source":["Our dataset returned no problem or non-parsable molecule."]},{"cell_type":"markdown","metadata":{"id":"o8BMjAYKrq4I"},"source":["# 7. Inorganics Filter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jo5QnN7Srq4I"},"outputs":[],"source":["# Import data\n","potential_actives = pd.read_csv(f'{data_folder}/before_finished/step_5/potential_actives.csv', sep=',', header=0)\n","potential_inactives = pd.read_csv(f'{data_folder}/before_finished/step_5/potential_inactives.csv', sep=',', header=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G8F8O0birq4I","outputId":"57b69061-9c68-4db4-a52b-1164cc7f8fa3"},"outputs":[{"name":"stdout","output_type":"stream","text":["In hits, there are 87 organic molecules and 0 inorganic molecules\n","In inactives, there are 61477 organic molecules and 0 inorganic molecules\n"]}],"source":["inorganic_actives_cids, organic_actives_cids = filters.inorganic_filter(potential_actives, smi_col, cid_col, type='smiles')\n","print(f'In hits, there are {len(organic_actives_cids)} organic molecules and {len(inorganic_actives_cids)} inorganic molecules')\n","\n","inorganic_inactives_cids, organic_inactives_cids = filters.inorganic_filter(potential_inactives, smi_col, cid_col, type='smiles')\n","print(f'In inactives, there are {len(organic_inactives_cids)} organic molecules and {len(inorganic_inactives_cids)} inorganic molecules')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZO-Ro6Zerq4J"},"outputs":[],"source":["#Create a new step folder:\n","if not os.path.exists(f'{data_folder}/before_finished/step_7'):\n","    os.makedirs(f'{data_folder}/before_finished/step_7')\n","\n","with open(f'{data_folder}/before_finished/step_7/inorganic.txt', 'w') as f:\n","    f.write(\"Actives:\\n\")\n","    for item in inorganic_actives_cids:\n","        f.write(\"%s\\n\" % item)\n","    f.write(\"\\n\\nInactives:\\n\")\n","    for item in inorganic_inactives_cids:\n","        f.write(\"%s\\n\" % item)\n","\n","# Drop inorganics: \n","potential_actives = potential_actives[~potential_actives[cid_col].isin(inorganic_actives_cids)]\n","potential_inactives = potential_inactives[~potential_inactives[cid_col].isin(inorganic_inactives_cids)]\n","\n","#save: \n","potential_actives.to_csv(f'{data_folder}/before_finished/step_7/organic_actives.csv', index=False)\n","potential_inactives.to_csv(f'{data_folder}/before_finished/step_7/organic_inactives.csv', index=False)\n","\n","print('Dropped inorganic and saved organic compounds into step_7 folder.')"]},{"cell_type":"markdown","metadata":{"id":"UkKdIZR1rq4J"},"source":["# 8. Mixtures Handling"]},{"cell_type":"markdown","metadata":{"id":"OmwJ9MySrq4J"},"source":["## 8.1. Quick check"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-0AOtzIOrq4J"},"outputs":[],"source":["#import: \n","organic_actives = pd.read_csv(f'{data_folder}/before_finished/step_7/organic_actives.csv', sep=',', header=0)\n","organic_inactives = pd.read_csv(f'{data_folder}/before_finished/step_7/organic_inactives.csv', sep=',', header=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-08lzECcrq4K","outputId":"3da5941a-d24a-4b74-c614-d3cf20c4a5d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of mixtures in hits is 21\n","Total number of mixtures in inactives is 1741\n"]}],"source":["filters.quick_check_mixtures('hits', organic_actives[smi_col])\n","filters.quick_check_mixtures('inactives', organic_inactives[smi_col])"]},{"cell_type":"markdown","metadata":{"id":"AIa7Dt8Hrq4K"},"source":["## 8.2. Handling mixture"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J2NBiwfhrq4K","outputId":"d979708c-9370-44d4-dda1-78312478fcaf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cannot decide between ['CC1=NC2=C(O1)C3=CC=CC=C3C=C2', 'C1=C(C=C(C(=C1[N+](=O)[O-])O)[N+](=O)[O-])[N+](=O)[O-]'] for CID 3241713\n","Big organic molecule for CID 3244813 does not pass Lipinski's rule of five\n","Cannot decide between ['CN(C)C1=NC2=CC=CC=C2C(=C1)N', 'C1=C(NC(=O)NC1=O)C(=O)O'] for CID 646688\n","Cannot decide between ['C1C2(CN3CN1CN(C2)C3)N', 'C1=CC(=CN=C1)C(=O)O'] for CID 648270\n","Cannot decide between ['CN(C)C1=NC2=C(CCC2)C(=C1)N', 'C1=C(C=NC=C1O)C(=O)O'] for CID 652177\n","Cannot decide between ['CC1=NC2=C(S1)C3=CC=CC=C3C=C2', 'C1=C(C=C(C(=C1[N+](=O)[O-])O)[N+](=O)[O-])[N+](=O)[O-]'] for CID 654127\n","Cannot decide between ['C1CC1C(C2CC2)NC3=NCCO3', 'C(=C/C(=O)O)\\\\C(=O)O'] for CID 5388964\n","Cannot decide between ['CN1C(=O)C2=C(N=C(N2)Cl)N(C1=O)C(=O)[O-]', 'CN(C)CCOC(C1=CC=CC=C1)C2=CC=CC=C2'] for CID 657227\n","Cannot decide between ['CC[N+](C)(C)CC1=CC=CC=C1Br', 'CC1=CC=C(C=C1)S(=O)(=O)[O-]'] for CID 6100\n","Cannot decide between ['C1CN(CCN1CCOCCO)C(C2=CC=CC=C2)C3=CC=C(C=C3)Cl', 'C1=CC=C2C(=C1)C=C(C(=C2CC3=C(C(=CC4=CC=CC=C43)C(=O)O)O)O)C(=O)O'] for CID 25096\n","Big organic molecule for CID 5284352 does not pass Lipinski's rule of five\n","Big organic molecule for CID 444034 does not pass Lipinski's rule of five\n","Big organic molecule for CID 5284439 does not pass Lipinski's rule of five\n"]}],"source":["processed_actives, removed_actives, small_organic_actives, small_inorganic_actives, not_lipinski_actives, cleaned_actives = filters.process_smi_mixtures(organic_actives, smi_col, cid_col)\n","processed_inactives, removed_inactives, small_organic_inactives, small_inorganic_inactives, not_lipinski_inactives, cleaned_inactives = filters.process_smi_mixtures(organic_inactives, smi_col, cid_col)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w-ppaAmTrq4K"},"outputs":[],"source":["# Create a new step folder\n","if not os.path.exists(f'{data_folder}/before_finished/step_8'):\n","    os.makedirs(f'{data_folder}/before_finished/step_8')\n","\n","#Generate df with the smiles column in the cleaned_actives or cleaned_inactives dictionary:\n","cleaned_actives_df = pd.DataFrame(list(cleaned_actives.values()), columns=[smi_col])\n","cleaned_inactives_df = pd.DataFrame(list(cleaned_inactives.values()), columns=[smi_col])\n","\n","#Export the cleaned hits and inactives to csv:\n","cleaned_actives_df.to_csv(f'{data_folder}/before_finished/step_8/cleaned_mixtures_actives.csv', index=False, header=False)\n","cleaned_inactives_df.to_csv(f'{data_folder}/before_finished/step_8/cleaned_mixtures_inactives.csv', index=False, header=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Yr5-WLXrq4L","outputId":"d90e78a3-abfe-4e07-bdf0-a14143228b75"},"outputs":[{"name":"stdout","output_type":"stream","text":["3241713 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n","3244813 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n","646688 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n","648270 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n","652177 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n","654127 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n","5388964 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n","657227 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n","6100 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n","25096 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n","5284352 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n","444034 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n","5284439 has been removed from inactives_M1_antagonist because it is a mixture with less than 5 atoms difference or the big organic molecule does not pass Lipinski's rule of five.\n"]}],"source":["processed_hits_df = filters.process_mixture_df('actives_M1_antagonist', organic_actives, processed_actives, removed_actives, small_organic_actives, small_inorganic_actives, smi_col, cid_col)\n","processed_inactives_df = filters.process_mixture_df('inactives_M1_antagonist', organic_inactives, processed_inactives, removed_inactives, small_organic_inactives, small_inorganic_inactives, smi_col, cid_col)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qb7lNZtzrq4L","outputId":"2d737adf-e8ef-42f4-a8df-7a890b477107"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataframes saved successfully\n"]}],"source":["with open(f'{data_folder}/before_finished/step_8/mixture.txt', 'w') as f:\n","    f.write(f\"\"\"\n","Hits before processing: {len(organic_actives)}\n","Hits before processing: {len(organic_actives)}\n","Hits after processing: {len(processed_hits_df)}\n","Mixtures detected: {len(removed_actives)}\n","Mixtures with small inorganic molecules: {len(small_inorganic_actives)}\n","Mixtures with big organic molecules passing Lipinski: {len(small_organic_actives)}\n","Mixtures with big organic molecules not passing Lipinski: {len(not_lipinski_actives)}\n","\n","Inactives before processing: {len(organic_inactives)}\n","Inactives after processing: {len(processed_inactives_df)}\n","Mixtures detected: {len(removed_inactives)}\n","Mixtures with small inorganic molecules: {len(small_inorganic_inactives)}\n","Mixtures with big organic molecules passing Lipinski: {len(small_organic_inactives)}\n","Mixtures with big organic molecules not passing Lipinski: {len(not_lipinski_inactives)}\n","\"\"\")\n","\n","# Save the processed dataframes to csv\n","processed_hits_df.to_csv(f'{data_folder}/before_finished/step_8/post8_actives.csv', index=False)\n","processed_inactives_df.to_csv(f'{data_folder}/before_finished/step_8/post8_inactives.csv', index=False)\n","\n","print('Dataframes saved successfully')"]},{"cell_type":"markdown","metadata":{"id":"U-mlhR8trq4L"},"source":["# 9. Neutralize & 10. Aromatize Molecules"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6C3Yjf4qrq4L"},"outputs":[],"source":["# Create a new step folder:\n","if not os.path.exists(f'{data_folder}/before_finished/step_9_10'):\n","    os.makedirs(f'{data_folder}/before_finished/step_9_10')\n","\n","#import:\n","pre9_actives = pd.read_csv(f'{data_folder}/before_finished/step_8/post8_actives.csv', sep=',', header=0)\n","pre9_inactives = pd.read_csv(f'{data_folder}/before_finished/step_8/post8_inactives.csv', sep=',', header=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d-6OIcTdrq4M"},"outputs":[],"source":["updated_smi = []\n","\n","#Update dataset with neutralized, aromatic SMILES\n","for smi in pre9_actives[smi_col]: \n","    mol = Chem.MolFromSmiles(smi)\n","    mol_neu = utils.neutralize_atoms(mol)\n","    smi_arom = utils.aromatize_smile(mol_neu)\n","    updated_smi.append(smi_arom)\n","    \n","#update the smiles in this df\n","pre9_actives[smi_col] = updated_smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"auQIIZlJrq4M"},"outputs":[],"source":["updated_smi = []\n","\n","#Update dataset with neutralized, aromatic SMILES\n","for smi in pre9_inactives[smi_col]: \n","    mol = Chem.MolFromSmiles(smi)\n","    mol_neu = utils.neutralize_atoms(mol)\n","    smi_arom = utils.aromatize_smile(mol_neu)\n","    updated_smi.append(smi_arom)\n","\n","#update the smiles in this df\n","pre9_inactives[smi_col] = updated_smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pCaAXSLxrq4M"},"outputs":[],"source":["#Save\n","pre9_actives.to_csv(f'{data_folder}/before_finished/step_9_10/post10_actives.csv', index=False)\n","pre9_inactives.to_csv(f'{data_folder}/before_finished/step_9_10/post10_inactives.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"qpyyd0pxrq4M"},"source":["# Post 9+10: Update InChI\n"]},{"cell_type":"markdown","metadata":{"id":"ffOOke7Hrq4M"},"source":["Is it important to now update InChI in our datasets, for 2 reasons:\n","\n","(1) Some mixture compounds have been modified (removal of small inorganic or organic molecules) in SMILES representation but not InChIs.\n","\n","(2) The SMILES representations have been neutralized and aromatized, but not InChIs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pVMRuZcirq4M"},"outputs":[],"source":["#export the smiles columns to txt\n","pre9_actives[smi_col].to_csv(f'{data_folder}/before_finished/step_9_10/smiles_actives.txt', index=False, header=False)\n","pre9_inactives[smi_col].to_csv(f'{data_folder}/before_finished/step_9_10/smiles_inactives.txt', index=False, header=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CoDFoGlFrq4N"},"outputs":[],"source":["\"\"\"\n","Submit the smiles files to PubChem Identifier Exchange Service: \n","    Input IDs: \"SMILES\"\n","    Operator type: \"same CID\" \n","    Output IDs: \"InChI\"\n","    Output method: \"Two column file showing each input output-correspondence\"\n","    Compression: \"No compression\"\n","InChI list should be saved into \"step_9_10\" folder, named as \"inchi_actives.txt\" and \"inchi_inactives\" \n","\"\"\"\n","#Import the converted InChIs\n","cleaned_inchi_hits = pd.read_csv(f'{data_folder}/before_finished/step_9_10/inchi_actives.txt', sep='\\t', header=None)\n","cleaned_inchi_inactives = pd.read_csv(f'{data_folder}/before_finished/step_9_10/inchi_inactives.txt', sep='\\t', header=None)\n","\n","#a dictionary of smiles and corresponding inchi in cleaned_inchi_hits\n","hits_smi_inchi_dict = dict(zip(cleaned_inchi_hits[0], cleaned_inchi_hits[1]))\n","inactives_smi_inchi_dict = dict(zip(cleaned_inchi_inactives[0], cleaned_inchi_inactives[1]))\n","                             \n","#update the pre9_hits by matching the smiles with keys and replace inchi with values:\n","pre9_actives['InChI'] = pre9_actives[smi_col].map(hits_smi_inchi_dict) \n","pre9_inactives['InChI'] = pre9_inactives[smi_col].map(inactives_smi_inchi_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jyjXEqCOrq4N"},"outputs":[],"source":["#export: \n","pre9_actives.to_csv(f'{data_folder}/before_finished/step_9_10/post10_actives.csv', index=False)\n","pre9_inactives.to_csv(f'{data_folder}/before_finished/step_9_10/post10_inactives.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"hrK9Xw9frq4N"},"source":["# 11. PAIN Filters"]},{"cell_type":"markdown","metadata":{"id":"kE3mb13erq4N"},"source":["## 11.1. Frequency of Hits (FoH) Filter"]},{"cell_type":"markdown","metadata":{"id":"NhuMG4Rerq4N"},"source":["Frequency of Hits is a complex concept that requires a merticulous approach. In general, the rule is if a compound was tested active in multiple assays, it is likely to be a promiscuous compound.\n","1. For each compounds, retrieve the information on its tested assays\n","2. For each of the assay tested, retrieve the sequence of the protein target.\n","3. Given all sequence of the protein tested, do a multiple sequence alignment to find the percentage Percent Identity (similarty) between these proteins. If an assay has high percentage to other targets, then these assays contribute less to promiscuousity of the compound.\n","4. Use the percentage identity as a weight:\n","w = 1 - %SI/100\n","Calculate the frequency of hits for each compound:\n","FoH = wACC/TAC\n","wACC is the weighed total number of assay tested where the compounds were identified acitives. TAC is the total number of assays tested."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h4JKGPsRrq4N"},"outputs":[],"source":["pre11_actives = pd.read_csv(f'{data_folder}/before_finished/step_9_10/post10_actives.csv', sep=',', header=0)\n","pre11_inactives = pd.read_csv(f'{data_folder}/before_finished/step_9_10/post10_inactives.csv', sep=',', header=0)\n","\n","# Create a new step folder:\n","if not os.path.exists(f'{data_folder}/before_finished/step_11/11_1'):\n","    os.makedirs(f'{data_folder}/before_finished/step_11/11_1')"]},{"cell_type":"markdown","metadata":{"id":"Fw2Fyb7jrq4N"},"source":["### 11.1.1. PubChem testing information for each compound"]},{"cell_type":"markdown","metadata":{"id":"yfYA2AKirq4O"},"source":["This part illustrates how to retrieve the information of how each compound was tested from the PubChem database. Bulk data retrieval from the ftp server is used to get the information of every bioassay in PubChem:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r9aChYmErq4O"},"outputs":[],"source":["url = 'https://ftp.ncbi.nlm.nih.gov/pubchem/Bioassay/Extras/bioassays.tsv.gz' #this FTP file records the summary data of all available AIDs in PubChem\n","\n","local_save_dir = 'S:\\coding\\WelQrate\\pubchem_sum'\n","local_save_path = os.path.join(local_save_dir, 'bioassays.tsv.gz')\n","\n","if not os.path.exists(local_save_dir):\n","    os.makedirs(local_save_dir)\n","r = requests.get(url, stream=True)\n","\n","with open(local_save_path, 'wb') as f:\n","    for chunk in r.iter_content(chunk_size=8192):\n","        f.write(chunk)\n","print('Downloaded to %s' % local_save_path)\n","\n","path = 'pubchem_sum/bioassays.tsv.gz'\n","\n","# Read the TSV file\n","all_bioassay = pd.read_csv(path, delimiter='\\t')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x3kssiqerq4O","outputId":"8af98ca5-6455-48c6-d104-3c0012538ab6"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>AID</th>\n","      <th>BioAssay Name</th>\n","      <th>Deposit Date</th>\n","      <th>Modify Date</th>\n","      <th>Source Name</th>\n","      <th>Source ID</th>\n","      <th>Substance Type</th>\n","      <th>Outcome Type</th>\n","      <th>Project Category</th>\n","      <th>BioAssay Group</th>\n","      <th>BioAssay Types</th>\n","      <th>Protein Accessions</th>\n","      <th>UniProts IDs</th>\n","      <th>Gene IDs</th>\n","      <th>Target TaxIDs</th>\n","      <th>Taxonomy IDs</th>\n","      <th>Number of Tested SIDs</th>\n","      <th>Number of Active SIDs</th>\n","      <th>Number of Tested CIDs</th>\n","      <th>Number of Active CIDs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>20040815</td>\n","      <td>20231014</td>\n","      <td>DTP/NCI</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>small-molecule</td>\n","      <td>Confirmatory</td>\n","      <td>Other</td>\n","      <td>NCI-60_DOSERESP</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>55004</td>\n","      <td>3280</td>\n","      <td>52994</td>\n","      <td>3057</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>20040815</td>\n","      <td>20231014</td>\n","      <td>DTP/NCI</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>small-molecule</td>\n","      <td>Confirmatory</td>\n","      <td>Other</td>\n","      <td>NCI-60_DOSERESP</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>51204</td>\n","      <td>2596</td>\n","      <td>49337</td>\n","      <td>2449</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>20040815</td>\n","      <td>20231014</td>\n","      <td>DTP/NCI</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>small-molecule</td>\n","      <td>Confirmatory</td>\n","      <td>Other</td>\n","      <td>NCI-60_DOSERESP</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>53832</td>\n","      <td>2486</td>\n","      <td>51804</td>\n","      <td>2301</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>20040815</td>\n","      <td>20231014</td>\n","      <td>DTP/NCI</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>small-molecule</td>\n","      <td>Confirmatory</td>\n","      <td>Other</td>\n","      <td>NCI-60_DOSERESP</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>53828</td>\n","      <td>4275</td>\n","      <td>51804</td>\n","      <td>4041</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>20040815</td>\n","      <td>20231014</td>\n","      <td>DTP/NCI</td>\n","      <td>NCI human tumor cell line growth inhibition as...</td>\n","      <td>small-molecule</td>\n","      <td>Confirmatory</td>\n","      <td>Other</td>\n","      <td>NCI-60_DOSERESP</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>53744</td>\n","      <td>3125</td>\n","      <td>51771</td>\n","      <td>2948</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   AID                                      BioAssay Name  Deposit Date  \\\n","0    1  NCI human tumor cell line growth inhibition as...      20040815   \n","1    3  NCI human tumor cell line growth inhibition as...      20040815   \n","2    5  NCI human tumor cell line growth inhibition as...      20040815   \n","3    7  NCI human tumor cell line growth inhibition as...      20040815   \n","4    9  NCI human tumor cell line growth inhibition as...      20040815   \n","\n","   Modify Date Source Name                                          Source ID  \\\n","0     20231014     DTP/NCI  NCI human tumor cell line growth inhibition as...   \n","1     20231014     DTP/NCI  NCI human tumor cell line growth inhibition as...   \n","2     20231014     DTP/NCI  NCI human tumor cell line growth inhibition as...   \n","3     20231014     DTP/NCI  NCI human tumor cell line growth inhibition as...   \n","4     20231014     DTP/NCI  NCI human tumor cell line growth inhibition as...   \n","\n","   Substance Type  Outcome Type Project Category   BioAssay Group  \\\n","0  small-molecule  Confirmatory            Other  NCI-60_DOSERESP   \n","1  small-molecule  Confirmatory            Other  NCI-60_DOSERESP   \n","2  small-molecule  Confirmatory            Other  NCI-60_DOSERESP   \n","3  small-molecule  Confirmatory            Other  NCI-60_DOSERESP   \n","4  small-molecule  Confirmatory            Other  NCI-60_DOSERESP   \n","\n","  BioAssay Types Protein Accessions UniProts IDs Gene IDs  Target TaxIDs  \\\n","0            NaN                NaN          NaN      NaN            NaN   \n","1            NaN                NaN          NaN      NaN            NaN   \n","2            NaN                NaN          NaN      NaN            NaN   \n","3            NaN                NaN          NaN      NaN            NaN   \n","4            NaN                NaN          NaN      NaN            NaN   \n","\n","  Taxonomy IDs  Number of Tested SIDs  Number of Active SIDs  \\\n","0          NaN                  55004                   3280   \n","1          NaN                  51204                   2596   \n","2          NaN                  53832                   2486   \n","3          NaN                  53828                   4275   \n","4          NaN                  53744                   3125   \n","\n","   Number of Tested CIDs  Number of Active CIDs  \n","0                  52994                   3057  \n","1                  49337                   2449  \n","2                  51804                   2301  \n","3                  51804                   4041  \n","4                  51771                   2948  "]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"source":["all_bioassay.head()"]},{"cell_type":"markdown","metadata":{"id":"LBRsh9tjrq4O"},"source":["### 11.1.2 Retrieving protein sequences for assays tested:"]},{"cell_type":"markdown","metadata":{"id":"jDyCfLCHrq4O"},"source":["Then, the testing information for each compound is retrieved from the PugREST API"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_dZitcHYrq4O"},"outputs":[],"source":["# Cache to store the number of compounds tested per AID to avoid redundant call. \n","num_compounds_tested_cache = {}\n","\n","def get_num_compounds_tested(aid, all_bioassay=all_bioassay):\n","    \"\"\"\n","    This function retrieves the information of how many compounds were tested in a given assay (by AID).\n","    \"\"\"\n","    if aid in num_compounds_tested_cache:\n","        return num_compounds_tested_cache[aid]\n","    else: \n","        #return the 'Number of Tested CIDs' column value at the row where the 'AID' column is equal to aid in the all_bioassay dataframe\n","        num_compounds_tested = all_bioassay[all_bioassay['AID'] == aid]['Number of Tested CIDs'].values[0]\n","    return num_compounds_tested\n","\n","def get_assay_data(cid):\n","    \"\"\"\n","    Return a dictionary of all targets that a given compound (by CID) was tested on in PubChem \n","    and the activity values of the compound. \n","    \"\"\"\n","    url = f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/{cid}/assaysummary/JSON\" #PUG-REST compound summary by CID\n","    response = requests.get(url)\n","    data = response.json()\n","\n","    target_activity = {}\n","\n","    if 'Table' in data and 'Row' in data['Table']:\n","        for row in data['Table']['Row']:\n","            cells = row['Cell']\n","            aid = int(cells[0])  # Extracting the AID from the first cell\n","\n","            # Proceed only if the assay is a screening assay\n","            if cells[10] == 'Screening':\n","\n","                # Proceed only if more than 10,000 compounds were tested\n","                num_compounds_tested = get_num_compounds_tested(aid)\n","                if num_compounds_tested > 10000:\n","                    target_gi = cells[5] # Retrieve the protein target's GI\n","                    activity_outcome = cells[4].lower()\n","\n","                    if target_gi not in target_activity:\n","                        target_activity[target_gi] = activity_outcome == 'active'\n","                    elif activity_outcome == 'active':\n","                        target_activity[target_gi] = True # If a compound was tested multiple times on the same protein, priotize \"active\" outcome.\n","            \n","            else:\n","                continue\n","\n","    return (cid, target_activity)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ubIQlIRZrq4O","outputId":"7307b38f-b9b2-4627-c612-42d4497f59a8"},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing CIDs: 100%|██████████| 87/87 [00:27<00:00,  3.19it/s]\n"]}],"source":["import requests\n","from concurrent.futures import ThreadPoolExecutor, as_completed\n","from tqdm import tqdm\n","\n","cids_list = pre11_actives[cid_col].tolist()\n","\n","def execute_with_multiprocessing(cids_list):\n","    \"\"\"\n","    For a given list of CIDs, return a dictionary of dictionaries \n","    of protein targets these compounds were tested on and the activity outcomes\n","    Input: \n","        [list of CIDs]\n","    Output: \n","        Dictionary of testing information for all CIDs, such as:\n","        {CID1:{target1:activity1, target3:activity3, ...},{CID2:{target2:activity2, target4:activity4, ...}, ...}}\n","    \"\"\"\n","    results_dict = {}\n","    with ThreadPoolExecutor(max_workers=10) as executor:\n","        # Prepare futures for all CIDs\n","        futures = [executor.submit(get_assay_data, cid) for cid in cids_list]\n","        \n","        # Process futures as they complete\n","        for future in tqdm(as_completed(futures), total=len(cids_list), desc=\"Processing CIDs\"):\n","            try:\n","                cid, target_activity = future.result()\n","                results_dict[cid] = target_activity\n","            except Exception as e:\n","                print(f\"Error processing CID: {e}\")\n","    return results_dict\n","\n","results_dict = execute_with_multiprocessing(cids_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a0x1U1Jorq4P"},"outputs":[],"source":["#export results_dict\n","with open(f'{data_folder}/before_finished/step_11/11_1/results_dict.json', 'w') as f:\n","    json.dump(results_dict, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WplloeIIrq4P","outputId":"b475419b-aefd-40a2-a2c8-a6a72b0b7c91"},"outputs":[{"name":"stdout","output_type":"stream","text":["['90111653', '291463269', '13699818', '30219', '47496637', '2853980', '4505445', '998701', '15646160', '124486680', '4503155', '118341367', '2358024', '21264324', '38349113', '116907', '23505220', '119579215', '134244587', '119580345', '4503385', '115529463', '10835013', '70832125', '46577642', '74315350', '14790033', '63102437', '5174513', '119603173', '2501205', '28373962', '262118306', '190938', '6016094', '4885057', '56417702', '21955158', '40254439', '111305821', '6274552', '7657550', '15645703', '32425330', '223468676', '4507793', '21361095', '115347926', '730163', '16878311', '156416009', '4826706', '32307126', '231632', '257380', '56202836', '155969707', '6912644', '23893623', '12830367', '171229', '47132585', '89348172', '56790945', '62868213', '78486550', '5454102', '216548193', '13325293', '4758204', '73586699', '73745819', '90652859', '52426748', '4502331', '166202459', '124487323', '89993689', '67463988', '15929025', '6680530', '4758878', '341916350', '13236497', '499328', '5730106', '15610402', '20070193', '4758484', '378544807', '134304838', '218891639', '881546', '510901', '5453722', '994798', '1302091', '48146199', '224494019', '167013344', '62203298', '10092597', '9955963', '1927', '22538455', '6166485', '27753985', '4502495', '16130723', '2507196', '7669492', '19860819', '2578455', '148378801', '47132611', '83779224', '86301151', '15610601', '7108463', '7706135', '28373018', '2702319', '4505209', '1246761', '10567816', '7706645', '433552101', '7381449', '1519312078', '168184763', '119607129', '54112388', '5032039', '216409728', '4507615', '4502003', '19923198', '109637798', '125541954', '47678551', '48145933', '4506113', '14389423', '4504843', '493539358', '48255881', '4505447', '224028257', '398366139', '312275222', '1111959238', '6978787', '45269145', '55976631', '20072248', '21595511', '1572493', '89191863', '42741659', '13177715', '1781172', '1762973', '9937384', '5016090', '487738', '113121', '48428097', '17391426', '68476498', '23943882', '4503351', '23110962', '55662034', '4507681', '83318444', '4757950', '116292172', '27807367', '21595776', '38027923', '285809906', '6679827', '54112432', '351542238', '74752344', '4506537', '124376142', '55960760', '124263658', '1628587', '115430235', '40807040', '32479527', '11094021', '31563518', '27368096', '81899072', '780303193', '68989256', '11093520', '147728', '7582271', '63477962', '76364066', '339641', '154146191', '1709543', '37589898', '301171662', '11528014', '270133071', '68565074', '285814664', '4503907', '59036749', '29788785', '76496497', '15675770', '4506243', '15610945', '4506055', '16130726', '1679362728', '31542303', '62740231', '55958172', '10190672', '10864009', '21359873', '42794767', '14149746', '15680217', '88501734', '225543099', '32400299', '216548487', '55584151', '195969650', '1937369734', '223459640', '160877737', '187952397', '187960042', '118764400', '112822', '38174238', '613504304', '119607128', '68474550', '9629363', '8574038', '2935630', '130375', '1237937630', '486173', '6831552', '166209887', '62362414', '34330186', '116734717', '71987181', '41872583', '83627717', '49574532', '4581413', '31881630', '597517618', '4826834', '1708272', '119622516', '37622910', '2393947', '148539876', '34577122', '20336315', '16306916', '56786138', '296080766', '74355113', '24119166', '15609874', '160707929', '929524245', '1655766739', '4503383', '6009644', '10835145', '4507593', '126642418', '46909587', '2498404', '119579178', '6708281', '4504343', '1782953264', '126698238', '46367787', '121945198', '6755076', '60391226', '1166512', '75495260', '7108336', '139472804', '15607504', '194068499', '218931251', '12803275', '296434520', '6325022', '28949057', '342179211', '21361340', '4502169', '73747889', '21315078', '1654220559', '17507875', '134142337', '3183518', '9629361', '597517265', '153217451', '116077694', '156104889', '21327705', '13027636', '116076351', '83758679', '124809506', '15927174', '62201602', '83699673', '160333370', '7657508', '90421313', '21392848', '37187860', '38788193', '38258652', '21464101', '5174547', '12381848', '11141885', '11275980', '67463989', '534286618', '13128862', '4503219', '62526033', '149631', '41872631', '9966877', '13399304', '13124881', '116516899', '528078313', '55956923', '110611243', '88702791', '85666113', '21489979', '1797100823', '124809271', '1575471', '86990435', '14719829', '151101270', '536029', '148745659', '32400300', '49168602', '120997', '82503229', '22035600', '253722402', '78070770', '194306653', '20336229', '117940060', '53832009', '6323930', '180352', '317373446', '47123300', '68565218', '109633019', '4757840', '222080095', '735367775', '27597073', '23893668', '5729858', '223460826', '74356043', '4507791', '2182777540', '14790119', '302699239', '15610807', '139424501', '1730321', '4503779', '16130724', '115496662', '578162', '25148072', '16130689', '32307152', '13272532', '16128424', '23510348', '164058', '219518789', '120538355', '74734243', '67191027', '12644416', '119508433', '71746704', '38156699']\n","421\n"]}],"source":["#import results_dict:\n","with open(f'{data_folder}/before_finished/step_11/11_1/results_dict.json', 'r') as f:\n","    results_dict = json.load(f)\n","\n","#get the list of all keys of the values in the dictionary:\n","protein_ids = []\n","for value in results_dict.values():\n","    protein_ids.extend(value.keys())\n","\n","#clean the list\n","protein_ids = list(set(protein_ids))\n","protein_ids = [id for id in protein_ids if id != '']\n","\n","print(protein_ids)\n","print(f'Require multiple sequencing alignment for {len(protein_ids)} proteins.')"]},{"cell_type":"markdown","metadata":{"id":"KuZ2CgDlrq4P"},"source":["Now we retrieve all the FASTA sequences of proteins tested for all of our compounds with Biopython API to Entrez of NCBI. The FASTA sequence is saved as \"sequences.fasta\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l8R77EuJrq4P"},"outputs":[],"source":["# Always tell NCBI who you are\n","Entrez.email = \"hdong26@amherst.edu\"\n","\n","# The filename where you want to save the sequences\n","output_filename = f'{data_folder}/before_finished/step_11/11_1/sequences.fasta'\n","\n","# Open a file to write the sequences\n","with open(output_filename, \"w\") as output_file:\n","    for id in protein_ids:\n","        try:\n","            # Fetch the sequence from NCBI\n","            handle = Entrez.efetch(db=\"protein\", id=id, rettype=\"fasta\", retmode=\"text\")\n","            sequence_data = handle.read()\n","            handle.close()\n","\n","            # Write the sequence data to the file\n","            output_file.write(sequence_data)\n","        except Exception as e:\n","            print(f\"An error occurred while fetching {id}: {e}\")"]},{"cell_type":"markdown","metadata":{"id":"3n-O8UfTrq4Q"},"source":["From the FASTA sequence, we also need to retrieve the list of protein names, since these are different from the protein GIs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0lAtM4Yxrq4Q"},"outputs":[],"source":["def extract_protein_names(file_path):\n","    protein_names = []\n","    with open(file_path, 'r') as file:\n","        for line in file:\n","            if line.startswith('>'):\n","                # Split the line at spaces and take the first item\n","                parts = line.split(' ')\n","                protein_name = parts[0]\n","                # Remove the leading '>' character\n","                protein_name = protein_name[1:]\n","                protein_names.append(protein_name)\n","    return protein_names\n","\n","file_path = f'{data_folder}/before_finished/step_11/11_1/sequences.fasta'\n","protein_names = extract_protein_names(file_path)\n","\n","# Create a dictionary to map protein IDs to protein names by index \n","protein_id_to_name = {protein_ids[i]: protein_names[i] for i in range(len(protein_ids))}"]},{"cell_type":"markdown","metadata":{"id":"hGh94Ztprq4Q"},"source":["### 11.1.3 Percent Sequence Identity by Multiple Sequence Alignment"]},{"cell_type":"markdown","metadata":{"id":"vvxo0gaCrq4Q"},"source":["The sequences.fasta file is submitted to https://www.ebi.ac.uk/jdispatcher/msa/clustalo for multiple sequencing alignment. The resulted table of percent sequence identity matrix is saved and imported for the calculation of FoH"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A3xMryw8rq4Q"},"outputs":[],"source":["\"\"\"\n","Submit sequences.fasta to https://www.ebi.ac.uk/jdispatcher/msa/clustalo\n","    Input sequence type: Protein\n","    Output format: ClustalW with character counts\n","Download the resulted Percent Identity Matrix file file and save as \"percent_identity_matrix.txt\"\n","\"\"\"\n","\n","#import the identity matrix:\n","protein_si = pd.read_csv(\n","    f'{data_folder}/before_finished/step_11/11_1/percent_identity_matrix.txt',\n","    delimiter='\\s+',\n","    header=None,\n","    skiprows=6 \n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"09UliO1Irq4Q"},"outputs":[],"source":["#remove the first column:\n","protein_si = protein_si.drop(protein_si.columns[0], axis=1)\n","\n","name = protein_si[1].tolist()\n","name = ['protein name'] + name\n","protein_si.columns = name"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sx43DZf2rq4R","outputId":"752c4fd9-6195-4a1d-859b-96091754c0f5"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>protein name</th>\n","      <th>NP_063937.2</th>\n","      <th>NP_002084.2</th>\n","      <th>NP_000302.1</th>\n","      <th>NP_004447.2</th>\n","      <th>NP_057856.1</th>\n","      <th>NP_001123617.1</th>\n","      <th>NP_001357589.1</th>\n","      <th>NP_492143.1</th>\n","      <th>NP_036543.4</th>\n","      <th>...</th>\n","      <th>NP_001136020.1</th>\n","      <th>NP_001167549.1</th>\n","      <th>EAW58811.1</th>\n","      <th>NP_217253.1</th>\n","      <th>EAW82767.1</th>\n","      <th>NP_066921.2</th>\n","      <th>AAA62473.1</th>\n","      <th>NP_004944.3</th>\n","      <th>NP_004283.2</th>\n","      <th>NP_004095.4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NP_063937.2</td>\n","      <td>100.00</td>\n","      <td>76.85</td>\n","      <td>15.69</td>\n","      <td>13.91</td>\n","      <td>15.68</td>\n","      <td>8.22</td>\n","      <td>14.77</td>\n","      <td>10.42</td>\n","      <td>14.56</td>\n","      <td>...</td>\n","      <td>6.94</td>\n","      <td>8.09</td>\n","      <td>6.87</td>\n","      <td>10.00</td>\n","      <td>12.07</td>\n","      <td>7.69</td>\n","      <td>7.95</td>\n","      <td>5.45</td>\n","      <td>7.89</td>\n","      <td>12.64</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NP_002084.2</td>\n","      <td>76.85</td>\n","      <td>100.00</td>\n","      <td>17.65</td>\n","      <td>14.02</td>\n","      <td>15.73</td>\n","      <td>9.72</td>\n","      <td>11.88</td>\n","      <td>10.53</td>\n","      <td>12.42</td>\n","      <td>...</td>\n","      <td>6.76</td>\n","      <td>9.84</td>\n","      <td>8.55</td>\n","      <td>11.11</td>\n","      <td>12.77</td>\n","      <td>8.70</td>\n","      <td>12.50</td>\n","      <td>9.66</td>\n","      <td>5.88</td>\n","      <td>12.05</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NP_000302.1</td>\n","      <td>15.69</td>\n","      <td>17.65</td>\n","      <td>100.00</td>\n","      <td>11.11</td>\n","      <td>16.82</td>\n","      <td>17.20</td>\n","      <td>5.98</td>\n","      <td>12.15</td>\n","      <td>11.86</td>\n","      <td>...</td>\n","      <td>5.97</td>\n","      <td>5.06</td>\n","      <td>5.06</td>\n","      <td>NaN</td>\n","      <td>10.53</td>\n","      <td>14.39</td>\n","      <td>8.79</td>\n","      <td>8.11</td>\n","      <td>16.67</td>\n","      <td>13.33</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NP_004447.2</td>\n","      <td>13.91</td>\n","      <td>14.02</td>\n","      <td>11.11</td>\n","      <td>100.00</td>\n","      <td>15.94</td>\n","      <td>12.43</td>\n","      <td>10.51</td>\n","      <td>13.64</td>\n","      <td>11.64</td>\n","      <td>...</td>\n","      <td>7.01</td>\n","      <td>10.91</td>\n","      <td>10.80</td>\n","      <td>8.33</td>\n","      <td>13.16</td>\n","      <td>10.00</td>\n","      <td>9.21</td>\n","      <td>8.81</td>\n","      <td>8.33</td>\n","      <td>11.81</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NP_057856.1</td>\n","      <td>15.68</td>\n","      <td>15.73</td>\n","      <td>16.82</td>\n","      <td>15.94</td>\n","      <td>100.00</td>\n","      <td>11.92</td>\n","      <td>9.65</td>\n","      <td>10.75</td>\n","      <td>11.50</td>\n","      <td>...</td>\n","      <td>13.68</td>\n","      <td>12.62</td>\n","      <td>10.80</td>\n","      <td>12.00</td>\n","      <td>16.16</td>\n","      <td>9.52</td>\n","      <td>13.41</td>\n","      <td>8.50</td>\n","      <td>8.33</td>\n","      <td>12.50</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>416</th>\n","      <td>NP_066921.2</td>\n","      <td>7.69</td>\n","      <td>8.70</td>\n","      <td>14.39</td>\n","      <td>10.00</td>\n","      <td>9.52</td>\n","      <td>10.78</td>\n","      <td>12.85</td>\n","      <td>14.43</td>\n","      <td>10.61</td>\n","      <td>...</td>\n","      <td>18.18</td>\n","      <td>19.10</td>\n","      <td>17.38</td>\n","      <td>20.27</td>\n","      <td>19.38</td>\n","      <td>100.00</td>\n","      <td>16.21</td>\n","      <td>16.93</td>\n","      <td>15.37</td>\n","      <td>19.26</td>\n","    </tr>\n","    <tr>\n","      <th>417</th>\n","      <td>AAA62473.1</td>\n","      <td>7.95</td>\n","      <td>12.50</td>\n","      <td>8.79</td>\n","      <td>9.21</td>\n","      <td>13.41</td>\n","      <td>9.85</td>\n","      <td>9.09</td>\n","      <td>4.63</td>\n","      <td>9.52</td>\n","      <td>...</td>\n","      <td>9.04</td>\n","      <td>10.83</td>\n","      <td>12.28</td>\n","      <td>12.62</td>\n","      <td>16.04</td>\n","      <td>16.21</td>\n","      <td>100.00</td>\n","      <td>16.28</td>\n","      <td>14.60</td>\n","      <td>20.41</td>\n","    </tr>\n","    <tr>\n","      <th>418</th>\n","      <td>NP_004944.3</td>\n","      <td>5.45</td>\n","      <td>9.66</td>\n","      <td>8.11</td>\n","      <td>8.81</td>\n","      <td>8.50</td>\n","      <td>13.70</td>\n","      <td>9.68</td>\n","      <td>9.43</td>\n","      <td>11.03</td>\n","      <td>...</td>\n","      <td>13.10</td>\n","      <td>17.65</td>\n","      <td>17.04</td>\n","      <td>14.77</td>\n","      <td>12.78</td>\n","      <td>16.93</td>\n","      <td>16.28</td>\n","      <td>100.00</td>\n","      <td>17.60</td>\n","      <td>21.53</td>\n","    </tr>\n","    <tr>\n","      <th>419</th>\n","      <td>NP_004283.2</td>\n","      <td>7.89</td>\n","      <td>5.88</td>\n","      <td>16.67</td>\n","      <td>8.33</td>\n","      <td>8.33</td>\n","      <td>8.77</td>\n","      <td>9.20</td>\n","      <td>9.38</td>\n","      <td>3.80</td>\n","      <td>...</td>\n","      <td>14.75</td>\n","      <td>16.67</td>\n","      <td>15.56</td>\n","      <td>11.46</td>\n","      <td>15.98</td>\n","      <td>15.37</td>\n","      <td>14.60</td>\n","      <td>17.60</td>\n","      <td>100.00</td>\n","      <td>25.11</td>\n","    </tr>\n","    <tr>\n","      <th>420</th>\n","      <td>NP_004095.4</td>\n","      <td>12.64</td>\n","      <td>12.05</td>\n","      <td>13.33</td>\n","      <td>11.81</td>\n","      <td>12.50</td>\n","      <td>12.37</td>\n","      <td>11.76</td>\n","      <td>11.83</td>\n","      <td>10.00</td>\n","      <td>...</td>\n","      <td>13.86</td>\n","      <td>16.61</td>\n","      <td>16.40</td>\n","      <td>18.23</td>\n","      <td>19.02</td>\n","      <td>19.26</td>\n","      <td>20.41</td>\n","      <td>21.53</td>\n","      <td>25.11</td>\n","      <td>100.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>421 rows × 422 columns</p>\n","</div>"],"text/plain":["    protein name  NP_063937.2  NP_002084.2  NP_000302.1  NP_004447.2  \\\n","0    NP_063937.2       100.00        76.85        15.69        13.91   \n","1    NP_002084.2        76.85       100.00        17.65        14.02   \n","2    NP_000302.1        15.69        17.65       100.00        11.11   \n","3    NP_004447.2        13.91        14.02        11.11       100.00   \n","4    NP_057856.1        15.68        15.73        16.82        15.94   \n","..           ...          ...          ...          ...          ...   \n","416  NP_066921.2         7.69         8.70        14.39        10.00   \n","417   AAA62473.1         7.95        12.50         8.79         9.21   \n","418  NP_004944.3         5.45         9.66         8.11         8.81   \n","419  NP_004283.2         7.89         5.88        16.67         8.33   \n","420  NP_004095.4        12.64        12.05        13.33        11.81   \n","\n","     NP_057856.1  NP_001123617.1  NP_001357589.1  NP_492143.1  NP_036543.4  \\\n","0          15.68            8.22           14.77        10.42        14.56   \n","1          15.73            9.72           11.88        10.53        12.42   \n","2          16.82           17.20            5.98        12.15        11.86   \n","3          15.94           12.43           10.51        13.64        11.64   \n","4         100.00           11.92            9.65        10.75        11.50   \n","..           ...             ...             ...          ...          ...   \n","416         9.52           10.78           12.85        14.43        10.61   \n","417        13.41            9.85            9.09         4.63         9.52   \n","418         8.50           13.70            9.68         9.43        11.03   \n","419         8.33            8.77            9.20         9.38         3.80   \n","420        12.50           12.37           11.76        11.83        10.00   \n","\n","     ...  NP_001136020.1  NP_001167549.1  EAW58811.1  NP_217253.1  EAW82767.1  \\\n","0    ...            6.94            8.09        6.87        10.00       12.07   \n","1    ...            6.76            9.84        8.55        11.11       12.77   \n","2    ...            5.97            5.06        5.06          NaN       10.53   \n","3    ...            7.01           10.91       10.80         8.33       13.16   \n","4    ...           13.68           12.62       10.80        12.00       16.16   \n","..   ...             ...             ...         ...          ...         ...   \n","416  ...           18.18           19.10       17.38        20.27       19.38   \n","417  ...            9.04           10.83       12.28        12.62       16.04   \n","418  ...           13.10           17.65       17.04        14.77       12.78   \n","419  ...           14.75           16.67       15.56        11.46       15.98   \n","420  ...           13.86           16.61       16.40        18.23       19.02   \n","\n","     NP_066921.2  AAA62473.1  NP_004944.3  NP_004283.2  NP_004095.4  \n","0           7.69        7.95         5.45         7.89        12.64  \n","1           8.70       12.50         9.66         5.88        12.05  \n","2          14.39        8.79         8.11        16.67        13.33  \n","3          10.00        9.21         8.81         8.33        11.81  \n","4           9.52       13.41         8.50         8.33        12.50  \n","..           ...         ...          ...          ...          ...  \n","416       100.00       16.21        16.93        15.37        19.26  \n","417        16.21      100.00        16.28        14.60        20.41  \n","418        16.93       16.28       100.00        17.60        21.53  \n","419        15.37       14.60        17.60       100.00        25.11  \n","420        19.26       20.41        21.53        25.11       100.00  \n","\n","[421 rows x 422 columns]"]},"execution_count":96,"metadata":{},"output_type":"execute_result"}],"source":["protein_si"]},{"cell_type":"markdown","metadata":{"id":"HcnMnaG8rq4R"},"source":["### 11.1.4 Calculation of FoHs:"]},{"cell_type":"markdown","metadata":{"id":"nQFKhjnCrq4R"},"source":["Until now, we have a dictionary of (cid: assays tested); (assay_tested:protein name), and percentage identity matrix with first columns as protein names.\n","For each compound, we retrieve the list of all protein names tested on that compounds by matching between the two first dictionary. From this list, we retrieve the corresponding matrix of percentages identitiy of these proteins corresponding to these compounds and calculate the FoH"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JG8Br4cDrq4R"},"outputs":[],"source":["protein_si_dict = {}\n","for name in protein_si['protein name']: \n","    for other_name in protein_si['protein name']: \n","        if other_name != name: \n","            protein_si_dict[(name, other_name)] = protein_si.loc[protein_si['protein name'] == name, other_name].values[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8MsDJ6_6rq4R","outputId":"ad479d8d-7fd6-4272-9ae9-5068ba9fdf15"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 87/87 [00:11<00:00,  7.79it/s]\n"]}],"source":["foh_dict = {}\n","\n","for cid, targets in tqdm.tqdm(results_dict.items()):\n","    active_weight_list = []\n","    total_weight_list = []\n","\n","    for target_id, result in targets.items():\n","        if target_id == '':\n","            continue\n","\n","        protein_name = protein_id_to_name[target_id]\n","        max_weight = 0\n","\n","        for other_id, other_result in targets.items():\n","            if other_id != target_id and other_id != '':\n","                other_protein_name = protein_id_to_name[other_id]\n","                value = protein_si_dict[(protein_name, other_protein_name)]\n","                max_weight = max(max_weight, value)\n","\n","        target_weight = 1 - max_weight / 100\n","\n","        if result:\n","            active_weight_list.append(target_weight)\n","        total_weight_list.append(target_weight)\n","\n","    if total_weight_list:\n","        foh_score = sum(active_weight_list) / sum(total_weight_list)\n","        foh_dict[cid] = foh_score\n","    else: \n","        foh_dict[cid] = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y5gOA7Htrq4R"},"outputs":[],"source":["#export foh_dict\n","with open(f'{data_folder}/before_finished/step_11/11_1/foh_dict.json', 'w') as f:\n","    json.dump(foh_dict, f)"]},{"cell_type":"markdown","metadata":{"id":"M_ngrRz3rq4S"},"source":["For compounds with FoH larger than 0.26, we remove them"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PBnReLTerq4S","outputId":"4151acab-708a-4d7d-bc5a-47e44a8eda66"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dropped 0 compounds with FoH larger than 0.26\n"]}],"source":["to_drop = []\n","for cid, foh_score in foh_dict.items():\n","    if foh_score > 0.26: \n","        to_drop.append(cid)\n","\n","post_FoH_actives = pre11_actives[~pre11_actives[cid_col].isin(to_drop)]\n","print(f'Dropped {(len(to_drop))} compounds with FoH larger than 0.26')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zNGXs_tmrq4S"},"outputs":[],"source":["post_FoH_actives.to_csv(f'{data_folder}/before_finished/step_11/11_1/post_FoH_actives.csv', index=False)\n","pre11_inactives.to_csv(f'{data_folder}/before_finished/step_11/11_1/post_FoH_inactives.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"f1ooqf0rrq4S"},"source":["## 11.2 Autofluoresence Filter"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["post_FoH_actives = pd.read_csv(f'{data_folder}/before_finished/step_11/11_1/post_FoH_actives.csv', sep=',', header=0)\n","post_FoH_inactives = pd.read_csv(f'{data_folder}/before_finished/step_11/11_1/post_FoH_inactives.csv', sep=',', header=0)"]},{"cell_type":"markdown","metadata":{"id":"s9Sxi5ijrq4T"},"source":["When finding false positive due to autofluorescence and luceferase inhibition, it is important to check if the particular assays use one of these technologies. Here, all three assays (AID626, AID1488, and AID1741) use fluorescence technologies, so it is optimal to remove compounds that are active in AIDs: 587, 588, 590, 591, 592, 593, 594"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p8Iu0L2drq4T"},"outputs":[],"source":["autofluorescence_cids = filters.load_autofluorescence_cids(data_folder)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XbHd2OFNrq4T","outputId":"80072bcd-9395-4d78-fc94-0f46e12b307b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dropped 0 autofluorescence compounds\n"]}],"source":["to_drop_actives = []\n","for cid in post_FoH_actives: \n","    if cid in autofluorescence_cids:\n","        to_drop.append(cid)\n","post_autofluorescence_actives = post_FoH_actives[~post_FoH_actives['PUBCHEM_CID'].isin(to_drop_actives)]\n","print(f'Dropped {(len(to_drop_actives))} autofluorescence compounds')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UZoreKrVrq4T","outputId":"60db886f-c545-40ea-d4a1-24eea4e673ea"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PUBCHEM_CID</th>\n","      <th>PUBCHEM_EXT_DATASOURCE_SMILES</th>\n","      <th>PUBCHEM_ACTIVITY_OUTCOME</th>\n","      <th>InChI</th>\n","      <th>Mol removed from mixture</th>\n","      <th>Small inorganic molecule</th>\n","      <th>Small organic molecule</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1263872</td>\n","      <td>Cc1cc(N2CCN(c3nc(N4CCOCC4)nc4ccccc34)CC2)c2ccc...</td>\n","      <td>Active</td>\n","      <td>InChI=1S/C26H28N6O/c1-19-18-24(20-6-2-4-8-22(2...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>655606</td>\n","      <td>Cc1ccc2nc(NC3=NCN(CCN4CCOCC4)CN3)nc(C)c2c1</td>\n","      <td>Active</td>\n","      <td>InChI=1S/C19H27N7O/c1-14-3-4-17-16(11-14)15(2)...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3236651</td>\n","      <td>C=CCSc1nnc2c(n1)OC(c1cccnc1)N(C(C)=O)c1ccccc1-2</td>\n","      <td>Active</td>\n","      <td>InChI=1S/C20H17N5O2S/c1-3-11-28-20-22-18-17(23...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6603423</td>\n","      <td>Brc1cccc(-c2cnc3n2CCCCC3)c1</td>\n","      <td>Active</td>\n","      <td>InChI=1S/C14H15BrN2/c15-12-6-4-5-11(9-12)13-10...</td>\n","      <td>Cl</td>\n","      <td>Cl</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2998899</td>\n","      <td>Cc1ccccc1C(OCC(O)CN1CCCCC1CCO)c1ccccc1</td>\n","      <td>Active</td>\n","      <td>InChI=1S/C24H33NO3/c1-19-9-5-6-13-23(19)24(20-...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>82</th>\n","      <td>3238898</td>\n","      <td>CCOC(=O)N1CCN(C(=O)c2ccc3c(c2)sc2nc(-c4ccccc4)...</td>\n","      <td>Active</td>\n","      <td>InChI=1S/C23H22N4O3S/c1-2-30-23(29)26-12-10-25...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>83</th>\n","      <td>2999354</td>\n","      <td>CN(C(=O)COC(=O)c1nc(-c2ccccc2)n(-c2ccccc2)n1)C...</td>\n","      <td>Active</td>\n","      <td>InChI=1S/C22H22N4O5S/c1-25(18-12-13-32(29,30)1...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>84</th>\n","      <td>663466</td>\n","      <td>CN1CCN(CC#CCn2c3ccccc3c3ccccc32)CC1</td>\n","      <td>Active</td>\n","      <td>InChI=1S/C21H23N3/c1-22-14-16-23(17-15-22)12-6...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>85</th>\n","      <td>2967872</td>\n","      <td>CC(=O)c1ccccc1OCC(O)CN1CCN(C(c2ccccc2)c2ccccc2...</td>\n","      <td>Active</td>\n","      <td>InChI=1S/C28H32N2O3/c1-22(31)26-14-8-9-15-27(2...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>86</th>\n","      <td>6602782</td>\n","      <td>CCOC(=O)Nc1ccc2c(c1)N(C(=O)CN1CCN(C)CC1)c1cccc...</td>\n","      <td>Active</td>\n","      <td>InChI=1S/C22H26N4O3S/c1-3-29-22(28)23-16-8-9-2...</td>\n","      <td>Cl</td>\n","      <td>Cl</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>87 rows × 7 columns</p>\n","</div>"],"text/plain":["    PUBCHEM_CID                      PUBCHEM_EXT_DATASOURCE_SMILES  \\\n","0       1263872  Cc1cc(N2CCN(c3nc(N4CCOCC4)nc4ccccc34)CC2)c2ccc...   \n","1        655606         Cc1ccc2nc(NC3=NCN(CCN4CCOCC4)CN3)nc(C)c2c1   \n","2       3236651    C=CCSc1nnc2c(n1)OC(c1cccnc1)N(C(C)=O)c1ccccc1-2   \n","3       6603423                        Brc1cccc(-c2cnc3n2CCCCC3)c1   \n","4       2998899             Cc1ccccc1C(OCC(O)CN1CCCCC1CCO)c1ccccc1   \n","..          ...                                                ...   \n","82      3238898  CCOC(=O)N1CCN(C(=O)c2ccc3c(c2)sc2nc(-c4ccccc4)...   \n","83      2999354  CN(C(=O)COC(=O)c1nc(-c2ccccc2)n(-c2ccccc2)n1)C...   \n","84       663466                CN1CCN(CC#CCn2c3ccccc3c3ccccc32)CC1   \n","85      2967872  CC(=O)c1ccccc1OCC(O)CN1CCN(C(c2ccccc2)c2ccccc2...   \n","86      6602782  CCOC(=O)Nc1ccc2c(c1)N(C(=O)CN1CCN(C)CC1)c1cccc...   \n","\n","   PUBCHEM_ACTIVITY_OUTCOME  \\\n","0                    Active   \n","1                    Active   \n","2                    Active   \n","3                    Active   \n","4                    Active   \n","..                      ...   \n","82                   Active   \n","83                   Active   \n","84                   Active   \n","85                   Active   \n","86                   Active   \n","\n","                                                InChI  \\\n","0   InChI=1S/C26H28N6O/c1-19-18-24(20-6-2-4-8-22(2...   \n","1   InChI=1S/C19H27N7O/c1-14-3-4-17-16(11-14)15(2)...   \n","2   InChI=1S/C20H17N5O2S/c1-3-11-28-20-22-18-17(23...   \n","3   InChI=1S/C14H15BrN2/c15-12-6-4-5-11(9-12)13-10...   \n","4   InChI=1S/C24H33NO3/c1-19-9-5-6-13-23(19)24(20-...   \n","..                                                ...   \n","82  InChI=1S/C23H22N4O3S/c1-2-30-23(29)26-12-10-25...   \n","83  InChI=1S/C22H22N4O5S/c1-25(18-12-13-32(29,30)1...   \n","84  InChI=1S/C21H23N3/c1-22-14-16-23(17-15-22)12-6...   \n","85  InChI=1S/C28H32N2O3/c1-22(31)26-14-8-9-15-27(2...   \n","86  InChI=1S/C22H26N4O3S/c1-3-29-22(28)23-16-8-9-2...   \n","\n","   Mol removed from mixture Small inorganic molecule Small organic molecule  \n","0                       NaN                      NaN                    NaN  \n","1                       NaN                      NaN                    NaN  \n","2                       NaN                      NaN                    NaN  \n","3                        Cl                       Cl                    NaN  \n","4                       NaN                      NaN                    NaN  \n","..                      ...                      ...                    ...  \n","82                      NaN                      NaN                    NaN  \n","83                      NaN                      NaN                    NaN  \n","84                      NaN                      NaN                    NaN  \n","85                      NaN                      NaN                    NaN  \n","86                       Cl                       Cl                    NaN  \n","\n","[87 rows x 7 columns]"]},"execution_count":106,"metadata":{},"output_type":"execute_result"}],"source":["post_autofluorescence_actives"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O-QtIMYxrq4U"},"outputs":[],"source":["if not os.path.exists(f'{data_folder}/before_finished/step_11/11_2'):\n","    os.makedirs(f'{data_folder}/before_finished/step_11/11_2')\n","\n","#save: \n","post_autofluorescence_actives.to_csv(f'{data_folder}/before_finished/step_11/11_2/post_autofluorescence_actives.csv', index=False)\n","pre11_inactives.to_csv(f'{data_folder}/before_finished/step_11/11_2/post_autofluorescence_inactives.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"z_evmryMrq4U"},"source":["## 11.3 RDKit PAIN filter"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["post_autofluorescence_actives = pd.read_csv(f'{data_folder}/before_finished/step_11/11_2/post_autofluorescence_actives.csv', sep=',', header=0)\n","post_autofluorescence_inactives = pd.read_csv(f'{data_folder}/before_finished/step_11/11_2/post_autofluorescence_inactives.csv', sep=',', header=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LmVQZoi_rq4U","outputId":"6d590afd-c695-4c0d-ca4d-59cc1696c533"},"outputs":[{"name":"stdout","output_type":"stream","text":["1 pains detected\n","2 pains detected\n","3 pains detected\n","4 pains detected\n","5 pains detected\n","6 pains detected\n","7 pains detected\n"]}],"source":["pains_actives = filters.detect_pains(post_autofluorescence_actives, smi_col, cid_col)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MlJhRQA5rq4U"},"outputs":[],"source":["post_pains_actives = post_autofluorescence_actives[~post_autofluorescence_actives['PUBCHEM_CID'].isin(pains_actives)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"avYhOMH7rq4U"},"outputs":[],"source":["if not os.path.exists(f'{data_folder}/before_finished/step_11/11_3'):\n","    os.makedirs(f'{data_folder}/before_finished/step_11/11_3')\n","\n","post_pains_actives.to_csv(f'{data_folder}/before_finished/step_11/11_3/post_pains_actives.csv', index=False)\n","post_autofluorescence_inactives.to_csv(f'{data_folder}/before_finished/step_11/11_3/post_pains_inactives.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"jOxNmVFgrq4V"},"source":["# 12. Drug-likeness Filter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ygKV94eErq4V"},"outputs":[],"source":["pre12_actives = pd.read_csv(f'{data_folder}/before_finished/step_11/11_3/post_pains_actives.csv', sep=',', header=0)\n","pre12_inactives = pd.read_csv(f'{data_folder}/before_finished/step_11/11_3/post_pains_inactives.csv', sep=',', header=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M3yt5E1Xrq4V","outputId":"9c0ca775-f091-46d6-de5e-f6d55f356b0a"},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing SMILES: 100%|██████████| 80/80 [00:00<?, ?it/s]\n"]}],"source":["not_drug_actives = filters.drug_likeness_filter_multiprocessing(pre12_actives, smi_col, cid_col)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j2fh9mHNrq4V","outputId":"e30db33b-f6bb-4c0b-da08-1ee2290ee8a9"},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing SMILES: 100%|██████████| 61464/61464 [00:00<00:00, 189179.37it/s]\n"]}],"source":["not_drug_inactives = filters.drug_likeness_filter_multiprocessing(pre12_inactives, smi_col, cid_col)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XQE2Gfg8rq4V","outputId":"673667e0-cf21-40d8-e62d-a766d031b697"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dropped 2 hit compounds that do not pass the drug likeness filter\n","Dropped 1171 inactive compounds that do not pass the drug likeness filter\n"]}],"source":["post12_actives = pre12_actives[~pre12_actives['PUBCHEM_CID'].isin(not_drug_actives)]\n","post12_inactives = pre12_inactives[~pre12_inactives['PUBCHEM_CID'].isin(not_drug_inactives)]\n","\n","print(f'Dropped {(len(not_drug_actives))} hit compounds that do not pass the drug likeness filter')\n","print(f'Dropped {(len(not_drug_inactives))} inactive compounds that do not pass the drug likeness filter')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i3gOhITfrq4W"},"outputs":[],"source":["if not os.path.exists(f'{data_folder}/before_finished/step_12'):\n","    os.makedirs(f'{data_folder}/before_finished/step_12')\n","\n","#Export not_drug_actives and inactives:\n","with open(f'{data_folder}/before_finished/step_12/not_drug_actives.json', 'w') as f:\n","    json.dump(not_drug_actives, f)\n","with open(f'{data_folder}/before_finished/step_12/not_drug_inactives.json', 'w') as f:\n","    json.dump(not_drug_inactives, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Q--y7xNrq4W"},"outputs":[],"source":["# save: \n","post12_actives.to_csv(f'{data_folder}/before_finished/step_12/post12_actives.csv', index=False)\n","post12_inactives.to_csv(f'{data_folder}/before_finished/step_12/post12_inactives.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"keBVA55Zrq4W"},"source":["# 13. ChemBL Curation Pipeline"]},{"cell_type":"markdown","metadata":{},"source":["Besides PubChem, the ChEMBL database is one of several public databases containing bioactivity data on small molecule compounds curated from various sources. Incoming compounds are typically not standardized according to consistent rules. To maintain the quality of the final database and to facilitate the comparison and integration of data on the same compound from different sources, it is essential to appropriately standardize the chemical structures in the database. This chemical curation pipeline has been developed by Bento, A.P, et al., using the open-source toolkit RDKit, including a Checker module that tests the validity of chemical structures and flags any serious errors. For ChEMBL, a penalty score of 7 is considered a fatal error, and the molfile is not loaded into the database.\n","\n","In our dataset, we passed all compounds through this Checker module to evaluate the validity of the included chemical structures. For compounds that returned a penalty score of 7, we will check them manually.\n","\n","Reference:\n","Bento, A.P., Hersey, A., Félix, E. et al. An open source chemical structure curation pipeline using RDKit. J Cheminform 12, 51 (2020). https://doi.org/10.1186/s13321-020-00456-1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_zieOev_rq4W"},"outputs":[],"source":["pre13_actives = pd.read_csv(f'{data_folder}/before_finished/step_12/post12_actives.csv', sep=',', header=0)\n","pre13_inactives = pd.read_csv(f'{data_folder}/before_finished/step_12/post12_inactives.csv', sep=',', header=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KGt0DmMZrq4W","outputId":"265954d6-f451-4fd9-9f2d-02f38eb4f66f"},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing SMILES: 100%|██████████| 78/78 [00:00<?, ?it/s]\n","Processing SMILES: 100%|██████████| 60293/60293 [00:30<00:00, 1989.84it/s] \n"]}],"source":["# Apply the ChemBL Curation Pipeline Checker module:\n","score_actives = utils.checker_multiprocessing(pre13_actives, smi_col, cid_col)\n","score_inactives = utils.checker_multiprocessing(pre13_inactives, smi_col, cid_col)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xHnJwn_frq4W","outputId":"0b596ede-c995-4cba-8be7-ba8caf557bae"},"outputs":[{"name":"stdout","output_type":"stream","text":["{0, 2}\n","{0, 2, 5, 6}\n"]}],"source":["#print all unique values in the dictionary:\n","print(set(score_actives.values()))\n","print(set(score_inactives.values()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eVwp2ZAkrq4W"},"outputs":[],"source":["# Create a new step folder\n","if not os.path.exists(f'{data_folder}/before_finished/step_13'):\n","    os.makedirs(f'{data_folder}/before_finished/step_13')\n","\n","# save the scores:\n","with open(f'{data_folder}/before_finished/step_13/score_actives.json', 'w') as f:\n","    json.dump(score_actives, f)\n","with open(f'{data_folder}/before_finished/step_13/score_inactives.json', 'w') as f:\n","    json.dump(score_inactives, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nSxYbsIXrq4X"},"outputs":[],"source":["#drop all compounds with a penalty score of 7:\n","to_drop_actives = []\n","to_drop_inactives = []\n","for cid, penalty_score in score_actives.items():\n","    if penalty_score == 7:\n","        to_drop_actives.append(cid)\n","for cid, penalty_score in score_inactives.items():\n","    if penalty_score == 7:\n","        to_drop_inactives.append(cid)\n","\n","post13_actives = pre13_actives[~pre13_actives[cid_col].isin(to_drop_actives)]\n","post13_inactives = pre13_inactives[~pre13_inactives[cid_col].isin(to_drop_inactives)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kiiEPXqGrq4X"},"outputs":[],"source":["#save final_hits and inactives:\n","post13_actives.to_csv(f'{data_folder}/before_finished/step_13/post13_actives.csv', index=False)\n","post13_inactives.to_csv(f'{data_folder}/before_finished/step_13/post13_inactives.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"udoXcCi5rq4X"},"source":["# 14. Final handling of chemical representation"]},{"cell_type":"markdown","metadata":{"id":"hwIT8cE8rq4X"},"source":["Any kind of molecular processing should come with a special attention to post-processing adjustment. This is because during molecular processing, changes in data representation and format could lead to inconsistency or redundancy in the datasets. Below are the two adjustments performed on our datasets. \n","\n","(1) Some of the InChIs in our datasets should be updated. This is because some of the InChI will be missing, since the PubChem Identifier Exchange service might not able to find the corresponding InChI for the aromatized, neutralized SMILES.\n","\n","(2) Presence of some additional duplicates resulted from molecular processing: While handling mixtures, there might be some mixtures whose component molecules are identical. For example, mixtures of organic and inorganic molecules (molX-ionA and molX-ionB) after removed the ions (ionA and ionB) will result in duplicates (molX). Moreover, since the original mixtures are different, their activities could be different. Therefore, we also need to check their activities while handling these duplicates.\n","- If all duplicates share the same results (active/inactive), we keep one of them, since it is likely that the organic molecule kept contributed more significantly to the activity of the mixture. \n","- If duplicates of the same molecules returned different activity, it is safer to remove both of them."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"odKFA2ykrq4X"},"outputs":[],"source":["#import: \n","pre14_actives = pd.read_csv(f'{data_folder}/before_finished/step_13/post13_actives.csv', sep=',', header=0)\n","pre14_inactives = pd.read_csv(f'{data_folder}/before_finished/step_13/post13_inactives.csv', sep=',', header=0)"]},{"cell_type":"markdown","metadata":{"id":"0ZlUbVYnrq4X"},"source":["## 14.1 Update InChI"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uIu30O8Trq4X"},"outputs":[],"source":["def smi_to_inchi(smi):\n","    mol = Chem.MolFromSmiles(smi)\n","    inchi = Chem.inchi.MolToInchi(mol)\n","    return inchi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WstqjQCnrq4Y","outputId":"bbfa1ee9-4b89-404f-ad0b-8e852f1f5421"},"outputs":[{"name":"stdout","output_type":"stream","text":["Updated 0 InChI values in pre14_hits\n"]},{"name":"stderr","output_type":"stream","text":["[02:07:04] WARNING: Charges were rearranged\n","\n","[02:07:04] WARNING: Omitted undefined stereo\n","\n","[02:07:04] WARNING: Omitted undefined stereo\n","\n","[02:07:04] WARNING: Omitted undefined stereo\n","\n","[02:07:04] WARNING: Omitted undefined stereo\n","\n","[02:07:05] WARNING: Omitted undefined stereo\n","\n"]},{"name":"stdout","output_type":"stream","text":["Updated 25 InChI values in pre14_inactives\n"]},{"name":"stderr","output_type":"stream","text":["[02:07:05] WARNING: Omitted undefined stereo\n","\n","[02:07:05] WARNING: Omitted undefined stereo\n","\n"]}],"source":["count = 0 \n","for index, row in pre14_actives.iterrows():\n","    if row['InChI'] != row['InChI']:\n","        pre14_actives.at[index, 'InChI'] = smi_to_inchi(row[smi_col])\n","        count += 1\n","print(f'Updated {count} InChI values in pre14_actives')\n","\n","count = 0\n","for index, row in pre14_inactives.iterrows():\n","    if row['InChI'] != row['InChI']:\n","        pre14_inactives.at[index, 'InChI'] = smi_to_inchi(row[smi_col])\n","        count += 1\n","print(f'Updated {count} InChI values in pre14_inactives')"]},{"cell_type":"markdown","metadata":{"id":"A_cqzZ5Trq4Y"},"source":["## 14.2 Handle duplicates"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xpU7Q5ASrq4Y","outputId":"efde3e5a-55ab-4a3b-b21f-38c9fbb970d0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of InChI duplicates in hits:  0\n","Number of InChI duplicates in inactives:  22\n","Number of SMILES duplicates in hits:  0\n","Number of SMILES duplicates in inactives:  22\n"]}],"source":["#Check if a mol in active set appeared in inactive set:\n","for i in pre14_actives[smi_col]:\n","    if i in list(pre14_inactives[smi_col]):\n","        print(f'{i} SMILES appeared in both active and inactive sets')\n","for i in pre14_actives['InChI']:\n","    if i in list(pre14_inactives['InChI']):\n","        print(f'{i} InChI appeared in both active and inactive sets')\n","\n","#Return all duplicates by comparing InChI:\n","final_actives_duplicates_InChI = pre14_actives[pre14_actives.duplicated(subset=['InChI'], keep=False)]\n","final_inactives_duplicates_InChI = pre14_inactives[pre14_inactives.duplicated(subset=['InChI'], keep=False)]\n","final_actives_duplicates_smi = pre14_actives[pre14_actives.duplicated(subset=[smi_col], keep=False)]\n","final_inactives_duplicates_smi = pre14_inactives[pre14_inactives.duplicated(subset=[smi_col], keep=False)]\n","\n","print('Number of InChI duplicates in hits: ', len(final_actives_duplicates_InChI))\n","print('Number of InChI duplicates in inactives: ', len(final_inactives_duplicates_InChI))\n","print('Number of SMILES duplicates in hits: ', len(final_actives_duplicates_smi))\n","print('Number of SMILES duplicates in inactives: ', len(final_inactives_duplicates_smi))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d12wLvHjrq4Y"},"outputs":[],"source":["if not os.path.exists(f'{data_folder}/before_finished/step_14'):\n","    os.makedirs(f'{data_folder}/before_finished/step_14')\n","\n","#write all the duplicates to a file:\n","#write duplicates to a txt file: \n","with open(f'{data_folder}/before_finished/step_14/duplicates.txt', 'w') as f:\n","    f.write('InChI duplicates in actives: \\n')\n","    f.write(final_actives_duplicates_InChI.to_string())\n","    f.write('\\n\\n')\n","    f.write('InChI duplicates in inactives: \\n')\n","    f.write(final_inactives_duplicates_InChI.to_string())\n","    f.write('\\n\\n')\n","    f.write('SMILES duplicates in actives: \\n')\n","    f.write(final_actives_duplicates_smi.to_string())\n","    f.write('\\n\\n')\n","    f.write('SMILES duplicates in inactives: \\n')\n","    f.write(final_inactives_duplicates_smi.to_string())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sT7F8fu8rq4Y"},"outputs":[],"source":["#remove these duplicates, keep the first one: \n","#by inchi:\n","final_actives = pre14_actives.drop_duplicates(subset=['InChI'], keep='first')\n","final_inactives = pre14_inactives.drop_duplicates(subset=['InChI'], keep='first')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V6MiBwGzrq4Z","outputId":"636b33ad-6bd6-4802-899a-ea69fa8da28f"},"outputs":[{"name":"stdout","output_type":"stream","text":["No more duplicates in hits\n","No more duplicates in inactives\n"]}],"source":["if len(final_actives[final_actives.duplicated(subset=[smi_col], keep=False)]) == 0:\n","    print('No more duplicates in hits')\n","\n","if len(final_inactives[final_inactives.duplicated(subset=[smi_col], keep=False)]) == 0:\n","    print('No more duplicates in inactives')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1o8bVOPNrq4Z"},"outputs":[],"source":["# save: \n","if not os.path.exists(f'{data_folder}/finished'):\n","    os.makedirs(f'{data_folder}/finished')\n","final_actives.to_csv(f'{data_folder}/finished/final_actives.csv',sep=',', index=False)\n","final_inactives.to_csv(f'{data_folder}/finished/final_inactives.csv',sep=',', index=False)"]},{"cell_type":"markdown","metadata":{"id":"Jj1d-2lMr60w"},"source":["# Some additional modifications"]},{"cell_type":"markdown","metadata":{"id":"ebqgaqW6rq4Z"},"source":["## A. Adjust column names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tvN6iHPzrq4Z"},"outputs":[],"source":["final_actives = pd.read_csv(f'{data_folder}/finished/final_actives.csv', sep=',', header=0)\n","final_inactives = pd.read_csv(f'{data_folder}/finished/final_inactives.csv', sep=',', header=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jC_ibapjrq4Z"},"outputs":[],"source":["# Add another column: \"activity_value\" with all empty NaN values for format consistency with regression datasets:\n","final_actives.loc[:, 'activity_value'] = np.nan \n","final_inactives.loc[:, 'activity_value'] = np.nan\n","\n","if 'small_organic_mol_from_mixture' not in final_actives.columns: # Sometimes, this column might be missing since no small org. mol was detected in mixtures.\n","    final_actives['small_organic_mol_from_mixture'] = np.nan\n","\n","# Rename the columns:\n","final_actives = final_actives.rename(columns={\n","    'PUBCHEM_CID': 'CID',\n","    'PUBCHEM_ACTIVITY_OUTCOME': 'activity_outcome',\n","    'PUBCHEM_EXT_DATASOURCE_SMILES': 'SMILES',\n","    'Mol removed from mixture': 'mol_removed_from_mixture',\n","    'Small inorganic molecule': 'small_inorganic_mol_from_mixture',\n","    'Small organic molecule': 'small_organic_mol_from_mixture'\n","})\n","final_inactives = final_inactives.rename(columns={\n","    'PUBCHEM_CID': 'CID',\n","    'PUBCHEM_ACTIVITY_OUTCOME': 'activity_outcome',\n","    'PUBCHEM_EXT_DATASOURCE_SMILES': 'SMILES',\n","    'Mol removed from mixture': 'mol_removed_from_mixture',\n","    'Small inorganic molecule': 'small_inorganic_mol_from_mixture',\n","    'Small organic molecule': 'small_organic_mol_from_mixture'\n","})\n","\n","#swap the positions of the columns InChI and activity_outcome:\n","final_actives = final_actives[['CID', 'SMILES', 'InChI', 'activity_outcome', 'activity_value', 'mol_removed_from_mixture', 'small_inorganic_mol_from_mixture', 'small_organic_mol_from_mixture']]\n","final_inactives = final_inactives[['CID', 'SMILES', 'InChI', 'activity_outcome', 'activity_value', 'mol_removed_from_mixture', 'small_inorganic_mol_from_mixture', 'small_organic_mol_from_mixture']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1b0TM-qzrq4a"},"outputs":[],"source":["#export:\n","final_actives.to_csv(f'{data_folder}/finished/final_actives.csv', sep=',', index=False)\n","final_inactives.to_csv(f'{data_folder}/finished/final_inactives.csv', sep=',', index=False)"]},{"cell_type":"markdown","metadata":{"id":"BJeEmtfUrq4a"},"source":["## B. Compile Control Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ahpTFm8Orq4a"},"outputs":[],"source":["for AID in AIDs:\n","    exec(f\"raw{AID} = pd.read_csv(f'{data_folder}/before_finished/step_1/AID{AID}.csv', sep=',', header=0)\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fTpnieNOrq4a"},"outputs":[],"source":["#import inchi:\n","for AID in AIDs:\n","    exec(f\"std_inchi{AID} = pd.read_csv(f'{data_folder}/before_finished/step_3/std_inchi_{AID}.txt', sep='\\t', header=None)\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VELrKJT1rq4a"},"outputs":[],"source":["#Update inchi\n","for AID in AIDs:\n","    exec(f\"\"\"\n","raw_inchi_dict{AID} = dict(zip(std_inchi{AID}[0], std_inchi{AID}[1]))\n","raw{AID}['InChI'] = raw{AID}['PUBCHEM_CID'].map(raw_inchi_dict{AID})\n","\"\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Tn3qxcqrq4b"},"outputs":[],"source":["raw_hits = raw628[raw628['PUBCHEM_ACTIVITY_OUTCOME'] == 'Active']\n","raw_inactives = raw628[raw628['PUBCHEM_ACTIVITY_OUTCOME'] == 'Inactive']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6K9Z9Jqerq4b"},"outputs":[],"source":["# Add some other columns to match the format of the curated data:\n","raw_hits.loc[:, 'activity_value'] = np.nan\n","raw_hits.loc[:, 'mol_removed_from_mixture'] = np.nan\n","raw_hits.loc[:, 'small_inorganic_mol_from_mixture'] = np.nan\n","raw_hits.loc[:, 'small_organic_mol_from_mixture'] = np.nan\n","\n","raw_inactives.loc[:, 'activity_value'] = np.nan\n","raw_inactives.loc[:, 'mol_removed_from_mixture'] = np.nan\n","raw_inactives.loc[:, 'small_inorganic_mol_from_mixture'] = np.nan\n","raw_inactives.loc[:, 'small_organic_mol_from_mixture'] = np.nan"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l_f0O2sxrq4b"},"outputs":[],"source":["# Rename the columns:\n","raw_hits = raw_hits.rename(columns={\n","    'PUBCHEM_CID': 'CID',\n","    'PUBCHEM_ACTIVITY_OUTCOME': 'activity_outcome',\n","    'PUBCHEM_EXT_DATASOURCE_SMILES': 'SMILES',\n","})\n","raw_inactives = raw_inactives.rename(columns={\n","    'PUBCHEM_CID': 'CID',\n","    'PUBCHEM_ACTIVITY_OUTCOME': 'activity_outcome',\n","    'PUBCHEM_EXT_DATASOURCE_SMILES': 'SMILES',\n","})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xGWBedA3rq4b"},"outputs":[],"source":["#swap the positions of the columns InChI and activity_outcome:\n","raw_hits = raw_hits[['CID', 'SMILES', 'InChI', 'activity_outcome', 'activity_value', 'mol_removed_from_mixture', 'small_inorganic_mol_from_mixture', 'small_organic_mol_from_mixture']]\n","raw_inactives = raw_inactives[['CID', 'SMILES', 'InChI', 'activity_outcome', 'activity_value', 'mol_removed_from_mixture', 'small_inorganic_mol_from_mixture', 'small_organic_mol_from_mixture']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1fSp097nrq4b"},"outputs":[],"source":["if not os.path.exists(f'{data_folder}/finished/control_data'):\n","    os.makedirs(f'{data_folder}/finished/control_data')\n","\n","#save the hits and inactives\n","raw_hits.to_csv(f'{data_folder}/finished/control_data/raw_hits.csv', sep=',', index=False)\n","raw_inactives.to_csv(f'{data_folder}/finished/control_data/raw_inactives.csv', sep=',', index=False)\n","\n","#save as txt:\n","raw_hits.to_csv(f'{data_folder}/finished/control_data/raw_hits.txt', sep=';', index=False, header=False)\n","raw_inactives.to_csv(f'{data_folder}/finished/control_data/raw_inactives.txt', sep=';', index=False, header=False)"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
